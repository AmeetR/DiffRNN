
@INPROCEEDINGS{Bergstra2013-lr,
title = "Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms",
booktitle = "Proceedings of the 12th Python in Science Conference",
author = "Bergstra, James and Yamins, Dan and Cox, David D",
editor = "der Walt, St\'{e}fan van and Millman, Jarrod and Huff, Katy",
pages = "13--20",
year =  2013
}

@ARTICLE{Stanley2002-ug,
title = "Evolving neural networks through augmenting topologies",
author = "Stanley, Kenneth O and Miikkulainen, Risto",
affiliation = "Department of Computer Sciences, The University of Texas at Austin, Austin, TX 78712, USA. kstanley@cs.utexas.edu",
abstract = "An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is significantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.",
journal = "Evol. Comput.",
volume =  10,
number =  2,
pages = "99--127",
year =  2002,
language = "en"
}

@ARTICLE{He2015-gk,
title = "Deep Residual Learning for Image Recognition",
author = "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
abstract = "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
month =  "10~" # dec,
year =  2015,
archivePrefix = "arXiv",
primaryClass = "cs.CV",
eprint = "1512.03385"
}

@ARTICLE{Kumaran2016-tu,
title = "What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated",
author = "Kumaran, Dharshan and Hassabis, Demis and McClelland, James L",
journal = "Trends Cogn. Sci.",
publisher = "Elsevier",
volume =  20,
number =  7,
pages = "512--534",
month =  "1~" # jul,
year =  2016,
keywords = "memory; learning; hippocampus; artificial intelligence",
language = "en"
}

@ARTICLE{Faget2016-ef,
title = "Afferent Inputs to {Neurotransmitter-Defined} Cell Types in the Ventral Tegmental Area",
author = "Faget, Lauren and Osakada, Fumitaka and Duan, Jinyi and Ressler, Reed and Johnson, Alexander B and Proudfoot, James A and Yoo, Ji Hoon and Callaway, Edward M and Hnasko, Thomas S",
affiliation = "Department of Neurosciences, University of California, San Diego, La Jolla, CA 92093, USA. Systems Neurobiology Laboratories, Salk Institute for Biological Studies, La Jolla, CA 92037, USA; Laboratory of Cellular Pharmacology, Graduate School of Pharmaceutical Sciences, Nagoya University, Nagoya 464-8601, Japan; Laboratory of Neural Information Processing, Institute for Advanced Research, Nagoya University, Nagoya 464-8601, Japan. Department of Neurosciences, University of California, San Diego, La Jolla, CA 92093, USA. Department of Neurosciences, University of California, San Diego, La Jolla, CA 92093, USA. Department of Neurosciences, University of California, San Diego, La Jolla, CA 92093, USA. Clinical and Translational Research Institute, University of California, San Diego, La Jolla, CA 92093, USA. Department of Neurosciences, University of California, San Diego, La Jolla, CA 92093, USA. Systems Neurobiology Laboratories, Salk Institute for Biological Studies, La Jolla, CA 92037, USA. Department of Neurosciences, University of California, San Diego, La Jolla, CA 92093, USA. Electronic address: thnasko@ucsd.edu.",
abstract = "The ventral tegmental area (VTA) plays a central role in the neural circuit control of behavioral reinforcement. Though considered a dopaminergic nucleus, the VTA contains substantial heterogeneity in neurotransmitter type, containing also GABA and glutamate neurons. Here, we used a combinatorial viral approach to transsynaptically label afferents to defined VTA dopamine, GABA, or glutamate neurons. Surprisingly, we find that these populations received qualitatively similar inputs, with dominant and comparable projections from the lateral hypothalamus, raphe, and ventral pallidum. However, notable differences were observed, with striatal regions and globus pallidus providing a greater share of input to VTA dopamine neurons, cortical input preferentially on to glutamate neurons, and GABA neurons receiving proportionally more input from the lateral habenula and laterodorsal tegmental nucleus. By comparing inputs to each of the transmitter-defined VTA cell types, this study sheds important light on the systems-level organization of diverse inputs to VTA.",
journal = "Cell Rep.",
month =  "7~" # jun,
year =  2016,
language = "en"
}

@ARTICLE{Rudebeck2014-wl,
title = "The orbitofrontal oracle: cortical mechanisms for the prediction and evaluation of specific behavioral outcomes",
author = "Rudebeck, Peter H and Murray, Elisabeth A",
affiliation = "Friedman Brain Institute, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, NY 10014, USA. Electronic address: peter.rudebeck@mssm.edu. Section on the Neurobiology of Learning and Memory, Laboratory of Neuropsychology, National Institute of Mental Health, Building 49, Suite 1B80, 49 Convent Drive, Bethesda, MD 20892, USA. Electronic address: murraye@mail.nih.gov.",
abstract = "The orbitofrontal cortex (OFC) has long been associated with the flexible control of behavior and concepts such as behavioral inhibition, self-control, and emotional regulation. These ideas emphasize the suppression of behaviors and emotions, but OFC's affirmative functions have remained enigmatic. Here we review recent work that has advanced our understanding of this prefrontal area and how its functions are shaped through interaction with subcortical structures such as the amygdala. Recent findings have overturned theories emphasizing behavioral inhibition as OFC's fundamental function. Instead, new findings indicate that OFC provides predictions about specific outcomes associated with stimuli, choices, and actions, especially their moment-to-moment value based on current internal states. OFC function thereby encompasses a broad representation or model of an individual's sensory milieu and potential actions, along with their relationship to likely behavioral outcomes.",
journal = "Neuron",
volume =  84,
number =  6,
pages = "1143--1156",
month =  "17~" # dec,
year =  2014,
language = "en"
}

@ARTICLE{Wilson2014-wg,
title = "Orbitofrontal cortex as a cognitive map of task space",
author = "Wilson, Robert C and Takahashi, Yuji K and Schoenbaum, Geoffrey and Niv, Yael",
affiliation = "Department of Psychology and Neuroscience Institute, Princeton University, Princeton, NJ 08544, USA. Electronic address: rcw2@princeton.edu. Department of Anatomy and Neurobiology, University of Maryland School of Medicine, Baltimore MD 21201, USA. Department of Anatomy and Neurobiology, University of Maryland School of Medicine, Baltimore MD 21201, USA; Department of Psychiatry, University of Maryland School of Medicine, Baltimore MD 21201, USA. Department of Psychology and Neuroscience Institute, Princeton University, Princeton, NJ 08544, USA. Electronic address: yael@princeton.edu.",
abstract = "Orbitofrontal cortex (OFC) has long been known to play an important role in decision making. However, the exact nature of that role has remained elusive. Here, we propose a unifying theory of OFC function. We hypothesize that OFC provides an abstraction of currently available information in the form of a labeling of the current task state, which is used for reinforcement learning (RL) elsewhere in the brain. This function is especially critical when task states include unobservable information, for instance, from working memory. We use this framework to explain classic findings in reversal learning, delayed alternation, extinction, and devaluation as well as more recent findings showing the effect of OFC lesions on the firing of dopaminergic neurons in ventral tegmental area (VTA) in rodents performing an RL task. In addition, we generate a number of testable experimental predictions that can distinguish our theory from other accounts of OFC function.",
journal = "Neuron",
volume =  81,
number =  2,
pages = "267--279",
month =  "22~" # jan,
year =  2014,
language = "en"
}

@ARTICLE{noauthor_undated-xc,
title = "54a42bcf0cf267bdb90671b4.pdf"
}

@ARTICLE{Stokes2016-hw,
title = "The Importance of {Single-Trial} Analyses in Cognitive Neuroscience",
author = "Stokes, Mark and Spaak, Eelke",
journal = "Trends Cogn. Sci.",
publisher = "Elsevier",
volume =  0,
number =  0,
month =  "27~" # may,
year =  2016,
annote = "- Related to Lundqvist/Miller 2016, also talks about Latimer et al 2015 (LIP ``ramps to bound'' actually discrete steps<div><br></div><div>- Points out that averaging over many trials may give misleading picture of what single-trial activity actually looks like</div><div><br></div><div>[But: 1- the Latimer result has been challenged and 2- The Gamma-burstiness of Lundqvist does not necessarily entails brief bursts of spikes separated by long stripes of silence]</div>",
language = "en"
}

@ARTICLE{Lazar2009-ba,
title = "{SORN}: a self-organizing recurrent neural network",
author = "Lazar, Andreea and Pipa, Gordon and Triesch, Jochen",
affiliation = "Frankfurt Institute of Advanced Studies, Johann Wolfgang Goethe University Frankfurt am Main, Germany. lazar@fias.uni-frankfurt.de",
abstract = "Understanding the dynamics of recurrent neural networks is crucial for explaining how the brain processes information. In the neocortex, a range of different plasticity mechanisms are shaping recurrent networks into effective information processing circuits that learn appropriate representations for time-varying sensory stimuli. However, it has been difficult to mimic these abilities in artificial neural network models. Here we introduce SORN, a self-organizing recurrent network. It combines three distinct forms of local plasticity to learn spatio-temporal patterns in its input while maintaining its dynamics in a healthy regime suitable for learning. The SORN learns to encode information in the form of trajectories through its high-dimensional state space reminiscent of recent biological findings on cortical coding. All three forms of plasticity are shown to be essential for the network's success.",
journal = "Front. Comput. Neurosci.",
volume =  3,
pages = "23",
month =  "30~" # oct,
year =  2009,
annote = "- Binary units with exc. STDP, synaptic scaling, and threshold adaptation. (In later papers, they add inhibitory STDP, but not in this one)<div><br></div><div>- Can learn to perform time-dependent tasks, e.g. count incoming stimuli to predict the next one.</div><div><br></div><div>- Network connectivity doesn't converge</div><div><br></div><div>- Synaptic scaling necessary to prevent seizures. Threshold adaptation allows all cells to fire.</div>",
keywords = "intrinsic plasticity; recurrent neural networks; reservoir computing; synaptic plasticity; time series prediction",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Richard2013-mq,
title = "Nucleus accumbens {GABAergic} inhibition generates intense eating and fear that resists environmental retuning and needs no local dopamine",
author = "Richard, Jocelyn M and Plawecki, Andrea M and Berridge, Kent C",
affiliation = "Department of Psychology, University of Michigan, Ann Arbor, MI, USA. jrichard@gallo.ucsf.edu",
abstract = "Intense fearful behavior and/or intense appetitive eating behavior can be generated by localized amino acid inhibitions along a rostrocaudal anatomical gradient within medial shell of nucleus accumbens of the rat. This can be produced by microinjections in medial shell of either the $\gamma$-aminobutyric acid (GABA)A agonist muscimol (mimicking intrinsic GABAergic inputs) or the AMPA ($\alpha$-amino-3-hydroxy-5-methylisoxazole-4-propionic acid) antagonist DNQX (6,7-dinitroquinoxaline-2,3-dione), disrupting corticolimbic glutamate inputs). At rostral sites in medial shell, each drug robustly stimulates appetitive eating and food intake, whereas at more caudal sites the same drugs instead produce increasingly fearful behaviors such as escape, distress vocalizations and defensive treading (an antipredator behavior rodents emit to snakes and scorpions). Previously we showed that intense motivated behaviors generated by glutamate blockade require local endogenous dopamine and can be modulated in valence by environmental ambience. Here we investigated whether GABAergic generation of intense appetitive and fearful motivations similarly depends on local dopamine signals, and whether the valence of motivations generated by GABAergic inhibition can also be retuned by changes in environmental ambience. We report that the answer to both questions is 'no'. Eating and fear generated by GABAergic inhibition of accumbens shell does not need endogenous dopamine. Also, the appetitive/fearful valence generated by GABAergic muscimol microinjections resists environmental retuning and is determined almost purely by rostrocaudal anatomical placement. These results suggest that nucleus accumbens GABAergic release of fear and eating are relatively independent of modulatory dopamine signals, and more anatomically pre-determined in valence balance than release of the same intense behaviors by glutamate disruptions.",
journal = "Eur. J. Neurosci.",
volume =  37,
number =  11,
pages = "1789--1802",
month =  jun,
year =  2013,
annote = "<div>- Known: Both </div><div><br></div>-  the DA interaction (AND the environmental retuning) is only for AMPAr blockade - not with muscimol ! Richard Plawecki Berridge Eur J Neurosci 2013",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Richard2011-fr,
title = "Nucleus Accumbens {Dopamine/Glutamate} Interaction Switches Modes to Generate Desire versus Dread: {D1} Alone for Appetitive Eating But {D1} and {D2} Together for Fear",
author = "Richard, Jocelyn M and Berridge, Kent C",
abstract = "The medial shell of nucleus accumbens (NAc) and its mesolimbic dopamine inputs mediate forms of fearful as well as of incentive motivation. For example, either appetitive and/or actively fearful behaviors are generated in a keyboard pattern by localized glutamate disruptions in NAc (via microinjection of the AMPA receptor antagonist DNQX) at different anatomical locations along a rostrocaudal gradient within the medial shell of rats. Rostral glutamate disruptions produce intense increases in eating, but more caudally placed disruptions produce increasingly fearful behaviors: distress vocalizations and escape attempts to human touch, and a spontaneous and directed antipredator response called defensive treading/burying. Local endogenous dopamine is required for either intense motivation to be generated by AMPA disruptions. Here we report that only endogenous local signaling at D1 dopamine receptors is needed for rostral generation of excessive eating, potentially implicating a direct output pathway contribution. In contrast, fear generation at caudal sites requires both D1 and D2 signaling simultaneously, potentially implicating an indirect output pathway contribution. Finally, when motivation valence generated by AMPA disruptions at intermediate sites was flipped by manipulating environmental ambience, from mostly appetitive in a comfortable home environment to mostly fearful in a stressful environment, the roles of local D1 and D2 signaling in dopamine/glutamate interaction at microinjection sites also switched dynamically to match the motivation valence generated at the moment. Thus, NAc D1 and D2 receptors, and their associated neuronal circuits, play different and dynamic roles in enabling desire and dread to be generated by localized NAc glutamate disruptions in medial shell.",
journal = "J. Neurosci.",
volume =  31,
number =  36,
pages = "12866--12879",
month =  "7~" # sep,
year =  2011,
annote = "- To generate feeding/liking with AMPAR disruption in rostral NAcc mSh, you need D1r at the same site<div><br></div><div>- To generate dread/fear/disliking with AMPAR disruption in caudal NAcc mSh, you need D1r AND D2r at the same site</div><div><br></div><div>- In NAcc mSh, ``direct'' pathway goes to VTA ?? Indirect goes to VP, then to  LH and VTA ?? From Humphries \& Prescott 2010...</div><div><br></div><div>- Wait, this kind of makes sense! If we assume disrupting the NAcc mSh kills the direct pathway which is inhibitory of VTA, thus releases lots of DA into the NAcc !! Reversely for the indirect pathway. BUT, direct is D1, while indirect is D1 and D2 !! (see Humphries\& Prescott 2010)....  </div><div><br></div><div>- BUT - the DA interaction (AND the environmental retuning) is only for AMPAr blockade - not with muscimol ! Richard Plawecki Berridge Eur J Neurosci 2013</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Reynolds2002-nv,
title = "Positive and Negative Motivation in Nucleus Accumbens Shell: Bivalent Rostrocaudal Gradients for {GABA-Elicited} Eating, Taste {``Liking''/``Disliking''} Reactions, Place {Preference/Avoidance}, and Fear",
author = "Reynolds, Sheila M and Berridge, Kent C",
abstract = "Microinjection of the GABAA agonist muscimol in the rostral medial accumbens shell in rats elicits appetitive eating behavior, but in the caudal shell instead elicits fearful defensive treading behavior. To further test the hypothesis that rostral shell muscimol microinjections produce positive motivational states, whereas caudal shell muscimol produces negative states, we measured behavioral place preference/avoidance conditioning and affective hedonic and aversive orofacial expressions of taste-elicited ``liking'' and ``disliking'' (gapes, etc.) in addition to fear and feeding behaviors. Farthest rostral muscimol microinjections (75 ng) caused increased eating behavior and also caused positive conditioned place preferences and increased positive hedonic reactions to the taste of sucrose. By contrast, caudal shell microinjections elicited negative defensive treading and caused robust negative conditioned place avoidance and negative aversive reactions to sucrose or quinine tastes. Intermediate rostral microinjections elicited effects of mixed positive/negative valence (positive appetitive eating behavior but negative place avoidance and negative taste reactions at mid-rostral sites, and sometimes positive eating simultaneously with fearful defensive treading more caudally). These results indicate that GABAergic neurotransmission in local microcircuits in nucleus accumbens mediates motivated/affective behavior that is bivalently organized along rostrocaudal gradients.",
journal = "J. Neurosci.",
volume =  22,
number =  16,
pages = "7308--7320",
month =  "15~" # aug,
year =  2002,
annote = "- See Reynolds \& Berridge 2008, Richard \& Berridge  2011"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Reynolds2008-yn,
title = "Emotional environments retune the valence of appetitive versus fearful functions in nucleus accumbens",
author = "Reynolds, Sheila M and Berridge, Kent C",
affiliation = "Department of Psychology, 525 E. University Avenue, University of Michigan, Ann Arbor, Michigan 48109-1109, USA. sheilar@umich.edu",
abstract = "The nucleus accumbens mediates both appetitive motivation for rewards and fearful motivation toward threats, which are generated in part by glutamate-related circuits organized in a keyboard fashion. At rostral sites of the medial shell, localized glutamate disruptions typically generate intense appetitive behaviors in rats, but the disruption incrementally generates fearful behaviors as microinjection sites move more caudally. We found that exposure to stressful environments caused caudal fear-generating zones to expand rostrally, filling approximately 90\% of the shell. Conversely, a preferred home environment caused fear-generating zones to shrink and appetitive-generating zones to expand caudally, filling approximately 90\% of the shell. Thus, the emotional environments retuned the generation of motivation in corticolimbic circuits.",
journal = "Nat. Neurosci.",
volume =  11,
number =  4,
pages = "423--425",
month =  apr,
year =  2008,
annote = "- KNOWN (from also other authors - See Reynolds \& Berridge 2002,  Richard \& Berridge 2011): <div><span style=``word-spacing: normal; line-height: 1.5em;''>* Inject GABA, or disrupt Glut, in rostral NAcc mShell = feeding frenzy ! Also, Conditioned Place Preference! and ``Liking'', hedonic responses !</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>* Same in caudal NAcc mShell = dread, fear, evasion, kicking sand ! Also, strong Conditioned Place Avoidance, ``disliking'' responses even to sucrose !</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>* 26\% of sites evoke graded mixtures of dread and desire - like a ``keyboard''</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- NAcc mSh Glu inputs are from BLA, HPC and Cortex (which part?)</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Glut / AMPAR antagonists generates Fos increase ??? More firing ??</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- In familiar environment, 90\% of NAcc mShell becomes pro-feeding on AMPA antagonist ! No mixed valence, many silent.</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- In stressful environment (Iggy Pop!), 80\% of NAcc mShell becomes pro-fear on AMPA disruption. Most remain mixed-valence, no silent any more.</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div>",
language = "en"
}

@ARTICLE{Roitman2005-bg,
title = "Nucleus accumbens neurons are innately tuned for rewarding and aversive taste stimuli, encode their predictors, and are linked to motor output",
author = "Roitman, Mitchell F and Wheeler, Robert A and Carelli, Regina M",
affiliation = "Department of Psychology, University of North Carolina, Chapel Hill, North Carolina 27599, USA.",
abstract = "The nucleus accumbens (NAc) is a key component of the brain's reward pathway, yet little is known of how NAc cells respond to primary rewarding or aversive stimuli. Here, naive rats received brief intraoral infusions of sucrose and quinine paired with cues in a classical conditioning paradigm while the electrophysiological activity of individual NAc neurons was recorded. NAc neurons (102) were typically inhibited by sucrose (39 of 52, 75\%) or excited by quinine (30 of 40, 75\%) infusions. Changes in firing rate were correlated with the oromotor response to intraoral infusions. Most taste-responsive neurons responded to only one of the stimuli. NAc neurons developed responses to the cues paired with sucrose and quinine. Thus, NAc neurons are innately tuned to rewarding and aversive stimuli and rapidly develop responses to predictive cues. The results indicate that the output of the NAc is very different when rats taste rewarding versus aversive stimuli.",
journal = "Neuron",
volume =  45,
number =  4,
pages = "587--597",
month =  "17~" # feb,
year =  2005,
annote = "- Some NAcc (Sh \& Core) neurons respond to delivery of sucrose or quinine - rarely both, and if they do, in opposite direction<div><br></div><div>- Response to sucrose is mostly inhibitory, confirming large suppression of NAcc during feeding</div><div><br></div><div>- Response to quinine is largely excitatory.</div><div><br></div><div>- Responses correlate with MEG activity.<br><div><br></div></div><div>- Neurons also respond to stimulus-predictive cue. However, only the ones that show excitatory response to sucrose-predictive cues seem to show any learning ?</div>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ramirez2015-ke,
title = "Active avoidance requires a serial basal amygdala to nucleus accumbens shell circuit",
author = "Ramirez, Franchesca and Moscarello, Justin M and LeDoux, Joseph E and Sears, Robert M",
affiliation = "Center for Neural Science, Department of Psychology, New York University, New York, New York 10003, and. Center for Neural Science. Center for Neural Science, Department of Psychology, New York University, New York, New York 10003, and Emotional Brain Institute, Nathan Kline Institute for Psychiatric Research, Orangeburg, New York 10962. Center for Neural Science, robert.sears@nyu.edu.",
abstract = "Freezing is a species-typical defensive reaction to conditioned threats. While the neural circuitry of aversive Pavlovian behavior has been extensively studied, less is known about the circuitry underlying more active responses to danger. Here we show that the flow of information between the basal amygdala (BA) and the nucleus accumbens (NAcc) is necessary for signaled active avoidance behavior. Rats trained to avoid shock by shuttling during an auditory conditioned stimulus showed increased expression of the activity-dependent protein c-Fos in the NAcc, specifically the shell subregion (NAccSh). Silencing neural activity in the NAccSh, but not in the adjacent NAcc core, disrupted avoidance behavior. Disconnection of the BA and the NAccSh was just as effective at disrupting avoidance behavior as bilateral NAccSh inactivations, suggesting learned avoidance behavior requires an intact BA-NAccSh circuit. Together, these data highlight an essential role for the amygdalar projection to the ventral striatum in aversively motivated actions.",
journal = "J. Neurosci.",
volume =  35,
number =  8,
pages = "3470--3477",
month =  "25~" # feb,
year =  2015,
annote = "- BLA-to-NAcc mShell (NOT Core) is necessary for active avoidance (as opposed to just plain freezing)<div><br></div><div>- Known: BLA, but not CeA, involved in active avoidance (while freezing involves both BLA and CeA); BLA-NAcc involved in appetive modulation of instrumental action !</div><div><br></div><div>- Task: a tone is associated to an impending footshock, but if you move to the other room you STOP THE TONE and prevent the footshock</div><div><br></div><div>- [So it's not just avoiding something in the near future, it's getting something right now - i.e. the end of the (presumably aversive) tone ! - But NAcc really does seem to have some ``dread'' neurons, as shown by Roitman 2005, and the Robinson \& Berridge ``keyboard'' stuff...]</div><div><br></div><div>- If you either kill NAccSh, or disconnect BLA from NAcc Sh, you strongly reduce avoidance. NAcc Co: no effect. </div><div><br></div><div>- Also, slightly increases freezing during the Avoidance task. But no effect on freezing in a one-room box or in a pure-Pavlovian task.</div><div><br></div><div>- Suggests model: LA->BA->CeA for conditioned Pavlovian reaction (freezing) , vs LA->BA->NaccSh for active conditioned response</div><div><br></div><div>- NOTE: IL/mPFC FF inhibition of CeA seems necessary to learn active avoidance, as opposed to always freezing... </div>",
keywords = "aversive; fear conditioning; motivation; negative reinforcement; two-way signaled active avoidance",
language = "en"
}

@ARTICLE{Namburi2015-vr,
title = "A circuit mechanism for differentiating positive and negative associations",
author = "Namburi, Praneeth and Beyeler, Anna and Yorozu, Suzuko and Calhoon, Gwendolyn G and Halbert, Sarah A and Wichmann, Romy and Holden, Stephanie S and Mertens, Kim L and Anahtar, Melodi and Felix-Ortiz, Ada C and Wickersham, Ian R and Gray, Jesse M and Tye, Kay M",
affiliation = "1] The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA [2] Neuroscience Graduate Program, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. Department of Genetics, Harvard Medical School, 77 Avenue Louis Pasteur, NRB 356, Boston, Massachusetts 02115, USA. The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. 1] The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA [2] Undergraduate Program in Neuroscience, Wellesley College, Wellesley, Massachusetts 02481, USA. The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. 1] The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA [2] Undergraduate Program in Neuroscience, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. 1] The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA [2] Master's Program in Biomedical Sciences, University of Amsterdam, Amsterdam 1098 XH, The Netherlands. 1] The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA [2] Undergraduate Program in Neuroscience, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. 1] The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA [2] Neuroscience Graduate Program, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. Department of Genetics, Harvard Medical School, 77 Avenue Louis Pasteur, NRB 356, Boston, Massachusetts 02115, USA. The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA.",
abstract = "The ability to differentiate stimuli predicting positive or negative outcomes is critical for survival, and perturbations of emotional processing underlie many psychiatric disease states. Synaptic plasticity in the basolateral amygdala complex (BLA) mediates the acquisition of associative memories, both positive and negative. Different populations of BLA neurons may encode fearful or rewarding associations, but the identifying features of these populations and the synaptic mechanisms of differentiating positive and negative emotional valence have remained unknown. Here we show that BLA neurons projecting to the nucleus accumbens (NAc projectors) or the centromedial amygdala (CeM projectors) undergo opposing synaptic changes following fear or reward conditioning. We find that photostimulation of NAc projectors supports positive reinforcement while photostimulation of CeM projectors mediates negative reinforcement. Photoinhibition of CeM projectors impairs fear conditioning and enhances reward conditioning. We characterize these functionally distinct neuronal populations by comparing their electrophysiological, morphological and genetic features. Overall, we provide a mechanistic explanation for the representation of positive and negative associations within the amygdala.",
journal = "Nature",
volume =  520,
number =  7549,
pages = "675--678",
month =  "30~" # apr,
year =  2015,
language = "en"
}

@ARTICLE{Janak2015-oi,
title = "From circuits to behaviour in the amygdala",
author = "Janak, Patricia H and Tye, Kay M",
affiliation = "1] Department of Psychological and Brain Sciences, Johns Hopkins University, Baltimore, Maryland 21218, USA. [2] Department of Neuroscience, Johns Hopkins University, Baltimore, Maryland 21205, USA. Department of Brain and Cognitive Sciences, Picower Institute for Learning and Memory, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA.",
abstract = "The amygdala has long been associated with emotion and motivation, playing an essential part in processing both fearful and rewarding environmental stimuli. How can a single structure be crucial for such different functions? With recent technological advances that allow for causal investigations of specific neural circuit elements, we can now begin to map the complex anatomical connections of the amygdala onto behavioural function. Understanding how the amygdala contributes to a wide array of behaviours requires the study of distinct amygdala circuits.",
journal = "Nature",
volume =  517,
number =  7534,
pages = "284--292",
month =  "15~" # jan,
year =  2015,
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Warren2016-zd,
title = "{Catecholamine-Mediated} Increases in Gain Enhance the Precision of Cortical Representations",
author = "Warren, Christopher M and Eldar, Eran and van den Brink, Ruud L and Tona, Klodianna-Daphne and van der Wee, Nic J and Giltay, Eric J and van Noorden, Martijn S and Bosch, Jos A and Wilson, Robert C and Cohen, Jonathan D and Nieuwenhuis, Sander",
affiliation = "Department of Psychology, Leiden University, 2333 AK Leiden, The Netherlands, Leiden Institute for Brain and Cognition, Leiden University, Leiden, 2300 RC Leiden, The Netherlands, c.m.warren@fsw.leidenuniv.nl. Welcome Trust Centre for Neuroimaging, University College London, London WC1N 3BG, United Kingdom. Department of Psychology, Leiden University, 2333 AK Leiden, The Netherlands, Leiden Institute for Brain and Cognition, Leiden University, Leiden, 2300 RC Leiden, The Netherlands. Department of Psychology, Leiden University, 2333 AK Leiden, The Netherlands, Leiden Institute for Brain and Cognition, Leiden University, Leiden, 2300 RC Leiden, The Netherlands. Leiden Institute for Brain and Cognition, Leiden University, Leiden, 2300 RC Leiden, The Netherlands, Department of Psychiatry, Leiden University Medical Center, 2333 ZA Leiden, The Netherlands. Department of Psychiatry, Leiden University Medical Center, 2333 ZA Leiden, The Netherlands. Department of Psychiatry, Leiden University Medical Center, 2333 ZA Leiden, The Netherlands. Department of Clinical Psychology, University of Amsterdam, 1018 XA Amsterdam, The Netherlands, Mannheim Institute of Public Health, Heidelberg University, 68167 Mannheim, Germany. Department of Psychology, University of Arizona, Tucson, Arizona 85721, and. Department of Psychology, Leiden University, 2333 AK Leiden, The Netherlands, Leiden Institute for Brain and Cognition, Leiden University, Leiden, 2300 RC Leiden, The Netherlands. Department of Psychology and Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey 08540.",
abstract = "UNLABELLED: Neurophysiological evidence suggests that neuromodulators, such as norepinephrine and dopamine, increase neural gain in target brain areas. Computational models and prominent theoretical frameworks indicate that this should enhance the precision of neural representations, but direct empirical evidence for this hypothesis is lacking. In two functional MRI studies, we examine the effect of baseline catecholamine levels (as indexed by pupil diameter and manipulated pharmacologically) on the precision of object representations in the human ventral temporal cortex using angular dispersion, a powerful, multivariate metric of representational similarity (precision). We first report the results of computational model simulations indicating that increasing catecholaminergic gain should reduce the angular dispersion, and thus increase the precision, of object representations from the same category, as well as reduce the angular dispersion of object representations from distinct categories when distinct-category representations overlap. In Study 1 (N = 24), we show that angular dispersion covaries with pupil diameter, an index of baseline catecholamine levels. In Study 2 (N = 24), we manipulate catecholamine levels and neural gain using the norepinephrine transporter blocker atomoxetine and demonstrate consistent, causal effects on angular dispersion and brain-wide functional connectivity. Despite the use of very different methods of examining the effect of baseline catecholamine levels, our results show a striking convergence and demonstrate that catecholamines increase the precision of neural representations. SIGNIFICANCE STATEMENT: Norepinephrine and dopamine are among the most widely distributed and ubiquitous neuromodulators in the mammalian brain and have a profound and pervasive impact on cognition. Baseline catecholamine levels tend to increase with increasing task engagement in tasks involving perceptual decisions, yet there is currently no direct evidence of the specific impact of these increases in catecholamine levels on perceptual encoding. Our results fill this void by showing that catecholamines enhance the precision of encoding cortical object representations, and by suggesting that this effect is mediated by increases in neural gain, thus offering a mechanistic account of our key finding.",
journal = "J. Neurosci.",
volume =  36,
number =  21,
pages = "5699--5708",
month =  "25~" # may,
year =  2016,
annote = "- Norepinephrine / Dopamine increase network gain, and thereby, increase the precision / reduce the dispersion of neural representations<div><br></div><div><br></div><div>- Measured both by pupil diameter, and by blocking NE/DA reuptake<br><div><br></div><div>- Gain increase is measured (among other) by increase in ``functional connectivity'' overall correlation b/w voxels, and in the clustering of this correlation matrix ! </div><div><br></div><div>- When DA/NE intervention fails to raise the gain as measured above, it also fails to increase precision / reduce dispersion</div></div>",
keywords = "catecholamine; dopamine; fMRI; norepinephrine; perception; psychopharmacology",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Parker2016-uu,
title = "Reward and choice encoding in terminals of midbrain dopamine neurons depends on striatal target",
author = "Parker, Nathan F and Cameron, Courtney M and Taliaferro, Joshua P and Lee, Junuk and Choi, Jung Yoon and Davidson, Thomas J and Daw, Nathaniel D and Witten, Ilana B",
affiliation = "Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, New Jersey, USA. Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, New Jersey, USA. Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, New Jersey, USA. Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, New Jersey, USA. Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, New Jersey, USA. Howard Hughes Medical Institute, University of California, San Francisco, San Francisco, California, USA. Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, New Jersey, USA. Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, New Jersey, USA.",
abstract = "Dopaminergic (DA) neurons in the midbrain provide rich topographic innervation of the striatum and are central to learning and to generating actions. Despite the importance of this DA innervation, it remains unclear whether and how DA neurons are specialized on the basis of the location of their striatal target. Thus, we sought to compare the function of subpopulations of DA neurons that target distinct striatal subregions in the context of an instrumental reversal learning task. We identified key differences in the encoding of reward and choice in dopamine terminals in dorsal versus ventral striatum: DA terminals in ventral striatum responded more strongly to reward consumption and reward-predicting cues, whereas DA terminals in dorsomedial striatum responded more strongly to contralateral choices. In both cases the terminals encoded a reward prediction error. Our results suggest that the DA modulation of the striatum is spatially organized to support the specialized function of the targeted subregion.",
journal = "Nat. Neurosci.",
month =  "25~" # apr,
year =  2016,
annote = "- DA neurons in VTA-SNc that project to NAcc and DMStri have different properties !<div><br></div><div>- NAcc-projecting neurons have much stronger responses to reward predictors (+ve for announcement of reward / -ve for no-reward)</div><div><br></div><div>- In both NAcc-projecting and DMS-projecting, response to reward predictors is an RPE: correlates positively with current reward, but negatively (with much smaller weight) to previous-trial reward !</div><div><br></div><div>- Both NAcc-projecting and DMS-projecting are excited by actions (nose poke, lever appearance) with roughly similar magnitude...</div><div><br></div><div>- .. However, the DMS-projecting (but NOT the NAcc-projecting) are lateralized, responding more strongly for contra-lateral movement ! </div><div><br></div><div><br></div>",
language = "en"
}

@ARTICLE{Haefner2016-pl,
title = "Perceptual {Decision-Making} as Probabilistic Inference by Neural Sampling",
author = "Haefner, Ralf M and Berkes, Pietro and Fiser, J\'{o}zsef",
affiliation = "Brain \& Cognitive Sciences, University of Rochester, Rochester, NY 14627, USA. Electronic address: ralf.haefner@gmail.com. Sloan-Swartz Center for Theoretical Neurobiology, Brandeis University, Waltham, MA 02454, USA. Department of Cognitive Science, Central European University, Budapest 1051, Hungary.",
abstract = "We address two main challenges facing systems neuroscience today: understanding the nature and function of cortical feedback between sensory areas and of correlated variability. Starting from the old idea of perception as probabilistic inference, we show how to use knowledge of the psychophysical task to make testable predictions for the influence of feedback signals on early sensory representations. Applying our framework to a two-alternative forced choice task paradigm, we can explain multiple empirical findings that have been hard to account for by the traditional feedforward model of sensory processing, including the task dependence of neural response correlations and the diverging time courses of choice probabilities and psychophysical kernels. Our model makes new predictions and characterizes a component of correlated variability that represents task-related information rather than performance-degrading noise. It demonstrates a normative way to integrate sensory and cognitive components into physiologically testable models of perceptual decision-making.",
journal = "Neuron",
volume =  90,
number =  3,
pages = "649--660",
month =  "4~" # may,
year =  2016,
annote = "- If you consider cortex like some sort of big Bayesian network, you can explain many things !<div><br></div><div>- In this framework, activities of V1 cells xi represent posterior probabilities, with p(xi / true-orientation) = exp. distr. with mean Gauss(xi's pref orientation - true orientation)</div><div><br></div><div>- Similarly, you include cells that represent posterior proba on actual orientation, and on the final choice (vert or horiz), with reciprocal connections</div><div><br></div><div>- Inference by sampling (? - see attached ArXiv paper that contains Supplementary Information)</div><div><br></div><div>- You can explain e.g. the structure of noise correlations b/w cells of different tunings, the decrease in stimulus-behavior correlation over course of trial, increase in choice probabilities for the xi/V1 cells..</div>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Collins2016-ci,
title = "Dynamic mesolimbic dopamine signaling during action sequence learning and expectation violation",
author = "Collins, Anne L and Greenfield, Venuz Y and Bye, Jeffrey K and Linker, Kay E and Wang, Alice S and Wassum, Kate M",
affiliation = "Dept. of Psychology, UCLA, Los Angeles, CA 90095, USA. Dept. of Psychology, UCLA, Los Angeles, CA 90095, USA. Dept. of Psychology, UCLA, Los Angeles, CA 90095, USA. Dept. of Psychology, UCLA, Los Angeles, CA 90095, USA. Dept. of Psychology, UCLA, Los Angeles, CA 90095, USA. Dept. of Psychology, UCLA, Los Angeles, CA 90095, USA. Brain Research Institute, UCLA, Los Angeles, CA 90095, USA.",
abstract = "Prolonged mesolimbic dopamine concentration changes have been detected during spatial navigation, but little is known about the conditions that engender this signaling profile or how it develops with learning. To address this, we monitored dopamine concentration changes in the nucleus accumbens core of rats throughout acquisition and performance of an instrumental action sequence task. Prolonged dopamine concentration changes were detected that ramped up as rats executed each action sequence and declined after earned reward collection. With learning, dopamine concentration began to rise increasingly earlier in the execution of the sequence and ultimately backpropagated away from stereotyped sequence actions, becoming only transiently elevated by the most distal and unexpected reward predictor. Action sequence-related dopamine signaling was reactivated in well-trained rats if they became disengaged in the task and in response to an unexpected change in the value, but not identity of the earned reward. Throughout training and test, dopamine signaling correlated with sequence performance. These results suggest that action sequences can engender a prolonged mode of dopamine signaling in the nucleus accumbens core and that such signaling relates to elements of the motivation underlying sequence execution and is dynamic with learning, overtraining and violations in reward expectation.",
journal = "Sci. Rep.",
volume =  6,
pages = "20231",
month =  "12~" # feb,
year =  2016,
annote = "- DA really is V.<div><br></div><div>- Rats learn to press two levers in sequence to get reward.</div><div><br></div><div>- Initial acquisition: DA spike at reward delivery</div><div><br></div><div>- During learning: develops ramping of DA from initial approach throughout the sequence performance</div><div><br></div><div>- At asymptote: maximal ramping</div><div><br></div><div>- At over-trained: no more ramping, DA looks flat ! BUT... There is now actually large DA increase at start of session, which was lower before.</div><div><br></div><div>- Also, DA ramping reappears after disorientation / disengagement</div><div><br></div><div>- Also if you change the value (but not the identity!) of the reward, you get new increase in DA </div><div><br></div><div>- Super compatible with the Hamid/Berke paper</div>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kennerley2011-ov,
title = "Double dissociation of value computations in orbitofrontal and anterior cingulate neurons",
author = "Kennerley, Steven W and Behrens, Timothy E J and Wallis, Jonathan D",
affiliation = "Institute of Neurology, University College London, London, UK. s.kennerley@ucl.ac.uk",
abstract = "Damage to prefrontal cortex (PFC) impairs decision-making, but the underlying value computations that might cause such impairments remain unclear. Here we report that value computations are doubly dissociable among PFC neurons. Although many PFC neurons encoded chosen value, they used opponent encoding schemes such that averaging the neuronal population extinguished value coding. However, a special population of neurons in anterior cingulate cortex (ACC), but not in orbitofrontal cortex (OFC), multiplexed chosen value across decision parameters using a unified encoding scheme and encoded reward prediction errors. In contrast, neurons in OFC, but not ACC, encoded chosen value relative to the recent history of choice values. Together, these results suggest complementary valuation processes across PFC areas: OFC neurons dynamically evaluate current choices relative to recent choice values, whereas ACC neurons encode choice predictions and prediction errors using a common valuation currency reflecting the integration of multiple decision parameters.",
journal = "Nat. Neurosci.",
volume =  14,
number =  12,
pages = "1581--1589",
month =  dec,
year =  2011,
annote = "<div>- Compares lPFC, OFC, and ACC.</div><div><br></div>- The figures and data are very confusing and difficult to understand, but basically:<div><br></div><div>- All areas encode 'value' (expected outcome, both during the choice stage and the outcome stage) and prediction errors, both positively and negatively correlated, but ACC has more.</div><div><br></div><div>- ACC in particular has a lot of positive prediction error detectors, which only fire if the reward was more than expected. </div><div><br></div><div>- Only ACC has substantial number of neurons that encode  across all three possible quantities (proba of reward, quantity of reward, effort to get reward), and they mostly use positive RPEs (only fire if more than expected)</div><div><br></div><div>- By contrast, in OFC, you see neurons that are negatively correlated with previous-trial outcome value</div><div><br></div><div>- They compute relative value of current trial wrt previous trial (this info is not just a lingering of previous firing, it only appears during the choice)</div>",
language = "en"
}

@ARTICLE{Kober2013-bl,
title = "Reinforcement Learning in Robotics: A Survey",
author = "Kober, Jens and Bagnell, J Andrew and Peters, Jan",
abstract = "Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and model-free as well as between value-function-based and policy-search methods. By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research.",
journal = "Int. J. Rob. Res.",
month =  "23~" # aug,
year =  2013,
annote = "10.1177/0278364913495721"
}

@ARTICLE{Rajan2016-yg,
title = "Recurrent Network Models of Sequence Generation and Memory",
author = "Rajan, Kanaka and Harvey, Christopher D and Tank, David W",
affiliation = "Joseph Henry Laboratories of Physics and Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ 08544, USA. Electronic address: krajan@princeton.edu. Department of Neurobiology, Harvard Medical School, Boston, MA 02115, USA. Electronic address: harvey@hms.harvard.edu. Department of Molecular Biology and Princeton Neuroscience Institute, Princeton University, Princeton, NJ 08544, USA. Electronic address: dwtank@princeton.edu.",
abstract = "Sequential activation of neurons is a common feature of network activity during a variety of behaviors, including working memory and decision making. Previous network models for sequences and memory emphasized specialized architectures in which a principled mechanism is pre-wired into their connectivity. Here we demonstrate that, starting from random connectivity and modifying a small fraction of connections, a largely disordered recurrent network can produce sequences and implement working memory efficiently. We use this process, called Partial In-Network Training (PINning), to model and match cellular resolution imaging data from the posterior parietal cortex during a virtual memory-guided two-alternative forced-choice task. Analysis of the connectivity reveals that sequences propagate by the cooperation between recurrent synaptic interactions and external inputs, rather than through feedforward or asymmetric connections. Together our results suggest that neural sequences may emerge through learning from largely unstructured network architectures.",
journal = "Neuron",
volume =  90,
number =  1,
pages = "128--142",
month =  "6~" # apr,
year =  2016,
language = "en"
}

@ARTICLE{Siegel2015-dg,
title = "Cortical information flow during flexible sensorimotor decisions",
author = "Siegel, Markus and Buschman, Timothy J and Miller, Earl K",
affiliation = "Centre for Integrative Neuroscience and MEG Center, University of T{\"{u}}bingen, T{\"{u}}bingen, Germany. Picower Institute for Learning and Memory and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. markus.siegel@uni-tuebingen.de. Picower Institute for Learning and Memory and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, NJ 08544, USA. Picower Institute for Learning and Memory and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA.",
abstract = "During flexible behavior, multiple brain regions encode sensory inputs, the current task, and choices. It remains unclear how these signals evolve. We simultaneously recorded neuronal activity from six cortical regions [middle temporal area (MT), visual area four (V4), inferior temporal cortex (IT), lateral intraparietal area (LIP), prefrontal cortex (PFC), and frontal eye fields (FEF)] of monkeys reporting the color or motion of stimuli. After a transient bottom-up sweep, there was a top-down flow of sustained task information from frontoparietal to visual cortex. Sensory information flowed from visual to parietal and prefrontal cortex. Choice signals developed simultaneously in frontoparietal regions and travelled to FEF and sensory cortex. This suggests that flexible sensorimotor choices emerge in a frontoparietal network from the integration of opposite flows of sensory and task information.",
journal = "Science",
volume =  348,
number =  6241,
pages = "1352--1355",
month =  "19~" # jun,
year =  2015,
annote = "- Record from all the things !<div><br></div><div>- A cue indicates whether to report motion or color</div><div><br></div><div>- Use two cues for each condition, presumably to separate cue information from task information (how is it done?)</div><div><br></div><div>- Surprise is that task information during the cue period appears first, very fast and transiently, in V4 and IT, then later in PFC and from there back to everywhere (IT \& V4 but also LIP , MT...)</div><div><br></div><div>- How do they measure task info as opposed to cue info? They compute selectivity B/W the two pairs of cues that signal task, and subtract the average of the selectivity to the two other possible separations of the 4 cues into 2 pairs (???? - so if the visual cells simply 'learn' to be more selective for the relevant pairs, that's task information?? )</div>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INBOOK{Rumelhart1986-ig,
title = "Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 2",
author = "Rumelhart, D E and McClelland, J L",
editor = "Rumelhart, David E and McClelland, James L and PDP Research Group, Corporate",
publisher = "MIT Press",
pages = "216--271",
chapter = "On Learning the Past Tenses of English Verbs",
year =  1986,
annote = "- The model for learning past tense of English verbs<div><br></div><div>- Children learn it in 3 phases: first individual pasts (everything is irregular), then they regularize everything, then finally they can handle both regular and irregular while spontaneously producing regulars for novel verbs.</div><div><br></div><div>- The model is extraordinarily simple - a 1-layer perceptron between input and output featural representations of words (no hidden units!)</div><div><br></div><div>- At first, the model learns one-to-one associations - everything is irregular</div><div><br></div><div>- Then, if there is an overwhelmingly present 'rule' in which units can co-activate depending on input co-activations, this rule takes over and initially wipes out the irregular associations - everything is regular</div><div><br></div><div>- Finally, the model learns enough that regular and irregular can coexist. </div><div><br></div><div><br></div><div>- [The featural representation is pretty involved, but roughly, it decomposes any word into series of items that encode a phoneme, its predecessor, and its successor[</div>",
address = "Cambridge, MA, USA"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cai2016-ip,
title = "A shared neural ensemble links distinct contextual memories encoded close in time",
author = "Cai, Denise J and Aharoni, Daniel and Shuman, Tristan and Shobe, Justin and Biane, Jeremy and Song, Weilin and Wei, Brandon and Veshkini, Michael and La-Vu, Mimi and Lou, Jerry and Flores, Sergio E and Kim, Isaac and Sano, Yoshitake and Zhou, Miou and Baumgaertel, Karsten and Lavi, Ayal and Kamata, Masakazu and Tuszynski, Mark and Mayford, Mark and Golshani, Peyman and Silva, Alcino J",
abstract = "Recent studies suggest that a shared neural ensemble may link distinct memories encoded close in time. According to the memory allocation hypothesis, learning triggers a temporary increase in neuronal excitability that biases the representation of a subsequent memory to the neuronal ensemble encoding the first memory, such that recall of one memory increases the likelihood of recalling the other memory. Here we show in mice that the overlap between the hippocampal CA1 ensembles activated by two distinct contexts acquired within a day is higher than when they are separated by a week. Several findings indicate that this overlap of neuronal ensembles links two contextual memories. First, fear paired with one context is transferred to a neutral context when the two contexts are acquired within a day but not across a week. Second, the first memory strengthens the second memory within a day but not across a week. Older mice, known to have lower CA1 excitability, do not show the overlap between ensembles, the transfer of fear between contexts, or the strengthening of the second memory. Finally, in aged mice, increasing cellular excitability and activating a common ensemble of CA1 neurons during two distinct context exposures rescued the deficit in linking memories. Taken together, these findings demonstrate that contextual memories encoded close in time are linked by directing storage into overlapping ensembles. Alteration of these processes by ageing could affect the temporal structure of memories, thus impairing efficient recall of related information.",
journal = "Nature",
publisher = "Nature Publishing Group",
month =  "23~" # may,
year =  2016,
annote = "- Contexts/memories learned in quick succession are encoded by overlapping neural ensembles !<div><br></div><div>- Known that learning increases  subsequent excitability in the CA1 population that encodes this memory</div><div><br></div><div>- In mouse hippocampus CA1, if you learn 2 environments 5 hours apart, they will be encoded by overlapping CA1 populations, but not if you learn them 7 days apart</div><div><br></div><div>- As a result, shocks in the former environment transfer to freezing in the latter (where no shock occurred)!</div><div><br></div><div>- But memory is still specific - you can extinguish freezing in the latter without extinguishing the former</div><div><br></div><div>- Related to increased excitability - absent in older mice, under specifically rescued.</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Christiansen1999-hi,
title = "Toward a connectionist model of recursion in human linguistic performance",
author = "Christiansen, Morten H and Chater, Nick",
abstract = "Naturally occurring speech contains only a limited amount of complex recursive structure, and this is reflected in the empirically documented difficulties that people experience when processing such structures. We present a connectionist model of human performance in processing recursive language structures. The model is trained on simple artificial languages. We find that the qualitative performance profile of the model matches human behavior, both on the relative difficulty of center-embedding and cross-dependency, and between the processing of these complex recursive structures and right-branching recursive constructions. We analyze how these differences in performance are reflected in the internal representations of the model by performing discriminant analyses on these representations both before and after training. Furthermore, we show how a network trained to process recursive structures can also generate such structures in a probabilistic fashion. This work suggests a novel explanation of people’s limited recursive performance, without assuming the existence of a mentally represented competence grammar allowing unbounded recursion.",
journal = "Cogn. Sci.",
volume =  23,
number =  2,
pages = "157--205",
month =  apr,
year =  1999,
annote = "<div>- Recursion in human languages is actually quite restricted in depth ! Even 1-level recursion can produce very difficult-to-read sentence</div><div><br></div>- Early simple recurrent neural networks  with just 2 hidden units can be trained to complete aaabbb - and generalize to unseen number of letters !<div><br></div><div>- With a more complex RNN you can learn more complex stuff like centered recursion (aABb, where case denotes plurality agreement).</div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Marcus1995-cv,
title = "German inflection: the exception that proves the rule",
author = "Marcus, G F and Brinkmann, U and Clahsen, H and Wiese, R and Pinker, S",
affiliation = "Dept. of Psychology, University of Massachusetts, Amherst 01003, USA.",
abstract = "Language is often explained as the product of generative rules and a memorized lexicon. For example, most English verbs take a regular past tense suffix (ask-asked), which is applied to new verbs (faxed, wugged), suggesting the mental rule ``add -ed to a Verb.'' Irregular verbs (break-broke, go-went) would be listed in memory. Alternatively, a pattern associator memory (such as a connectionist network) might record all past tense forms and generalize to new ones by similarity; irregular and regular patterns would differ only because of their different numbers of verbs. We present evidence that mental rules are indispensible. A rule concatenates a suffix to a symbol for verbs, so it does not require access to memorized verbs or their sound patterns, but applies as the ``default,'' whenever memory access fails. We find 21 such circumstances for regular past tense formation, including novel, unusual-sounding, and rootless and headless derived words; in every case, people inflect them regularly (explaining quirks like flied out, sabre-tooths, walkmans). Contrary to the connectionist account, these effects are not due to regular words constituting a large majority of vocabulary. The German participle -t applies to a much smaller percentage of verbs than its English counterpart, and the German plural -s applies to a small minority of nouns. But the affixes behave in the language like their English counterparts, as defaults. We corroborate this effect in two experiments eliciting ratings of participle and plural forms of novel German words. Thus default suffixation is not due to numerous regular words reinforcing a pattern in associative memory. Because default cases do not occupy a cohesive similarity space, but do correspond to the range of a symbol, they are evidence for a memory-independent, symbol-concatenating mental operation.",
journal = "Cogn. Psychol.",
volume =  29,
number =  3,
pages = "189--256",
month =  dec,
year =  1995,
annote = "- Argues that the learning of inflections (past tenses of verbs, plurals of nouns) cannot result simply from associative memory through repeated exposure (as in the McClelland model), but requires a symbolic rule manipulation system<div><br></div><div>- (Also stress the important ambiguity of the term ``rule'': it can mean ``majority pattern'', or it can mean ``freely generalizable pattern'' - the latter, they say,cannot be extracted solely from the former?) </div><div><br></div><div>- The crucial point is not so much the irregular (which do actually show strong associative memory effects), but the regulars, which seem to require a ``default'' rule (-ed / -s), which applies in a broad set of cases that can be predicted by a few principles !</div><div><br></div><div>- In particular, 5 principles  (a- lexicaon is organized by roots, b-similar roots evoke similar behaviors through associative memory c- inflection info about a root only applies if that root is the 'head' of the word d- mental grammar has 'default' endings that apply unless preempted by item in lexicon memory) explain all the 21 cases where regular trumps irregular, and 5 situations where the opposite is true !!</div><div><br></div><div>- Also use the example of German, where the 'default' rules (-s plural, -t past tense) are the vast minority, thus can't be explained as a result of being the largest class.</div><div><br></div><div>- Explicitly say that this is not about connectionism, and that connectionist systems could be devised to do all this - it's just against the McClelland associative-memory-only model - also they say that ymbolic is better because it can capture all that without specially designed connectivity or training set (but wait, the set of principles *is* an ad hoc, specially-devised mechanism!)</div><div><br></div><div>- They even suggest a brief sketch of a connectionist model that could do the default thing.</div><div><br></div><div>- [ Of course the ideal would be if a connectionist model could automatically learn and discover the rule set. Which it can do, using reward! In fact one could say that Hebbian-associative and reward-instructive are two complementary ways of shaping connectivity, and the problem with Marcus is that they seem to assume that the only connectionist learning principle is the Hebbian-associative ! ]</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Namboodiri2015-ek,
title = "Visually cued action timing in the primary visual cortex",
author = "Namboodiri, Vijay Mohan K and Huertas, Marco A and Monk, Kevin J and Shouval, Harel Z and Hussain Shuler, Marshall G",
affiliation = "The Solomon H. Snyder Department of Neuroscience, The Johns Hopkins University, Baltimore, MD 21205, USA. Department of Neurobiology and Anatomy, University of Texas - Houston, Houston, TX 77030, USA. The Solomon H. Snyder Department of Neuroscience, The Johns Hopkins University, Baltimore, MD 21205, USA. Department of Neurobiology and Anatomy, University of Texas - Houston, Houston, TX 77030, USA. The Solomon H. Snyder Department of Neuroscience, The Johns Hopkins University, Baltimore, MD 21205, USA. Electronic address: shuler@jhmi.edu.",
abstract = "Most behaviors are generated in three steps: sensing the external world, processing that information to instruct decision-making, and producing a motor action. Sensory areas, especially primary sensory cortices, have long been held to be involved only in the first step of this sequence. Here, we develop a visually cued interval timing task that requires rats to decide when to perform an action following a brief visual stimulus. Using single-unit recordings and optogenetics in this task, we show that activity generated by the primary visual cortex (V1) embodies the target interval and may instruct the decision to time the action on a trial-by-trial basis. A spiking neuronal model of local recurrent connections in V1 produces neural responses that predict and drive the timing of future actions, rationalizing our observations. Our data demonstrate that the primary visual cortex may contribute to the instruction of visually cued timed actions.",
journal = "Neuron",
volume =  86,
number =  1,
pages = "319--330",
month =  "8~" # apr,
year =  2015,
annote = "- Rat V1 neurons instruct the timing of delayed action !! V1 Does Everything !<div><br></div><div>- Rats must lick at a fixed, optimal delay from a visual cue stimulus</div><div><br></div><div>- Some V1 neurons maintain response (neg or pos) throughout the delay, mostly for a duration equal to the average optimal interval (as previously shown)!</div><div><br></div><div>- A subset of these actually correlate to action timing on a trial-to-trial basis </div><div><br></div><div>- Some fire upon the lick time ! Actually seem to instruct the action  (e.g. not on erroneous visually-independent response, eye-of-cue-dependent, etc.)</div><div><br></div><div>- Optogenetic perturbation in V1 delays action</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Schuck2015-na,
title = "Medial prefrontal cortex predicts internally driven strategy shifts",
author = "Schuck, Nicolas W and Gaschler, Robert and Wenke, Dorit and Heinzle, Jakob and Frensch, Peter A and Haynes, John-Dylan and Reverberi, Carlo",
affiliation = "Princeton Neuroscience Institute, Princeton University, Princeton, NJ 08544, USA; Department of Psychology, Humboldt-Universit{\"{a}}t zu Berlin, 10099 Berlin, Germany; Center for Lifespan Psychology, Max Planck Institute for Human Development, 14195 Berlin, Germany. Electronic address: nschuck@princeton.edu. Department of Psychology, Humboldt-Universit{\"{a}}t zu Berlin, 10099 Berlin, Germany; Department of Psychology, Universit{\"{a}}t Koblenz-Landau, 76829 Landau in der Pfalz, Germany. Department of Psychology, Humboldt-Universit{\"{a}}t zu Berlin, 10099 Berlin, Germany. Translational Neuromodeling Unit (TNU), Institute for Biomedical Engineering, University of Zurich and Swiss Federal Institute of Technology (ETH), 8032 Zurich, Switzerland; Bernstein Center for Computational Neuroscience, Charit\'{e}-Universit{\"{a}}tsmedizin Berlin, 10115 Berlin, Germany. Department of Psychology, Humboldt-Universit{\"{a}}t zu Berlin, 10099 Berlin, Germany. Bernstein Center for Computational Neuroscience, Charit\'{e}-Universit{\"{a}}tsmedizin Berlin, 10115 Berlin, Germany; Max Planck Institute for Human Cognitive and Brain Sciences, 04103 Leipzig, Germany; Department of Neurology, Otto-von-Guericke University, 30106 Magdeburg, Germany. Bernstein Center for Computational Neuroscience, Charit\'{e}-Universit{\"{a}}tsmedizin Berlin, 10115 Berlin, Germany; Department of Psychology, University of Milano-Bicocca, 20126 Milano, Italy; Milan Center for Neuroscience, 20126 Milano, Italy. Electronic address: carlo.reverberi@unimib.it.",
abstract = "Many daily behaviors require us to actively focus on the current task and ignore all other distractions. Yet, ignoring everything else might hinder the ability to discover new ways to achieve the same goal. Here, we studied the neural mechanisms that support the spontaneous change to better strategies while an established strategy is executed. Multivariate neuroimaging analyses showed that before the spontaneous change to an alternative strategy, medial prefrontal cortex (MPFC) encoded information that was irrelevant for the current strategy but necessary for the later strategy. Importantly, this neural effect was related to future behavioral changes: information encoding in MPFC was changed only in participants who eventually switched their strategy and started before the actual strategy change. This allowed us to predict spontaneous strategy shifts ahead of time. These findings suggest that MPFC might internally simulate alternative strategies and shed new light on the organization of PFC.",
journal = "Neuron",
volume =  86,
number =  1,
pages = "331--340",
month =  "8~" # apr,
year =  2015,
annote = "- mPFC (including ACC!) seems to encode information that is relevant to an imminent strategy shift, without the subject's conscious awareness?...<div><br></div><div>[Human fMRI]</div><div><br></div><div>- Task: tell position of a stimulus. Unbeknownst to subjects, after a while, color (which is much more obvious than position) becomes yoked to position. 31\% of subjects detect it and now use color to respond.</div><div><br></div><div>- mPFC (including ACC) only encodes color immediately before the switch of strategy !  lPFC encodes it afterwards.</div><div><br></div><div>- Apparently mPFC encoding precedes conscious awareness of the relation...</div>"
}

@ARTICLE{Lake2015-lh,
title = "Human-level concept learning through probabilistic program induction",
author = "Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B",
affiliation = "Center for Data Science, New York University, 726 Broadway, New York, NY 10003, USA. brenden@nyu.edu. Department of Computer Science and Department of Statistics, University of Toronto, 6 King's College Road, Toronto, ON M5S 3G4, Canada. Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA 02139, USA.",
abstract = "People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms-for action, imagination, and explanation. We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world's alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. We also present several ``visual Turing tests'' probing the model's creative generalization abilities, which in many cases are indistinguishable from human behavior.",
journal = "Science",
volume =  350,
number =  6266,
pages = "1332--1338",
month =  "11~" # dec,
year =  2015
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Stanislas_Dehaene2016-aa,
title = "Decoding the Dynamics of Conscious Perception: The Temporal Generalization Method - Springer",
booktitle = "Micro-, Meso- and {Macro-Dynamics} of the Brain",
author = "Stanislas Dehaene, Jean-Re´mi King",
editor = "G. Buzsaki, Y Christen",
publisher = "Springer",
year =  2016,
annote = "- EEG/MEG of auditory sequence with local vs. global deviants<div><br></div><div>- At 1st presentation of AAAB, B evokes both MisMatch Negativity and P3b</div><div>- With successive presentations, only MMN remains</div><div>- Then when you show AAAA (global deviant), P3b alone evoked !</div><div><br></div><div>- Cross-temporal decoding of local deviance and global deviance</div><div><br></div><div>- Encoding of local deviance lasts for ~200ms (on the diagonal), is highly dynamic (dark 'wings', little outside diagonal)</div><div><br></div><div>- By contrast, encoding of global deviance is durable and (after a little bit of initial waggling?) quite stable - big red square</div><div><br></div><div>- Local deviance is also encoded (faintly !) during sleep ! Can cross-decode b/w sleep and wake. Global deviance is not </div><div><br></div><div>- Stable, 'squarish' encodings are posited as a mark of reaching consciousness - the global worspace</div><div><br></div><div>- Conscious perception corresponds to entry into the Global Neuronal Workspace, composed of a big network of frontal, parietal and temporal cortex, which stabilizes transient sensory information.</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Arnsten2014-gz,
title = "Molecular influences on working memory circuits in dorsolateral prefrontal cortex",
author = "Arnsten, Amy F T and Jin, Lu E",
affiliation = "Department of Neurobiology, Yale University School of Medicine, New Haven, Connecticut, USA. Department of Neurobiology, Yale University School of Medicine, New Haven, Connecticut, USA.",
abstract = "The working memory circuits of the primate dorsolateral prefrontal cortex (dlPFC) are modulated in a unique manner, often opposite to the molecular mechanisms needed for long-term memory consolidation. Working memory, our ``mental sketch pad'' is an ephemeral process, whereby transient, mental representations form the foundation for abstract thought. The microcircuits that generate mental representations are found in deep layer III of the dlPFC, where pyramidal cells excite each other to keep information ``in mind'' through NMDA receptor synapses on spines. The catecholaminergic and cholinergic arousal systems have rapid and flexible influences on the strength of these connections, thus allowing coordination between arousal and cognitive states. These modulators can rapidly weaken connectivity, for example, as occurs during uncontrollable stress, via feedforward calcium-cAMP signaling opening potassium (K(+)) channels near synapses on spines. Lower levels of calcium-cAMP-K(+) channel signaling provide negative feedback within recurrent excitatory circuits, and help to gate inputs to shape the contents of working memory. There are also explicit mechanisms to inhibit calcium-cAMP signaling and strengthen connectivity, for example, postsynaptic $\alpha$2A-adrenoceptors on spines. This work has led to the development of the $\alpha$2A agonist, guanfacine, for the treatment of a variety of dlPFC disorders. In mental illness, there are a variety of genetic insults to the molecules that normally serve to inhibit calcium-cAMP signaling in spines, thus explaining why so many genetic insults can lead to the same phenotype of impaired dlPFC cognitive function. Thus, the molecular mechanisms that provide mental flexibility may also confer vulnerability when dysregulated in cognitive disorders.",
journal = "Prog. Mol. Biol. Transl. Sci.",
volume =  122,
pages = "211--231",
year =  2014,
annote = "<div>- dlPFC may be to actions and thoughts what vmPFC and OFC are to emotions and values?</div><div><br></div><div><br></div><div>[ Summary:</div><div><br></div><div>- Delay cell firing maintained by recurrent NMDAR-dependent excitation between similarly-tuned Pyramidal neurons in deep L3, shaped by mutual inhibition between differently-tuned groups</div><div><br></div><div>- L3 Pyr connect through long, slender spines, ideal for fast, dynamic connectivity regulation by neuromodulators</div><div><br></div><div>- Varying levels of the same modulators can have different effects through differential recruiting of different receptors</div><div><br></div><div>- NE alpha1 receptors decrease connectivity, while NE alpha2 receptor agonists (like quanfacine) improve it</div><div><br></div><div>- D1R at very low and very high level kill delay response.</div><div><br></div><div>- At intermediate concentration, small increase in D1R activation improves signal to noise ratio by selectively decreasing response to non-preferred direction !</div><div><br></div><div>]</div><div><br></div>- The visual-memory dlPFC area is area 46.<div><br></div><div>- Some neurons encode Target location in the delay, but others encode Response, Fixation and Cue - not treated here.</div><div><br></div><div>- Memory neurons with similar tuning excite each other recurrently, which creates sustained NMDAR-dependent firing</div><div><br></div><div>- Neuron tuning is shaped by GABA, which are excited by ``dissimilar'' tuning Pyrs (hmmm, does it mean the GABA are also tuned and connect to anti-tuned?)</div><div><br></div><div>- The relevant NMDAR are strictly synaptic, as opposed to HPC or sensory cortex where they can be extrasynaptic ??\textbackslash{}</div><div><br></div><div>- AMPAR contribute a little to Delay cells, but much more to Response cells. Ketamine blocks delay cells, but increases response cells??</div><div><br></div><div>- ``Arousal systems include catecholamine, Ach, serotonin, orexin and histamines'' !  All project to dlPFC.</div><div><br></div><div>- Usually respond to salient events, but can go on tonic overdrive in high uncontrollable stress / danger</div><div><br></div><div>- Different levels of neuromodulators (e.g. NE) have distinct effects due to distinct selective receptor recruitment</div><div><br></div><div>- Apparently, catecholamines + ACh more important in dlPFC, serotonin more important in OFC ??</div><div><br></div><div>- L2/3 Pyr of PFC connect through long slender dendrites, ideal for dynamic modulation of connectivity (timescale of seconds)</div><div><br></div><div>- Can take dlPFC ``offline'' so more primitive circuits can take over during danger? </div><div><br></div><div>- Activate ``Ca2+-cAMP signalling'' takes off dlPFC. Inhibiting it strengthens task-related firing .</div><div><br></div><div>- NE activation of alpha1A-AR decreases dlPFC firing. Conversely, alpha2A-AR (adrenergic) increase dlPFC firing, improves cognition (!), blocking them collapses it, reduces WM and self-control ?</div><div><br></div><div>- Translational application: guanfacine (alpha2-AR agonist) as a medicine for ADHD ! </div><div><br></div><div>- Also, nic-alpha7R improve connectivity, presumably by facilitating NMDAR (much like they facilitate AMPAR in sensory and HPC circuits?). Muscarinic receptors also increase connectivity (so both ACh ).</div><div><br></div><div><br></div><div>- `` D1R stim regulates the breadth of inputs'' - uh?</div><div><br></div><div>- No DA is as bad as removing CTX ! D1R stim has inverted-U shape, facilitating connectivity/firing for intermediate range, decreasing it at low and high extremes.</div><div><br></div><div>- Small delivery of D1R agonists decrease Delay cell response to non-preferred direction, leaves preferred response intact !!</div><div><br></div><div>- Too much D1R reduces firing and impairs WM.</div><div><br></div>",
keywords = "Calcium; Cognition; Dopamine; HCN channels; KCNQ channels; Norepinephrine; Schizophrenia; Stress; cAMP"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tritsch2012-fj,
title = "Dopaminergic modulation of synaptic transmission in cortex and striatum",
author = "Tritsch, Nicolas X and Sabatini, Bernardo L",
affiliation = "Howard Hughes Medical Institute, Department of Neurobiology, Harvard Medical School, Boston, MA 02115, USA.",
abstract = "Among the many neuromodulators used by the mammalian brain to regulate circuit function and plasticity, dopamine (DA) stands out as one of the most behaviorally powerful. Perturbations of DA signaling are implicated in the pathogenesis or exploited in the treatment of many neuropsychiatric diseases, including Parkinson's disease (PD), addiction, schizophrenia, obsessive compulsive disorder, and Tourette's syndrome. Although the precise mechanisms employed by DA to exert its control over behavior are not fully understood, DA is known to regulate many electrical and biochemical aspects of neuronal function including excitability, synaptic transmission, integration and plasticity, protein trafficking, and gene transcription. In this Review, we discuss the actions of DA on ionic and synaptic signaling in neurons of the prefrontal cortex and striatum, brain areas in which dopaminergic dysfunction is thought to be central to disease.",
journal = "Neuron",
volume =  76,
number =  1,
pages = "33--50",
month =  "4~" # oct,
year =  2012,
annote = "- Effects of Dopamine : It's complicated !<div><br></div><div>- DA can affect proba of transmitter release, postsyn sensitivity to transmitter, and pre- and post-syn cell excitability !</div><div><br></div><div>- Striatum has many GABA interneurons (which integrate CTX input and preferentially target dSPNs over iSPNs)and a population of cholinergic interneurons that respond to salient stimuli by a (DA-dependent!) pause with or without rebound.</div><div><br></div><div>- In PFC, DA innervation is densest in the deep layers. D2 in particular is pretty sparse in l2/3. Most neurons may not be DA-modulated, even in deep layers. </div><div><br></div><div>`` D1 receptor mRNA is expressed in approximately
20\% of layer L2/3 and L5 and in 40\% of L6 pyramidal cells (Table
2). By contrast, D2 receptor mRNA is only sparsely detected
in superficial layer pyramidal neurons (5\% in L2/3) and in 25\%
and 13\% of L5 and L6 pyramidal cells''</div><div><br></div><div>- Local PFC interneurons have proportionally more likely to have DA receptors ! 60\% of PV have D1R. Fewer have D2R.</div><div><br></div><div><br></div><div>-  in general, D1R and D2R activation both reduce probability of presynaptic transmitter release - for Gu, GABA, Ach (but with variations across areas)</div><div>- But several reports of increase in neurotransmitter release with D1R/D2R agonists !</div><div><br></div><div>- D1R potentiates NMDA receptors. D2R don't directly modulate NMDA EPSCs, but decrese their effects downstream (?)</div><div><br></div><div>- D1R agonists and D2R antagonists positively affect AMPA receptors while D2R agonists negatively affect them... but apparently this is not sufficient to modify AMPA EPSCs ! (perhaps because it needs another mechanism)</div><div><br></div><div>- In Striatum, D1R (present in dSPN) favors excitability, while D2R (present in iSPN) reduce it</div><div><br></div><div>- In cortex, DA modulates excitability of both pyramidal and interneurons</div><div><br></div><div>- D1R seems to potentiate deep-layer Pyramidal neurons. Maybe.</div><div><br></div><div>- DA in PFC strikingly increases GABA interneuron firing !</div>"
}

@ARTICLE{Marder2012-xm,
title = "Neuromodulation of neuronal circuits: back to the future",
author = "Marder, Eve",
affiliation = "Biology Department and Volen Center, Brandeis University, Waltham, MA 02454, USA. marder@brandeis.edu",
abstract = "All nervous systems are subject to neuromodulation. Neuromodulators can be delivered as local hormones, as cotransmitters in projection neurons, and through the general circulation. Because neuromodulators can transform the intrinsic firing properties of circuit neurons and alter effective synaptic strength, neuromodulatory substances reconfigure neuronal circuits, often massively altering their output. Thus, the anatomical connectome provides a minimal structure and the neuromodulatory environment constructs and specifies the functional circuits that give rise to behavior.",
journal = "Neuron",
volume =  76,
number =  1,
pages = "1--11",
month =  "4~" # oct,
year =  2012,
annote = "- Neuromodulation is super important and has massive effects on small circuits (e.g. crustacean stomach ganglion)<div><br></div><div>- Neuromodulator can mess with currents, synaptic strength, etc. and generally affect almost all behavior of a cell or circuit<br><div><br></div><div>- Circuits are modulated by multiple neuromodulators, both local and external</div><div><br></div><div>- Different neuromodulators lead to different cycles in small circuit - but they all generate a cycle.</div><div>- Neurons containing the same neuromodulator can have wildly different effects, due in part to different co transmitters</div><div><br></div><div>- Neuromodulators can ``join'' circuits by strengthening the synapses that link them, uniting them in a common rhythm !</div><div><br></div><div>- Different modulators can alter the baseline or the amplitude of an oscillation independently !</div><div><br></div></div><div>- Every synapse has its strength subject to neuromodulation in complex, neuron=specific manner ?</div><div><br></div><div>- Various mechanisms (saturation, modulation of complementary / opposing targets, voltage dependence) stabilize the effects of neuromodulation</div><div><br></div><div>- Even then, the same modulator application can have different effect on different individuals (much like drugs in humans)</div><div><br></div><div>- Connectome is only the start !</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mishra2016-mw,
title = "Symmetric spike timing-dependent plasticity at {CA3-CA3} synapses optimizes storage and recall in autoassociative networks",
author = "Mishra, Rajiv K and Kim, Sooyun and Guzman, Segundo J and Jonas, Peter",
journal = "Nat. Commun.",
publisher = "Nature Publishing Group",
volume =  7,
month =  "13~" # may,
year =  2016,
annote = "- Wow. STDP at CA3-CA3 recurrent hippocampus synapses is actually not ``normal'' STDP at all - it's symmetric !<div><br></div><div>- Fire together, wire together, independently of who is first or second? </div><div><br></div><div>- Broad time window, ~150ms</div><div><br></div><div>- Should compare with the Siegelbaum and other hippocampus plasticity mechanisms...?</div>"
}

@ARTICLE{Timme2016-re,
title = "{High-Degree} Neurons Feed Cortical Computations",
author = "Timme, Nicholas M and Ito, Shinya and Myroshnychenko, Maxym and Nigam, Sunny and Shimono, Masanori and Yeh, Fang-Chin and Hottowy, Pawel and Litke, Alan M and Beggs, John M",
affiliation = "Department of Physics, Indiana University, Bloomington, Indiana, United States of America. Santa Cruz Institute for Particle Physics, University of California at Santa Cruz, Santa Cruz, California, United States of America. Program in Neuroscience, Indiana University, Bloomington, Indiana, United States of America. Department of Physics, Indiana University, Bloomington, Indiana, United States of America. MGH/HST Athinoula A. Martinos Center, Harvard Medical School, Charlestown, Massachusetts, United States of America. Department of Neuroscience and Behavioral Disorders, Duke-NUS Graduate Medical School, Singapore. Physics and Applied Computer Science, AGH University of Science and Technology, Krakow, Poland. Santa Cruz Institute for Particle Physics, University of California at Santa Cruz, Santa Cruz, California, United States of America. Department of Physics, Indiana University, Bloomington, Indiana, United States of America.",
abstract = "Recent work has shown that functional connectivity among cortical neurons is highly varied, with a small percentage of neurons having many more connections than others. Also, recent theoretical developments now make it possible to quantify how neurons modify information from the connections they receive. Therefore, it is now possible to investigate how information modification, or computation, depends on the number of connections a neuron receives (in-degree) or sends out (out-degree). To do this, we recorded the simultaneous spiking activity of hundreds of neurons in cortico-hippocampal slice cultures using a high-density 512-electrode array. This preparation and recording method combination produced large numbers of neurons recorded at temporal and spatial resolutions that are not currently available in any in vivo recording system. We utilized transfer entropy (a well-established method for detecting linear and nonlinear interactions in time series) and the partial information decomposition (a powerful, recently developed tool for dissecting multivariate information processing into distinct parts) to quantify computation between neurons where information flows converged. We found that computations did not occur equally in all neurons throughout the networks. Surprisingly, neurons that computed large amounts of information tended to receive connections from high out-degree neurons. However, the in-degree of a neuron was not related to the amount of information it computed. To gain insight into these findings, we developed a simple feedforward network model. We found that a degree-modified Hebbian wiring rule best reproduced the pattern of computation and degree correlation results seen in the real data. Interestingly, this rule also maximized signal propagation in the presence of network-wide correlations, suggesting a mechanism by which cortex could deal with common random background input. These are the first results to show that the extent to which a neuron modifies incoming information streams depends on its topological location in the surrounding functional network.",
journal = "PLoS Comput. Biol.",
volume =  12,
number =  5,
pages = "e1004858",
month =  may,
year =  2016,
annote = "- Uses an interesting definition of ``computation'' performed by a Neuron, namely ``synergy''.<br><div><br></div><div>- (Rat slice)</div><div><br></div><div>- The synergy is computed by using both conditional MI (conditioning on past of the output neuron) and some measure of ``redundancy'' between various inputs - the redundancy measure is pretty tricky...</div><div><br></div><div>- You just subtract redundancy, unique info from conditional MI to get the synergy</div><div><br></div><div>- Interesting, but maximal for XOR, which is certainly a computation but a lousy one.</div><div><br></div><div>- Main finding: ``<span style=''font-family: arial; line-height: 18px; word-spacing: normal;``>More specifically, the neurons that compute the most information tend to receive inputs from high-degree neurons. The in-degree of a neuron, however, has no relationship to the amount of information it computes.''</span></div>"
}

@ARTICLE{Visser2016-pp,
title = "Quantifying learning-dependent changes in the brain: Single-trial multivoxel pattern analysis requires slow event-related {fMRI}",
author = "Visser, Ren\'{e}e M and de Haan, Michelle I C and Beemsterboer, Tinka and Haver, Pia and Kindt, Merel and Scholte, H Steven",
affiliation = "Department of Clinical Psychology, University of Amsterdam, Amsterdam, The Netherlands. Amsterdam Brain and Cognition (ABC), Amsterdam, The Netherlands. Medical Research Council-Cognition and Brain Sciences Unit, Cambridge, UK. Amsterdam Brain and Cognition (ABC), Amsterdam, The Netherlands. Department of Psychiatry, Academic Medical Centre, University of Amsterdam, Amsterdam, The Netherlands. Spinoza Centre for Neuroimaging, University of Amsterdam, Amsterdam, The Netherlands. Spinoza Centre for Neuroimaging, University of Amsterdam, Amsterdam, The Netherlands. Department of Clinical Psychology, University of Amsterdam, Amsterdam, The Netherlands. Amsterdam Brain and Cognition (ABC), Amsterdam, The Netherlands. Amsterdam Brain and Cognition (ABC), Amsterdam, The Netherlands. Spinoza Centre for Neuroimaging, University of Amsterdam, Amsterdam, The Netherlands. Department of Brain and Cognition, University of Amsterdam, Amsterdam, The Netherlands.",
abstract = "Single-trial analysis is particularly useful for assessing cognitive processes that are intrinsically dynamic, such as learning. Studying these processes with fMRI is problematic, as the low signal-to-noise ratio of fMRI requires the averaging over multiple trials, obscuring trial-by-trial changes in neural activation. The superior sensitivity of multivoxel pattern analysis over univariate analyses has opened up new possibilities for single-trial analysis, but this may require different fMRI designs. Here, we measured fMRI and pupil dilation responses during discriminant aversive conditioning, to assess associative learning in a trial-by-trial manner. The impact of design choices was examined by varying trial spacing and trial order in a series of five experiments (total n = 66), while keeping stimulus duration constant (4.5 s). Our outcome measure was the change in similarity between neural response patterns related to two consecutive presentations of the same stimulus (within-stimulus) and between patterns related to pairs of different stimuli (between-stimulus) that shared a specific outcome (electric stimulation vs. no consequence). This trial-by-trial similarity analysis revealed clear single-trial learning curves in conditions with intermediate (8.1-12.6 s) and long (16.5-18.4 s) intervals, with effects being strongest in designs with long intervals and counterbalanced stimulus presentation. No learning curves were observed in designs with shorter intervals (1.6-6.1 s), indicating that rapid event-related designs-at present, the most common designs in fMRI research-are not suited for single-trial pattern analysis. These findings emphasize the importance of deciding on the type of analysis prior to data collection.",
journal = "Psychophysiology",
month =  "6~" # may,
year =  2016,
annote = "- You can do MVPA fMRI to assess learning in single trials, but only if you use long intervals...<div><br></div><div><br></div><div>- [... maybe, possibly, didn't actually read]</div>",
keywords = "Associative learning; Aversive conditioning; Multivoxel pattern analysis; Representational similarity analysis; Single-trial fMRI"
}


@ARTICLE{Barbour2007-az,
title = "What can we learn from synaptic weight distributions?",
author = "Barbour, Boris and Brunel, Nicolas and Hakim, Vincent and Nadal, Jean-Pierre",
affiliation = "Laboratoire de Neurobiologie (CNRS UMR 8544), Ecole Normale Sup\'{e}rieure, 46 rue d'Ulm, 75005 Paris, France. barbour@ens.fr",
abstract = "Much research effort into synaptic plasticity has been motivated by the idea that modifications of synaptic weights (or strengths or efficacies) underlie learning and memory. Here, we examine the possibility of exploiting the statistics of experimentally measured synaptic weights to deduce information about the learning process. Analysing distributions of synaptic weights requires a theoretical framework to interpret the experimental measurements, but the results can be unexpectedly powerful, yielding strong constraints on possible learning theories as well as information that is difficult to obtain by other means, such as the information storage capacity of a cell. We review the available experimental and theoretical techniques as well as important open issues.",
journal = "Trends Neurosci.",
volume =  30,
number =  12,
pages = "622--629",
month =  dec,
year =  2007
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wacongne2012-jc,
title = "A neuronal model of predictive coding accounting for the mismatch negativity",
author = "Wacongne, Catherine and Changeux, Jean-Pierre and Dehaene, Stanislas",
affiliation = "Commissariat \`{a} l'Energie Atomique, DSV/I2BM, NeuroSpin Center, F-91191 Gif/Yvette, France, University Paris 11, F-91405 Orsay, France. catherine.wacongne@gmail.com",
abstract = "The mismatch negativity (MMN) is thought to index the activation of specialized neural networks for active prediction and deviance detection. However, a detailed neuronal model of the neurobiological mechanisms underlying the MMN is still lacking, and its computational foundations remain debated. We propose here a detailed neuronal model of auditory cortex, based on predictive coding, that accounts for the critical features of MMN. The model is entirely composed of spiking excitatory and inhibitory neurons interconnected in a layered cortical architecture with distinct input, predictive, and prediction error units. A spike-timing dependent learning rule, relying upon NMDA receptor synaptic transmission, allows the network to adjust its internal predictions and use a memory of the recent past inputs to anticipate on future stimuli based on transition statistics. We demonstrate that this simple architecture can account for the major empirical properties of the MMN. These include a frequency-dependent response to rare deviants, a response to unexpected repeats in alternating sequences (ABABAA…), a lack of consideration of the global sequence context, a response to sound omission, and a sensitivity of the MMN to NMDA receptor antagonists. Novel predictions are presented, and a new magnetoencephalography experiment in healthy human subjects is presented that validates our key hypothesis: the MMN results from active cortical prediction rather than passive synaptic habituation.",
journal = "J. Neurosci.",
volume =  32,
number =  11,
pages = "3665--3678",
month =  "14~" # mar,
year =  2012,
annote = "- Computational model of the MisMatch Negativity / Oddball increased response, based on predictive coding.<div><br></div><div>- Suggests that L4 is prediction error layer, L2/3 is the prediction error (which predicts future stimuli based on input from a memory source) that inhibits L4</div><div><br></div><div>- The memory source here is just 400 delay-line neurons, thus 400ms memory of past stimuli (note that predicted stimuli still produce a feedforward activation, just less)</div><div><br></div><div>- STDP from memory to L2/3 : connections from memory slots to L2/3 encode conditional probability of having each L2/3 neur firing when input at time t-n was X...</div><div><br></div><div>- Explains also non-repetition responses, and even omission responses, unlike habituation / adaptation / synaptic depression accounts.</div><div><br></div><div>- Insensitive to more global, long-term regularities, only cares about transition probabilities from 1 stim to the next - as expected !</div><div><br></div><div>- PROBLEM : requires FAST stdp to learn ongoing stats. Weird...</div><div>- Better to assume that there are cells selective to any </div>"
}

@ARTICLE{Howard2016-id,
title = "Converging prefrontal pathways support associative and perceptual features of conditioned stimuli",
author = "Howard, James D and Kahnt, Thorsten and Gottfried, Jay A",
journal = "Nat. Commun.",
publisher = "Nature Publishing Group",
volume =  7,
month =  "4~" # may,
year =  2016,
annote = "- Interesting example of what you can do with fMRI...<div><br></div><div>- Task: subject learn to associate 2 among 4 olfactory stimuli with monetary reward (there are 2 categories of stimuli, one in each is rewarded).</div><div><br></div><div>- Piriform cortex encodes stimulus category. OFC encodes stimulus identity. vmPFC encodes stimulus value [at least at the scale detectable by MVPA].</div><div><br></div><div>- Of course this might simply mean that identity encoding in PC occurs at a scale that confounds MVPA.</div><div><br></div><div>- Also, learning leads to a change in connectivity: OFC -> vmPFC ++ , specifically for the rewarded stimuli.</div><div><br></div>"
}

@ARTICLE{Kremkow2016-oc,
title = "Principles underlying sensory map topography in primary visual cortex",
author = "Kremkow, Jens and Jin, Jianzhong and Wang, Yushi and Alonso, Jose M",
affiliation = "Graduate Center for Vision Research, State University of New York, College of Optometry, 33 West 42nd Street, New York, New York 10036, USA. Graduate Center for Vision Research, State University of New York, College of Optometry, 33 West 42nd Street, New York, New York 10036, USA. Graduate Center for Vision Research, State University of New York, College of Optometry, 33 West 42nd Street, New York, New York 10036, USA. Graduate Center for Vision Research, State University of New York, College of Optometry, 33 West 42nd Street, New York, New York 10036, USA.",
abstract = "The primary visual cortex contains a detailed map of the visual scene, which is represented according to multiple stimulus dimensions including spatial location, ocular dominance and stimulus orientation. The maps for spatial location and ocular dominance arise from the spatial arrangement of thalamic afferent axons in the cortex. However, the origins of the other maps remain unclear. Here we show that the cortical maps for orientation, direction and retinal disparity in the cat (Felis catus) are all strongly related to the organization of the map for spatial location of light (ON) and dark (OFF) stimuli, an organization that we show is OFF-dominated, OFF-centric and runs orthogonal to ocular dominance columns. Because this ON-OFF organization originates from the clustering of ON and OFF thalamic afferents in the visual cortex, we conclude that all main features of visual cortical topography, including orientation, direction and retinal disparity, follow a common organizing principle that arranges thalamic axons with similar retinotopy and ON-OFF polarity in neighbouring cortical regions.",
journal = "Nature",
month =  "27~" # apr,
year =  2016,
annote = "<div>d- Highly detailed study of retinotopic V1 Cat maps for ON/OFF, orientation, binocular, etc.</div><div><br></div><div>- Orientation preference rotation seems to be caused by ON thalamic-input domains rotating around an OFF thalamic-input domain 'anchor' as you move through the cortex</div><div><br></div><div>(They seem to be measuring the responses of 'sites')</div><div><br></div><div>- So the OFF center RF moves slowly as you move across cortex, and the ON centers rotate around it ....</div><div><br></div>- Explains also direction preference, because the weaker inputs have a delay !"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Huth2016-js,
title = "Natural speech reveals the semantic maps that tile human cerebral cortex",
author = "Huth, Alexander G and de Heer, Wendy A and Griffiths, Thomas L and Theunissen, Fr\'{e}d\'{e}ric E and Gallant, Jack L",
journal = "Nature",
publisher = "Nature Publishing Group",
volume =  532,
number =  7600,
pages = "453--458",
month =  "27~" # apr,
year =  2016,
annote = "- First: get a word embedding to encode words into semantically-distant K-size vectors (each dimension in the vector is number of co-occurrences with a certain 'basis word' over a massive corpus)<div><br></div><div>- Second: regress the activity of each voxel on the vector of the just-heard word (with delays, and covariates to account for low-level processes)</div><div><br></div><div>- This gives you K regression weights for each voxel</div><div><br></div><div>- Do PCA over all the weights ! That gives you K dimensions, or 'semantic directions'. The first 4 capture much of the variance.</div><div><br></div><div>- So the probable effect of any given word on all the brain can be summarized mostly by 4 numbers, capturing semantic dimensions..</div><div><br></div><div>- Then you can map each voxel in the brain by which PC its weights are most aligned to, giving a semantic atlas of the brain </div><div><br></div><div>- PC1 is apparently social vs perceptual, etc.</div><div><br></div><div>- Insanely reproducible zones of specific colors...</div><div><br></div><div>- [ Problems? How to account for dumb emotional-attentional effects? E.g. you get a big red patch in the auditory cortex, suggesting that these are mostly modulated by PC1... ]</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Bourdoukan2012-xt,
title = "Learning optimal spike-based representations",
booktitle = "Advances in Neural Information Processing Systems 25",
author = "Bourdoukan, Ralph and Barrett, David and Deneve, Sophie and Machens, Christian K",
editor = "Pereira, F and Burges, C J C and Bottou, L and Weinberger, K Q",
publisher = "Curran Associates, Inc.",
pages = "2285--2293",
year =  2012,
annote = "- Derives learning rule to build the Deneve networks<div><br></div><div><div>- Seems to require that the input be x + dx/dt ?? </div><div><br></div><div>- Gives optimal values for thresholds and resets ! (in the simple case of just trying to track a single input with self-inhibition)</div><div><br></div><div>- Single neuron with inhibitory autapse:   the inhibitory autapse learns by minimizing loss function x* - x), which somehow simplifies to just (squared)  potential V! (makes sense since V is basically the estimate of the error...)</div></div><div><br></div><div>- Multiple neurons: now loss function is x*-x + total-firing (i.e. regularized w/ activation penalty)</div><div><br></div><div>- Now the learning ruls is basically (inhibitory-)Hebbian: dWi->j ~= Vj*firing(i)</div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Deneve2016-oh,
title = "Efficient codes and balanced networks",
author = "Den\`{e}ve, Sophie and Machens, Christian K",
affiliation = "Laboratoire de Neurosciences Cognitives, \'{E}cole Normale Sup\'{e}rieure, Paris, France. Champalimaud Centre for the Unknown, Lisbon, Portugal.",
abstract = "Recent years have seen a growing interest in inhibitory interneurons and their circuits. A striking property of cortical inhibition is how tightly it balances excitation. Inhibitory currents not only match excitatory currents on average, but track them on a millisecond time scale, whether they are caused by external stimuli or spontaneous fluctuations. We review, together with experimental evidence, recent theoretical approaches that investigate the advantages of such tight balance for coding and computation. These studies suggest a possible revision of the dominant view that neurons represent information with firing rates corrupted by Poisson noise. Instead, tight excitatory/inhibitory balance may be a signature of a highly cooperative code, orders of magnitude more precise than a Poisson rate code. Moreover, tight balance may provide a template that allows cortical neurons to construct high-dimensional population codes and learn complex functions of their inputs.",
journal = "Nat. Neurosci.",
volume =  19,
number =  3,
pages = "375--382",
month =  "23~" # feb,
year =  2016,
annote = "- Poisson rate-coding seems silly - error scales w/ 1 / sqrt(NbSpikes) rather than 1/NbSpikes minimum.<div><br></div><div>- Loosely balanced E/I creates irregular firing and allows for rate-based coding (firing rate follows E input)</div><div>- Some evidence for it</div><div>- Note: Inhibitory plasticity is real, both homeostatic and fine-tuned (e.g. in A1). PRedicted by Vogels' inhibitory STDP !</div><div><br></div><div>- But E/I also seems correlated on very short timescales, e.g. Gamma oscillations, ; also, nearby neurons have highly correlated membrane potentials, despite uncorrelated spiking</div><div><br></div><div>- Renart: dense connectivity = tight balance. Vogels: inhib STDP = tight balance.</div><div><br></div><div>- Deneve model: tight inhibition allows for precise spike-coding of real-valued input</div><div>- If input is x(t), (smoothed) output is estimate x*(t), just put a feedback inhib, and the total input will be x(t) - x*(t) - i.e. the error ! So neurons will only fire if (negative!) error becomes large !</div><div><br></div><div>- [Hmmm, requires that the input be x + dx/dt ?? ]</div><div><br></div><div>[- Bourdoukan implement sthe learning... in the inhibitory autapse... simple loss function: error is minimized by minimizing potential V! (makes sense since V is basically the estimate of the error...)]</div><div><br></div><div>- The representation can be spread over multiple neurons which automatically coordinate to jointly track the signal !</div><div>- For multi-dimensional input, just make E and I similarly tuned for each neuron (?) </div><div><br></div><div>- What about more complex computations on input / memory? Then you need slow excitatory recurrent synapses. </div><div>- Cites the Lim papers about negative-feedback - apparently that's based on the same principle</div><div><br></div><div>- You can also build a oscillator, in which each neuron fires at a specific phase and a readout computes the oscillation</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Noroozi2016-pg,
title = "Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles",
author = "Noroozi, Mehdi and Favaro, Paolo",
abstract = "In this paper we study the problem of image representation learning without human annotation. Following the principles of self-supervision, we build a convolutional neural network (CNN) that can be trained to solve Jigsaw puzzles as a pretext task, which requires no manual labeling, and then later repurposed to solve object classification and detection. To maintain the compatibility across tasks we introduce the context-free network (CFN), a Siamese-ennead CNN. The CFN takes image tiles as input and explicitly limits the receptive field (or context) of its early processing units to one tile at a time. We show that the CFN is a more compact version of AlexNet, but with the same semantic learning capabilities. By training the CFN to solve Jigsaw puzzles, we learn both a feature mapping of object parts as well as their cor-rect spatial arrangement. Our experimental evaluations show that the learned features capture semantically relevant content. The performance in object detection of features extracted from the CFN is the highest (51.8\%) among unsupervisedly trained features, and very close to that of supervisedly trained features (56.5\%). In object classification the CFN features achieve also the best accuracy (38.1\%) among unsupervisedly trained features on the ImageNet 2012 dataset.",
month =  "30~" # mar,
year =  2016,
annote = "<div><span style=``word-spacing: normal; line-height: 1.5em;''>- Use jigsaw-puzzle learning as a powerful, fast *unsupervised* method for training CNNs, which can then be used for classification, object detection, etc.</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Divide the image into 3x3 patches (with gaps), then feed random rearrangement of patches and train the network to produce the correct order (i.e. position vector) </span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Each patch is processed through the whole AlexNet-like network (?...)</span></div>",
archivePrefix = "arXiv",
primaryClass = "cs.CV",
eprint = "1603.09246"
}

@ARTICLE{Thelen2003-ji,
title = "Adjustment of muscle mechanics model parameters to simulate dynamic contractions in older adults",
author = "Thelen, Darryl G",
affiliation = "Department of Mechanical Engineering, University of Wisconsin-Madison, Madison, WI 53706-1572, USA.",
abstract = "The generation of muscle-actuated simulations that accurately represent the movement of old adults requires a model that accounts for changes in muscle properties that occur with aging. An objective of this study was to adjust the parameters of Hill-type musculo-tendon models to reflect nominal age-related changes in muscle mechanics that have been reported in the literature. A second objective was to determine whether using the parametric adjustments resulted in simulated dynamic ankle torque behavior similar to that seen in healthy old adults. The primary parameter adjustment involved decreasing maximum isometric muscle forces to account for the loss of muscle mass and specific strength with age. A review of the literature suggested the need for other modest adjustments that account for prolonged muscular deactivation, a reduction in maximum contraction velocity, greater passive muscle stiffness and increased normalized force capacity during lengthening contractions. With age-related changes incorporated, a musculo-tendon model was used to simulate isometric and isokinetic contractions of ankle plantarflexor and dorsiflexor muscles. The model predicted that ankle plantarflexion power output during 120 deg/s shortening contractions would be over 40\% lower in old adults compared to healthy young adults. These power losses with age exceed the 30\% loss in isometric strength assumed in the model but are comparable to 39-44\% reductions in ankle power outputs measured in healthy old adults of approximately 70 years of age. Thus, accounting for age-related changes in muscle properties, other than decreased maximum isometric force, may be particularly important when simulating movements that require substantial power development.",
journal = "J. Biomech. Eng.",
volume =  125,
number =  1,
pages = "70--77",
month =  feb,
year =  2003
}

@ARTICLE{Saul2015-su,
title = "Benchmarking of dynamic simulation predictions in two software platforms using an upper limb musculoskeletal model",
author = "Saul, Katherine R and Hu, Xiao and Goehler, Craig M and Vidt, Meghan E and Daly, Melissa and Velisar, Anca and Murray, Wendy M",
affiliation = "a Mechanical and Aerospace Engineering Department , North Carolina State University , Raleigh , NC 27695 , USA.",
abstract = "Several opensource or commercially available software platforms are widely used to develop dynamic simulations of movement. While computational approaches are conceptually similar across platforms, technical differences in implementation may influence output. We present a new upper limb dynamic model as a tool to evaluate potential differences in predictive behavior between platforms. We evaluated to what extent differences in technical implementations in popular simulation software environments result in differences in kinematic predictions for single and multijoint movements using EMG- and optimization-based approaches for deriving control signals. We illustrate the benchmarking comparison using SIMM-Dynamics Pipeline-SD/Fast and OpenSim platforms. The most substantial divergence results from differences in muscle model and actuator paths. This model is a valuable resource and is available for download by other researchers. The model, data, and simulation results presented here can be used by future researchers to benchmark other software platforms and software upgrades for these two platforms.",
journal = "Comput. Methods Biomech. Biomed. Engin.",
volume =  18,
number =  13,
pages = "1445--1458",
year =  2015,
keywords = "biomechanics; computational modeling; medical computing; musculoskeletal; neuromuscular"
}

@ARTICLE{Holzbaur2005-zb,
title = "A model of the upper extremity for simulating musculoskeletal surgery and analyzing neuromuscular control",
author = "Holzbaur, Katherine R S and Murray, Wendy M and Delp, Scott L",
affiliation = "Mechanical Engineering Department, Stanford University, Stanford, California 94305, USA.",
abstract = "Biomechanical models of the musculoskeletal system are frequently used to study neuromuscular control and simulate surgical procedures. To be broadly applicable, a model must be accessible to users, provide accurate representations of muscles and joints, and capture important interactions between joints. We have developed a model of the upper extremity that includes 15 degrees of freedom representing the shoulder, elbow, forearm, wrist, thumb, and index finger, and 50 muscle compartments crossing these joints. The kinematics of each joint and the force-generating parameters for each muscle were derived from experimental data. The model estimates the muscle-tendon lengths and moment arms for each of the muscles over a wide range of postures. Given a pattern of muscle activations, the model also estimates muscle forces and joint moments. The moment arms and maximum moment-generating capacity of each muscle group (e.g., elbow flexors) were compared to experimental data to assess the accuracy of the model. These comparisons showed that moment arms and joint moments estimated using the model captured important features of upper extremity geometry and mechanics. The model also revealed coupling between joints, such as increased passive finger flexion moment with wrist extension. The computer model is available to researchers at http://nmbl.stanford.edu.",
journal = "Ann. Biomed. Eng.",
volume =  33,
number =  6,
pages = "829--840",
month =  jun,
year =  2005
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Vicente2016-hb,
title = "Direct and indirect dorsolateral striatum pathways reinforce different action strategies",
author = "Vicente, Ana M and Galv\~{a}o-Ferreira, Pedro and Tecuapetla, Fatuel and Costa, Rui M",
journal = "Curr. Biol.",
publisher = "Elsevier",
volume =  26,
number =  7,
pages = "R267--R269",
month =  "4~" # apr,
year =  2016,
annote = "<div>- Stim of indirect pathway MSNs in DLS is NOT aversive - it seems to generate indiscriminate motivation/response increase? </div><div><br></div>- Self-stimulation paradigm in DLStri, separately for MSNs with direct (D1) and indirect (D2) receptors<div><br></div><div>- 2 levers, one delivers stimulation, other does nothing</div><div><br></div><div>- If stimulate D1: fast increase specifically for active lever presses, goes away if contingency degraded, reinstated after contingency reinstated</div><div><br></div><div>- If lever stimulates D2: slow Increase in BOTH lever presses, doesn't go away when contingency degrades.</div><div><br></div>"
}

@ARTICLE{Grosmark2016-du,
title = "Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences",
author = "Grosmark, Andres D and Buzs\'{a}ki, Gy{\"{o}}rgy",
affiliation = "Department of Neuroscience, Columbia University Medical Center, New York, NY 10019, USA. The Neuroscience Institute, School of Medicine, New York University, New York, NY 10016, USA. The Neuroscience Institute, School of Medicine, New York University, New York, NY 10016, USA. Center for Neural Science, New York University, New York, NY 10016, USA. gyorgy.buzsaki@nyumc.org.",
abstract = "Cell assembly sequences during learning are ``replayed'' during hippocampal ripples and contribute to the consolidation of episodic memories. However, neuronal sequences may also reflect preexisting dynamics. We report that sequences of place-cell firing in a novel environment are formed from a combination of the contributions of a rigid, predominantly fast-firing subset of pyramidal neurons with low spatial specificity and limited change across sleep-experience-sleep and a slow-firing plastic subset. Slow-firing cells, rather than fast-firing cells, gained high place specificity during exploration, elevated their association with ripples, and showed increased bursting and temporal coactivation during postexperience sleep. Thus, slow- and fast-firing neurons, although forming a continuous distribution, have different coding and plastic properties.",
journal = "Science",
volume =  351,
number =  6280,
pages = "1440--1443",
month =  "25~" # mar,
year =  2016
}

@ARTICLE{Peters2008-zw,
title = "Reinforcement learning of motor skills with policy gradients",
author = "Peters, Jan and Schaal, Stefan",
affiliation = "Max Planck Institute for Biological Cybernetics, Spemannstrasse 38, T{\"{u}}bingen, Germany. jan.peters@tuebingen.mpg.de",
abstract = "Autonomous learning is one of the hallmarks of human and animal behavior, and understanding the principles of learning will be crucial in order to achieve true autonomy in advanced machines like humanoid robots. In this paper, we examine learning of complex motor skills with human-like limbs. While supervised learning can offer useful tools for bootstrapping behavior, e.g., by learning from demonstration, it is only reinforcement learning that offers a general approach to the final trial-and-error improvement that is needed by each individual acquiring a skill. Neither neurobiological nor machine learning studies have, so far, offered compelling results on how reinforcement learning can be scaled to the high-dimensional continuous state and action spaces of humans or humanoids. Here, we combine two recent research developments on learning motor control in order to achieve this scaling. First, we interpret the idea of modular motor control by means of motor primitives as a suitable way to generate parameterized control policies for reinforcement learning. Second, we combine motor primitives with the theory of stochastic policy gradient learning, which currently seems to be the only feasible framework for reinforcement learning for humanoids. We evaluate different policy gradient methods with a focus on their applicability to parameterized motor primitives. We compare these algorithms in the context of motor primitive learning, and show that our most modern algorithm, the Episodic Natural Actor-Critic outperforms previous algorithms by at least an order of magnitude. We demonstrate the efficiency of this reinforcement learning method in the application of learning to hit a baseball with an anthropomorphic robot arm.",
journal = "Neural Netw.",
volume =  21,
number =  4,
pages = "682--697",
month =  may,
year =  2008
}

@ARTICLE{Lee2016-pv,
title = "Anatomy and function of an excitatory network in the visual cortex",
author = "Lee, Wei-Chung Allen and Bonin, Vincent and Reed, Michael and Graham, Brett J and Hood, Greg and Glattfelder, Katie and Reid, R Clay",
affiliation = "Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA. Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA. Neuro-Electronics Research Flanders, a research initiative by imec, Vlaams Instituut voor Biotechnologie (VIB) and Katholieke Universiteit (KU) Leuven, 3001 Leuven, Belgium. Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA. Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA. Biomedical Applications Group, Pittsburgh Supercomputing Center, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213, USA. Allen Institute for Brain Science, Seattle, Washington 98103, USA. Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA. Allen Institute for Brain Science, Seattle, Washington 98103, USA.",
abstract = "Circuits in the cerebral cortex consist of thousands of neurons connected by millions of synapses. A precise understanding of these local networks requires relating circuit activity with the underlying network structure. For pyramidal cells in superficial mouse visual cortex (V1), a consensus is emerging that neurons with similar visual response properties excite each other, but the anatomical basis of this recurrent synaptic network is unknown. Here we combined physiological imaging and large-scale electron microscopy to study an excitatory network in V1. We found that layer 2/3 neurons organized into subnetworks defined by anatomical connectivity, with more connections within than between groups. More specifically, we found that pyramidal neurons with similar orientation selectivity preferentially formed synapses with each other, despite the fact that axons and dendrites of all orientation selectivities pass near (<5 $\mu$m) each other with roughly equal probability. Therefore, we predict that mechanisms of functionally specific connectivity take place at the length scale of spines. Neurons with similar orientation tuning formed larger synapses, potentially enhancing the net effect of synaptic specificity. With the ability to study thousands of connections in a single circuit, functional connectomics is proving a powerful method to uncover the organizational logic of cortical networks.",
journal = "Nature",
month =  "28~" # mar,
year =  2016,
annote = "<div>- confirms the Mrsic-Flogel stuff</div><div><br></div><div>- Similar-tuning neuron preferentially excite each other...</div><div><br></div><div>- ... above and beyond what could be expected from simple proximity !</div><div><br></div><div>- Apparently the mutually excitatory subnetworks of similarly-tune neurons are really formed by selective synapses, because the anatomical ``potential connections'' seem to be all-to-all !</div><div><br></div><div>- Confirms the model</div><div><br></div>"
}

@ARTICLE{Lundqvist2016-no,
title = "Gamma and Beta Bursts Underlie Working Memory",
author = "Lundqvist, Mikael and Rose, Jonas and Herman, Pawel and Brincat, Scott L and Buschman, Timothy J and Miller, Earl K",
journal = "Neuron",
publisher = "Elsevier",
volume =  0,
number =  0,
month =  "17~" # mar,
year =  2016,
annote = "<div>- See also Stokes 2016</div><div><br></div>- PUNCHLINE: Working memory is maintained by brief bursts of spiking+gamma power, reflecting transient activations of weak attractors, NOT by sustained, extended increases in firing (which only show up as an artifact of averaging over many trials)!<div><br></div><div>[ Not sure if the two are mutually exclusive, or if their data actually shows that?... Crucial Q: is the firing rate of Delay cells at baseline outside of the Gamma bursts? Not sure they show that...]<br><div><br></div><div>- Task: must remember location and color of 2 or 3 stimuli</div><div><br></div><div>- During stimuli presentation, Gamma increases (and Beta decreases), but only at sites where spiking contains information about stimuli !</div><div><br></div><div>- Gamma increases occur in very short bursts. At informative sites only, bursting rate increases during stimulus presentations, and then slowly re-increases during the delay period - So does gamma power. (burst rate grows w/ number of stimuli encoded)</div><div><br></div><div>- Gamma power modulated by lower-freq , but only because the bursts have a stereotyped duration - they're NOT periodic ! (xcorr: no side peaks).</div><div><br></div><div>- Furthermore, some informative neurons peak during stimulus, while other peak during delay. Even if you only select the former (``early''), you see a strong increase in burst rates in the delay ! Also, Gamma power perfectly tracks the burst rate of ``early'', NOT ``late'' neurons !</div><div><br></div><div>- [It seems that these ``late'' neurons are the actual ``Delay'' cells, while the burst/gamma-aligned neurons are the ``cue'' cells ?]</div><div>- [Info about stimuli is larger in the ``late'', non-gamma-tracking cells during delay! ]</div><div>- [Increase in burst rate during late delay in the gamma-tracking, ``early'', cue-like cells may simply be a general anticipatory effect...? They do control by using a second task where there is no test stimulus, still see the late increase, but may be anticipation of motor task itself]</div><div>- [They say the gamma-tracking, cue-like cells are ``encoding/decoding'' cells, while the late-/delay-like cells are ``Maintenance'' cells...]</div><div>- [Certainly these two seem co-located, as non-gamma-modulated sites have basically no info about stimulus at any time of the trial, despite only slightly lower overall firing rates - Fig. 3A]</div><div>- [But note that burst is defined as 2SD Gamma power above *trial* mean, which suggests maintenance/delay cells also follow the brief-bursts pattern, so the main conclusion still applies?]</div><div>- [Critical Q: Is firing at baseline outside of the Gamma bubbles?]</div></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Jocham2016-oj,
title = "{Reward-Guided} Learning with and without Causal Attribution",
author = "Jocham, Gerhard and Brodersen, Kay H and Constantinescu, Alexandra O and Kahn, Martin C and Ianni, Angela M and Walton, Mark E and Rushworth, Matthew F S and Behrens, Timothy E J",
affiliation = "Oxford Centre for Functional MRI of the Brain, Nuffield Department of Clinical Neurosciences, University of Oxford, John Radcliffe Hospital, Oxford OX3 9DU, UK; Center for Behavioral Brain Sciences, Otto-von-Guericke-Universit{\"{a}}t Magdeburg, Universit{\"{a}}tsplatz 2, 39106 Magdeburg, Germany; Faculty of Economics and Management, Otto-von-Guericke-Universit{\"{a}}t Magdeburg, Universit{\"{a}}tsplatz 2, 39106 Magdeburg, Germany. Electronic address: jocham@ovgu.de. Oxford Centre for Functional MRI of the Brain, Nuffield Department of Clinical Neurosciences, University of Oxford, John Radcliffe Hospital, Oxford OX3 9DU, UK; Department of Experimental Psychology, University of Oxford, South Parks Road, Oxford OX1 3UD, UK. Electronic address: khbrodersen@gmail.com. Oxford Centre for Functional MRI of the Brain, Nuffield Department of Clinical Neurosciences, University of Oxford, John Radcliffe Hospital, Oxford OX3 9DU, UK. Oxford Centre for Functional MRI of the Brain, Nuffield Department of Clinical Neurosciences, University of Oxford, John Radcliffe Hospital, Oxford OX3 9DU, UK. Oxford Centre for Functional MRI of the Brain, Nuffield Department of Clinical Neurosciences, University of Oxford, John Radcliffe Hospital, Oxford OX3 9DU, UK; Section on Integrative Neuroimaging, Clinical and Translational Neuroscience Branch, National Institute of Mental Health, National Institutes of Health, Intramural Research Program, Department of Health and Human Services, Bethesda, MD 20892, USA. Department of Experimental Psychology, University of Oxford, South Parks Road, Oxford OX1 3UD, UK. Department of Experimental Psychology, University of Oxford, South Parks Road, Oxford OX1 3UD, UK. Oxford Centre for Functional MRI of the Brain, Nuffield Department of Clinical Neurosciences, University of Oxford, John Radcliffe Hospital, Oxford OX3 9DU, UK; Wellcome Trust Centre for Neuroimaging, University College London, 12 Queen Square, London WC1N 3BG, UK.",
abstract = "When an organism receives a reward, it is crucial to know which of many candidate actions caused this reward. However, recent work suggests that learning is possible even when this most fundamental assumption is not met. We used novel reward-guided learning paradigms in two fMRI studies to show that humans deploy separable learning mechanisms that operate in parallel. While behavior was dominated by precise contingent learning, it also revealed hallmarks of noncontingent learning strategies. These learning mechanisms were separable behaviorally and neurally. Lateral orbitofrontal cortex supported contingent learning and reflected contingencies between outcomes and their causal choices. Amygdala responses around reward times related to statistical patterns of learning. Time-based heuristic mechanisms were related to activity in sensorimotor corticostriatal circuitry. Our data point to the existence of several learning mechanisms in the human brain, of which only one relies on applying known rules about the causal structure of the task.",
journal = "Neuron",
month =  "9~" # mar,
year =  2016,
annote = "- There are several ways to learn from rewards<div><br></div><div>- One is the normal, 'contingent' way - you learn which precise stimuli are associated with reward</div><div><br></div><div>- But there are other, less precise ways!</div><div>- 'Proximity' learning: reward (Even those you know are just random) make it more likely that the recent choices will be chosen again </div><div>- 'Statistical' learning: reward (even those you know are just random) lead to more future selection of the option you selected more in the past</div><div><br></div><div>- lOFC lesions are known to damage contingent learning, favor non-contingent learning</div><div><br></div><div>- They find that lOFC + VS favor contingent learning. </div><div><br></div><div>- Amygdala activity during a reward makes it less likely to be treated as contigent, more likely to cause statistical + proximity learning</div><div><br></div><div>- Something about the dlStriatum + VTA .... Seems to favor proximal learning?</div>"
}

@ARTICLE{Churchland2014-ww,
title = "A Dynamical Basis Set for Generating Reaches",
author = "Churchland, Mark M and Cunningham, John P",
affiliation = "Department of Neuroscience, Grossman Center for the Statistics of Mind, David Mahoney Center for Brain and Behavior Research, Kavli Institute for Brain Science, Columbia University Medical Center, New York, New York 10032 mc3502@columbia.edu. Department of Statistics, Grossman Center for the Statistics of Mind, Center for Theoretical Neuroscience, Institute for Data Science and Engineering, Columbia University, New York, New York 10027.",
abstract = "The motor cortex was the one of the first cortical areas to be explored electrophysiologically, yet little agreement has emerged regarding its basic response properties. Often it is assumed that single-neuron responses reflect a preference for a particular movement or movement variable. It may be further assumed that movement is generated by (or at least accompanied by) a growing population-level preference for the relevant movement. This view has been attractive because it provides a canonical form for the single neuron, a link between preparatory and movement activity, a way of interpreting the population response, and a platform for designing analyses and couching hypotheses. However, this traditional view yields predictions that are at odds with basic features of the data. We discuss an alternative simplified model, in which outgoing commands are produced by dynamics that generate different output patterns as a function of the initial preparatory state. For reaching tasks, we hypothesized simple quasioscillatory dynamics because they provide a natural basis set for the empirical patterns of muscle activity. The predictions of the dynamical model match the data well at both the single-neuron and population levels, and the quasioscillatory patterns explain many of the otherwise odd features of the neural responses.",
journal = "Cold Spring Harb. Symp. Quant. Biol.",
volume =  79,
pages = "67--80",
year =  2014
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cheung2016-ae,
title = "The auditory representation of speech sounds in human motor cortex",
author = "Cheung, Connie and Hamiton, Liberty S and Johnson, Keith and Chang, Edward F",
affiliation = "Graduate Program in Bioengineering, University of California, Berkeley-University of California, San Francisco, San Francisco, United States. Department of Neurological Surgery, University of California, San Francisco, San Francisco, United States. Center for Integrative Neuroscience, University of California, San Francisco, San Francisco, United States. Department of Physiology, University of California, San Francisco, San Francisco, United States. Department of Neurological Surgery, University of California, San Francisco, San Francisco, United States. Center for Integrative Neuroscience, University of California, San Francisco, San Francisco, United States. Department of Physiology, University of California, San Francisco, San Francisco, United States. Department of Linguistics, University of California, Berkeley, Berkeley, United States. Graduate Program in Bioengineering, University of California, Berkeley-University of California, San Francisco, San Francisco, United States. Department of Neurological Surgery, University of California, San Francisco, San Francisco, United States. Center for Integrative Neuroscience, University of California, San Francisco, San Francisco, United States. Department of Physiology, University of California, San Francisco, San Francisco, United States.",
abstract = "In humans, listening to speech evokes neural responses in the motor cortex. This has been controversially interpreted as evidence that speech sounds are processed as articulatory gestures. However, it is unclear what information is actually encoded by such neural activity. We used high-density direct human cortical recordings while participants spoke and listened to speech sounds. Motor cortex neural patterns during listening were substantially different than during articulation of the same sounds. During listening, we observed neural activity in the superior and inferior regions of ventral motor cortex. During speaking, responses were distributed throughout somatotopic representations of speech articulators in motor cortex. The structure of responses in motor cortex during listening was organized along acoustic features similar to auditory cortex, rather than along articulatory features as during speaking. Motor cortex does not contain articulatory representations of perceived actions in speech, but rather, represents auditory vocal information.",
journal = "Elife",
volume =  5,
year =  2016,
annote = "<div>[- Neat application of human ECoG in high-gamma range as an MUA alternative]</div><div><br></div>- Motor cortex is activated during speech audition...<div><br></div><div>- But this activation is not articulatory: activity during listening does not resemble activity during speaking</div><div><br></div><div>- Activity in motor cortex during speaking clusters according to articulation features; but during listening, it clusters (less strongly than auditory, but still) according to acoustic features of stimulus </div><div><br></div><div>- So motor cortex activation during listening to speech is basically an acoustic input, not a reproduction of motor articulation </div>",
keywords = "auditory; human; motor cortex; motor theory; neuroscience; speech"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Song2016-hh,
title = "Training {Excitatory-Inhibitory} Recurrent Neural Networks for Cognitive Tasks: A Simple and Flexible Framework",
author = "Song, H Francis and Yang, Guangyu R and Wang, Xiao-Jing",
affiliation = "Center for Neural Science, New York University, New York, New York, United States of America. Center for Neural Science, New York University, New York, New York, United States of America. Center for Neural Science, New York University, New York, New York, United States of America. NYU-ECNU Institute of Brain and Cognitive Science, NYU Shanghai, Shanghai, China.",
abstract = "The ability to simultaneously record from large numbers of neurons in behaving animals has ushered in a new era for the study of the neural circuit mechanisms underlying cognitive functions. One promising approach to uncovering the dynamical and computational principles governing population responses is to analyze model recurrent neural networks (RNNs) that have been optimized to perform the same tasks as behaving animals. Because the optimization of network parameters specifies the desired output but not the manner in which to achieve this output, ``trained'' networks serve as a source of mechanistic hypotheses and a testing ground for data analyses that link neural computation to behavior. Complete access to the activity and connectivity of the circuit, and the ability to manipulate them arbitrarily, make trained networks a convenient proxy for biological circuits and a valuable platform for theoretical investigation. However, existing RNNs lack basic biological features such as the distinction between excitatory and inhibitory units (Dale's principle), which are essential if RNNs are to provide insights into the operation of biological circuits. Moreover, trained networks can achieve the same behavioral performance but differ substantially in their structure and dynamics, highlighting the need for a simple and flexible framework for the exploratory training of RNNs. Here, we describe a framework for gradient descent-based training of excitatory-inhibitory RNNs that can incorporate a variety of biological knowledge. We provide an implementation based on the machine learning library Theano, whose automatic differentiation capabilities facilitate modifications and extensions. We validate this framework by applying it to well-known experimental paradigms such as perceptual decision-making, context-dependent integration, multisensory integration, parametric working memory, and motor sequence generation. Our results demonstrate the wide range of neural activity patterns and behavior that can be modeled, and suggest a unified setting in which diverse cognitive computations and mechanisms can be studied.",
journal = "PLoS Comput. Biol.",
volume =  12,
number =  2,
pages = "e1004792",
month =  feb,
year =  2016,
annote = "- Neat methods for Theano-based supervised backprop learning of tasks in RNNs<div><br></div><div>- Includes a neat regularization to prevent vanishing gradients, from Bengio et al.</div><div><br></div><div>- They separate 'connectivity' matrices from absolute-value (forced positive) weight matrices, with optimization only applied to the latter. Thus you can maintain specific connectivity patterns. Dale's law, etc.</div><div><br></div><div>- Various tasks, including the Mante-Sussillo one</div><div><br></div><div>- Neatest is the Romo task where they show clear reduction in firing  during the delay period ! Exactly what Barak et al. said was difficult to achieve ?... Well more precisely the increase in neurons tuned to F1 near the end of delay period... This also appears ! PResumably an effect of L2-penalty on firing rates</div><div><br></div>"
}

@ARTICLE{noauthor_undated-jf,

}

@ARTICLE{Whitney2016-qw,
title = "Understanding Visual Concepts with Continuation Learning",
author = "Whitney, William F and Chang, Michael and Kulkarni, Tejas and Tenenbaum, Joshua B",
abstract = "We introduce a neural network architecture and a learning algorithm to produce factorized symbolic representations. We propose to learn these concepts by observing consecutive frames, letting all the components of the hidden representation except a small discrete set (gating units) be predicted from the previous frame, and let the factors of variation in the next frame be represented entirely by these discrete gated units (corresponding to symbolic representations). We demonstrate the efficacy of our approach on datasets of faces undergoing 3D transformations and Atari 2600 games.",
month =  "22~" # feb,
year =  2016,
archivePrefix = "arXiv",
primaryClass = "cs.LG",
eprint = "1602.06822"
}

@ARTICLE{Soltoggio2013-rg,
title = "Solving the distal reward problem with rare correlations",
author = "Soltoggio, Andrea and Steil, Jochen J",
affiliation = "Research Institute for Cognition and Robotics and Faculty of Technology, Bielefeld University, Bielefeld 33615, Germany. asoltogg@cor-lab.uni-bielefeld.de",
abstract = "In the course of trial-and-error learning, the results of actions, manifested as rewards or punishments, occur often seconds after the actions that caused them. How can a reward be associated with an earlier action when the neural activity that caused that action is no longer present in the network? This problem is referred to as the distal reward problem. A recent computational study proposes a solution using modulated plasticity with spiking neurons and argues that precise firing patterns in the millisecond range are essential for such a solution. In contrast, the study reported in this letter shows that it is the rarity of correlating neural activity, and not the spike timing, that allows the network to solve the distal reward problem. In this study, rare correlations are detected in a standard rate-based computational model by means of a threshold-augmented Hebbian rule. The novel modulated plasticity rule allows a randomly connected network to learn in classical and instrumental conditioning scenarios with delayed rewards. The rarity of correlations is shown to be a pivotal factor in the learning and in handling various delays of the reward. This study additionally suggests the hypothesis that short-term synaptic plasticity may implement eligibility traces and thereby serve as a selection mechanism in promoting candidate synapses for long-term storage.",
journal = "Neural Comput.",
volume =  25,
number =  4,
pages = "940--978",
month =  apr,
year =  2013,
annote = "- Show that you can get reward-modulated Hebbian learning like Izhikevich 2007 with firing-rate networks - no need for spikes / STDP<div><br></div><div>- Both this and Izhikevich 2007 use RECURRENT NETWORKS (though weakly recurrent, not chaotic)</div><div><br></div><div>- Uses Hebbian learning that is only triggered for very strong correlated / anti-correlated firing</div><div><br></div><div>- Claims that this is the crucial component that allows learning to occur quickly !</div><div><br></div><div>- Would probably also work with simple RMHL... but would it be slower though</div>"
}

@ARTICLE{Smolensky1990-vv,
title = "Tensor product variable binding and the representation of symbolic structures in connectionist systems",
author = "Smolensky, Paul",
abstract = "A general method, the tensor product representation, is defined for the connectionist representation of value/variable bindings. The technique is a formalization of the idea that a set of value/variable pairs can be represented by accumulating activity in a collection of units each of which computes the product of a feature of a variable and a feature of its value. The method allows the fully distributed representation of bindings and symbolic structures. Fully and partially localized special cases of the tensor product representation reduce to existing cases of connectionist representations of structured data. The representation rests on a principled analysis of structure; it saturates gracefully as larger structures are represented; it permits recursive construction of complex representations from simpler ones; it respects the independence of the capacities to generate and maintain multiple bindings in parallel; it extends naturally to continuous structures and continuous representational patterns; it permits values to also serve as variables; and it enables analysis of the interference of symbolic structures stored in associative memories. It has also served as the basis for working connectionist models of high-level cognitive tasks.",
journal = "Artif. Intell.",
volume =  46,
number =  1,
pages = "159--216",
month =  "1~" # nov,
year =  1990
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dehaene2015-of,
title = "The Neural Representation of Sequences: From Transition Probabilities to Algebraic Patterns and Linguistic Trees",
author = "Dehaene, Stanislas and Meyniel, Florent and Wacongne, Catherine and Wang, Liping and Pallier, Christophe",
affiliation = "Coll\`{e}ge de France, 11 Place Marcelin Berthelot, 75005 Paris, France; Cognitive Neuroimaging Unit, CEA DSV/I2BM, INSERM, Universit\'{e} Paris-Sud, Universit\'{e} Paris-Saclay, NeuroSpin center, 91191 Gif/Yvette, France. Electronic address: stanislas.dehaene@cea.fr. Cognitive Neuroimaging Unit, CEA DSV/I2BM, INSERM, Universit\'{e} Paris-Sud, Universit\'{e} Paris-Saclay, NeuroSpin center, 91191 Gif/Yvette, France. Coll\`{e}ge de France, 11 Place Marcelin Berthelot, 75005 Paris, France; Cognitive Neuroimaging Unit, CEA DSV/I2BM, INSERM, Universit\'{e} Paris-Sud, Universit\'{e} Paris-Saclay, NeuroSpin center, 91191 Gif/Yvette, France. Key Laboratory of Brain Functional Genomics (MOE \& STCSM), Institute of Cognitive Neuroscience, School of Psychology and Cognitive Science, East China Normal University, Shanghai 200062, China; NYU-ECNU Institute of Brain and Cognitive Science at NYU Shanghai, Shanghai 200062, China. Cognitive Neuroimaging Unit, CEA DSV/I2BM, INSERM, Universit\'{e} Paris-Sud, Universit\'{e} Paris-Saclay, NeuroSpin center, 91191 Gif/Yvette, France.",
abstract = "A sequence of images, sounds, or words can be stored at several levels of detail, from specific items and their timing to abstract structure. We propose a taxonomy of five distinct cerebral mechanisms for sequence coding: transitions and timing knowledge, chunking, ordinal knowledge, algebraic patterns, and nested tree structures. In each case, we review the available experimental paradigms and list the behavioral and neural signatures of the systems involved. Tree structures require a specific recursive neural code, as yet unidentified by electrophysiology, possibly unique to humans, and which may explain the singularity of human language and cognition.",
journal = "Neuron",
volume =  88,
number =  1,
pages = "2--19",
month =  "7~" # oct,
year =  2015,
annote = "<div>- Extraordinary review on sequences and the neural basis of language(s)</div><div><br></div>- All ``sequences'' are not equal !<div><br></div><div><br></div><div>- Simplest sequences are transitions: predicting the identity of the next stimulus given the previous one. Examples: Mismatch response (MMR) / ``Oddball'' paradigm : If you expect AAAA... or ABABAB... and suddenly find a violation (AAAAB, or ABABABB), you get a large response in many areas</div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Oddball responses also happen if you omit the stimulus altogether - so it's not just cellular adaptation (in fact, repetition suppression is possibly largely due to prediction rather than just cellular adaptation)</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Unconscious and automatic, also occurs in coma !</span></div><div><br></div><div><br></div><div>- Next up is 'chunking' - ability to detect reoccurring chunks of individual stimuli (to-ki-bu).</div><div>- If you hear AAAAB, initially the B causes oddball response with MMR and then a P3b. If repeated, the P3b goes away (though the MMR still there !) But P3b reappears on hearing AAAAA !</div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- This chunk-level response is slower and not automatic - goes away if distracted by attention-capturing task !</span></div><div>- Also seen in a ``purer'' form by stream of syllables in which certain chunks occur several times (to-ki-bu). After hearing such streams, babies recognize (attend less to) the reoccurring triplets.</div><div>- Also, babies found it easier to attach semantic associations to these recurring triplets than to novel triplets!</div><div>- After training, adults show a left-lateral rhythm at 1/3 syllable frequency - they automatically divide into chunks of three !</div><div>- Also occurs for vision, actions, etc. E.g. BG and PFC learn to only fire at start and end of sequences of actions.</div><div>- Chunks of chunks also represented in anterior PFC !</div><div><br></div><div><br></div><div>- Ordinal : sequences that only depend on order, independently of timing.</div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- When remembering a list, we mostly remember 1st and last - primacy + recency effect</span></div><div>- If monkeys learn sequences a1 a2 a3 and b1 b2 b3, they are more likely to confuse elements at the same location ! (a1 b2 a3 rather than a1 b1 a3) !</div><div>- If need to remember sequence of 3 shapes, ~44\% of PFC neurons are tuned to serial position in the list (independently of stimulus identity) !?</div><div>- Also untrained animals can track numbers (of stimuli, actions, etc.) </div><div>- How to remember which item was 1st, 2nd or 3rd? Botvinick \& Watanabe: Gain field between stim identity and ordinal position !</div><div>- Such cells are indeed found in PFC </div><div><br></div><div><br></div><div>- Algebraic patterns: based on 'same' or 'different' rather than specific identity: AAB vs ABA, regardless of what A or B are ! (Can also be based on other relationships than equality - e.g. increasing sequences)</div><div>- When trained to perform sequences of different actions (push, pull..), some PFC neurons encode algebraic patterns (e.g. tuned to AAA or AAB or ABA, disregarding the specific actions !)</div><div>- In fMRI, can detect violation responses for algebraic patterns (AAAB vs AAAA) or number (AAAA vs AAAAA) or both. </div><div>- In animals, these occur in different areas - but in humans. they overlap in IFG and pSTS - Language areas !</div><div>- No accepted neural model for such abstract encoding !</div><div><br></div><div>- Nested Tree Structure: recognize structures made of tree of ``constituents'', which can be shifted around in the sequence, linked by coordinations ('and', etc. </div><div>- Tree structure required to compute e.g. agreement: ``The cars [that pass this truck] are red'' : you immediately recognize that 'are' should match 'the cars', rather than the proximal 'this truck' !</div><div>- Chomsky 'minimalist' program - all trees can be built by 'merging' pairs of elements (i.e. trees are binary ! hmmm...)</div><div>- Chomsky says all sentences are neat, long, complex trees. Marcus says ``Nah'' - subtrees or ``treelets'' bound in transitory and imperfect manner.</div><div>- Network for sentence comprehension: left-hemisphere pSTS, MTG, TPJ, temporal pole - and especially IFG = Broca's Area = Brodmann 45 \& 44.</div><div>- Stricter circuit: Left putamen, STS and IFG [Hmmm, is left putamen in agreement with Pauli, Yarkoni et al.s parcellation of striatum?] + arcuate fascucle and extreme capsule.</div><div>- Learning fake languages with ``realistic'' rules generate increase in IFG response; non-real rules don't.</div><div>- iFG + pSTS seem not related to meaning of word - also involved when detecting tree-arranged constituents with ``jabberwocky'' words (as opposed to TPJ, TP, aSTS)</div><div>- Maybe IFG is the generic ``merge'', while the actual elements to be bound are STS? E.g. different regions of STS encode the different grammatical elements (subject, verb, object), independently of temporal order!</div><div>- Formation of trees not unique to language [He, that's why Broca's area is part of generic multiple-demand network...]</div><div>- You can build grammars based on simple pairs ([AB][CD][EF]) or embedded trees ([A[BC]D], where whatever is between brackets can be switched to another). The latter engage BA 44 more (thus, IFG responds to many types of 'sequences', including the simpler one described previously)</div><div>- Monkeys can apparently learn pairs-grammars, but NOT nested-tree grammars !</div><div>Smolensky \& legendre 2006 have a model for this - also taken by Eliasmith</div>"
}

@ARTICLE{Lai2015-md,
title = "Giraffe: Using Deep Reinforcement Learning to Play Chess",
author = "Lai, Matthew",
abstract = "This report presents Giraffe, a chess engine that uses self-play to discover all its domain-specific knowledge, with minimal hand-crafted knowledge given by the programmer. Unlike previous attempts using machine learning only to perform parameter-tuning on hand-crafted evaluation functions, Giraffe's learning system also performs automatic feature extraction and pattern recognition. The trained evaluation function performs comparably to the evaluation functions of state-of-the-art chess engines - all of which containing thousands of lines of carefully hand-crafted pattern recognizers, tuned over many years by both computer chess experts and human chess masters. Giraffe is the most successful attempt thus far at using end-to-end machine learning to play chess.",
month =  "4~" # sep,
year =  2015,
archivePrefix = "arXiv",
primaryClass = "cs.AI",
eprint = "1509.01549"
}

@INPROCEEDINGS{Edvardsen2015-fy,
title = "A Passive Mechanism for {Goal-Directed} Navigation using Grid Cells",
booktitle = "07/20/2015-07/24/2015",
author = "Edvardsen, Vegard",
publisher = "The MIT Press",
pages = "191--198",
month =  "20~" # jul,
year =  2015,
annote = "<div>- A simple model of goal-directed navigation using grid cell representation of both current environment and target location !</div><div><br></div>- Includes neat discussion of attractor models of grid cells<div><br></div><div>- In velocity-integrating grid cells models (Burak \& Fiete 2009), the cells have directional preference, i.e. their lateral inputs are a DoG, but shifted in the direction opposite to their preferred direction</div><div><br></div><div>- Apparently this stabilizes to a field of bumps (OK...)</div><div><br></div><div>- If you feed input selectively to the cells that prefer current motion direction, the bumps shift in space in that direction, thus maintaining the grid cell representation</div><div><br></div><div>- For navigation: Have some goal-direction-selective 'goal cells' that compare both the current grid cell field, and the grid cell field when the animal is at the target location</div><div><br></div><div>- More precisely, they get excited if there is an activity peak at their preferred location X in grid cell field, AND if there is a peak at location X + offset in the target-position field (where offset is the cell's preferred goal direction)</div><div><br></div><div>- Then the cell are most active when the goal is in their preferred direction !</div><div><br></div><div>- If you have enough cells to cover the field, and enough field at various scales to cover all scales, you can use this to guide navigation to goal !</div><div><br></div><div>- Seems not to account for obstacles?</div>",
conference = "European Conference on Artificial Life 2015"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Pauli2016-yo,
title = "Regional specialization within the human striatum for diverse psychological functions",
author = "Pauli, Wolfgang M and O'Reilly, Randall C and Yarkoni, Tal and Wager, Tor D",
affiliation = "Division of the Humanities and Social Sciences, California Institute of Technology, Pasadena, CA 91125; pauli@caltech.edu. Department of Psychology and Neuroscience, University of Colorado Boulder, Boulder, CO 80309; Department of Psychology, University of Texas at Austin, Austin, TX 78712; Department of Psychology and Neuroscience, University of Colorado Boulder, Boulder, CO 80309; Institute of Cognitive Science, University of Colorado Boulder, Boulder, CO 80309.",
abstract = "Decades of animal and human neuroimaging research have identified distinct, but overlapping, striatal zones, which are interconnected with separable corticostriatal circuits, and are crucial for the organization of functional systems. Despite continuous efforts to subdivide the human striatum based on anatomical and resting-state functional connectivity, characterizing the different psychological processes related to each zone remains a work in progress. Using an unbiased, data-driven approach, we analyzed large-scale coactivation data from 5,809 human imaging studies. We (i) identified five distinct striatal zones that exhibited discrete patterns of coactivation with cortical brain regions across distinct psychological processes and (ii) identified the different psychological processes associated with each zone. We found that the reported pattern of cortical activation reliably predicted which striatal zone was most strongly activated. Critically, activation in each functional zone could be associated with distinct psychological processes directly, rather than inferred indirectly from psychological functions attributed to associated cortices. Consistent with well-established findings, we found an association of the ventral striatum (VS) with reward processing. Confirming less well-established findings, the VS and adjacent anterior caudate were associated with evaluating the value of rewards and actions, respectively. Furthermore, our results confirmed a sometimes overlooked specialization of the posterior caudate nucleus for executive functions, often considered the exclusive domain of frontoparietal cortical circuits. Our findings provide a precise functional map of regional specialization within the human striatum, both in terms of the differential cortical regions and psychological functions associated with each striatal zone.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
month =  "1~" # feb,
year =  2016,
annote = "- Parcellate striatum voxels according to their cortical coactivations, estimated over 5000+ fMRI studies<div><br></div><div>- They note that there isn't an obvious number of precise clusters, it seems more diffuse/overlapping</div><div><br></div><div>- Seems to be a preference for 3 clusters - VS, Caudate, Putamen?</div><div><br></div><div>- But they chose 5 clusters - VS, Ca, Cp, Pa, Pp</div><div><br></div><div>- VS more associated with OFC, vmPFC (duh). Seems to evaluate stimulus value</div><div><br></div><div>- Ca (anterior Caudate): associated with 'reaching, 'grasping' and 'reinforcement', activated by comparing money-gain trials vs feedback only trials. Evaluate action value? </div><div><br></div><div>- Pp (posterior Putamen): Sensorimotor, pain ! Insula, MTL, medial sensorimotor.</div><div><br></div><div>- Pa: social / language (Broca's area)  - more activated when experts sing but not when novices sing</div><div><br></div><div>- Cp: Executive functions (Alexander puts it in oculomotr circuit...) associated with ``Causality'', 'rehearsal' and 'arithmetic', task-set shifting, inhibition. dlPFC, ACC. </div><div><br></div><div> Very nice patterns, but difficult to find which areas they actually are. E.g. the lower temporal lobe has a 'red' zone and a 'purple' zone (VS) - is it MTL vs IT?...</div>",
keywords = "NeuroSynth; coactivation analysis; corticostriatal circuits; human striatum; parcellation"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cone2016-gh,
title = "Physiological state gates acquisition and expression of mesolimbic reward prediction signals",
author = "Cone, Jackson J and Fortin, Samantha M and McHenry, Jenna A and Stuber, Garret D and McCutcheon, James E and Roitman, Mitchell F",
affiliation = "Graduate Program in Neuroscience, University of Illinois at Chicago, Chicago, IL 60612; Department of Psychology, University of Illinois at Chicago, Chicago, IL 60607; Graduate Program in Neuroscience, University of Illinois at Chicago, Chicago, IL 60612; Department of Psychology, University of Illinois at Chicago, Chicago, IL 60607; Department of Psychiatry, University of North Carolina at Chapel Hill, Chapel Hill, NC 27514; Department of Psychiatry, University of North Carolina at Chapel Hill, Chapel Hill, NC 27514; Department of Cell Biology and Physiology, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599; Department of Neuroscience, Psychology and Behaviour, University of Leicester, Leicester LE1 9HN, United Kingdom. Department of Psychology, University of Illinois at Chicago, Chicago, IL 60607; mroitman@uic.edu.",
abstract = "Phasic dopamine signaling participates in associative learning by reinforcing associations between outcomes (unconditioned stimulus; US) and their predictors (conditioned stimulus; CS). However, prior work has always engendered these associations with innately rewarding stimuli. Thus, whether dopamine neurons can acquire prediction signals in the absence of appetitive experience and update them when the value of the outcome changes remains unknown. Here, we used sodium depletion to reversibly manipulate the appetitive value of a hypertonic sodium solution while measuring phasic dopamine signaling in rat nucleus accumbens. Dopamine responses to the NaCl US following sodium depletion updated independent of prior experience. In contrast, prediction signals were only acquired through extensive experience with a US that had positive affective value. Once learned, dopamine prediction signals were flexibly expressed in a state-dependent manner. Our results reveal striking differences with respect to how physiological state shapes dopamine signals evoked by outcomes and their predictors.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
month =  "1~" # feb,
year =  2016,
annote = "- Rats dislike Salt, unless they're salt-depleted<div><br></div><div>- Salt produces phasic DA in NAcc core, but only if rats are salt-depleted</div><div><br></div><div>- What about conditioned, salt-predicting stimuli?</div><div><br></div><div>- If trained normally, the CS does NOT elicit DA </div><div><br></div><div>- BUT, if trained (a lot) under depletion, THEN the CS does elicit DA ! (same thing for conditioned approach behavior)</div><div><br></div><div>- So the US valence and DA-producing updates immediately, but the CS only becomes attractive + DA-releasing after training UNDER conditions where the US is appetive !</div><div><br></div><div>- Seems to conflict with e.g. Robinson \& Berridge 2013, ``Instant transformation...'' But apparently training and Salt concentrations were different (they say)</div>",
keywords = "dopamine; learning; motivation; nucleus accumbens; voltammetry"
}

@ARTICLE{Ikemoto2010-fs,
title = "Brain reward circuitry beyond the mesolimbic dopamine system: a neurobiological theory",
author = "Ikemoto, Satoshi",
affiliation = "Behavioral Neuroscience Research Branch, National Institute on Drug Abuse, National Institutes of Health, US Department of Health and Human Services, 251 Bayview Blvd, Suite 200, Baltimore, MD 21224, United States. Satoshi.Ikemoto@nih.gov",
abstract = "Reductionist attempts to dissect complex mechanisms into simpler elements are necessary, but not sufficient for understanding how biological properties like reward emerge out of neuronal activity. Recent studies on intracranial self-administration of neurochemicals (drugs) found that rats learn to self-administer various drugs into the mesolimbic dopamine structures-the posterior ventral tegmental area, medial shell nucleus accumbens and medial olfactory tubercle. In addition, studies found roles of non-dopaminergic mechanisms of the supramammillary, rostromedial tegmental and midbrain raphe nuclei in reward. To explain intracranial self-administration and related effects of various drug manipulations, I outlined a neurobiological theory claiming that there is an intrinsic central process that coordinates various selective functions (including perceptual, visceral, and reinforcement processes) into a global function of approach. Further, this coordinating process for approach arises from interactions between brain structures including those structures mentioned above and their closely linked regions: the medial prefrontal cortex, septal area, ventral pallidum, bed nucleus of stria terminalis, preoptic area, lateral hypothalamic areas, lateral habenula, periaqueductal gray, laterodorsal tegmental nucleus and parabrachical area.",
journal = "Neurosci. Biobehav. Rev.",
volume =  35,
number =  2,
pages = "129--150",
month =  nov,
year =  2010
}

@ARTICLE{Actions_undated-ep,
title = "Neurobiology of Learning and Memory",
author = "Actions, Performance of Goal-Directed"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hsu2014-oc,
title = "Contributions of the paraventricular thalamic nucleus in the regulation of stress, motivation, and mood",
author = "Hsu, David T and Kirouac, Gilbert J and Zubieta, Jon-Kar and Bhatnagar, Seema",
affiliation = "Department of Psychiatry and the Molecular and Behavioral Neuroscience Institute, University of Michigan Ann Arbor, MI, USA. Departments of Oral Biology and Psychiatry, Faculties of Dentistry and Medicine, University of Manitoba Winnipeg, MB, Canada. Department of Psychiatry and the Molecular and Behavioral Neuroscience Institute, University of Michigan Ann Arbor, MI, USA. Department of Anesthesiology, Children's Hospital of Philadelphia, University of Pennsylvania Perelman School of Medicine Philadelphia, PA, USA.",
abstract = "The purpose of this review is to describe how the function and connections of the paraventricular thalamic nucleus (Pa) may play a role in the regulation of stress and negative emotional behavior. Located in the dorsal midline thalamus, the Pa is heavily innervated by serotonin, norepinephrine, dopamine (DA), corticotropin-releasing hormone, and orexins (ORX), and is the only thalamic nucleus connected to the group of structures comprising the amygdala, bed nucleus of the stria terminalis (BNST), nucleus accumbens (NAcc), and infralimbic/subgenual anterior cingulate cortex (sgACC). These neurotransmitter systems and structures are involved in regulating motivation and mood, and display abnormal functioning in several psychiatric disorders including anxiety, substance use, and major depressive disorders (MDD). Furthermore, rodent studies show that the Pa is consistently and potently activated following a variety of stressors and has a unique role in regulating responses to chronic stressors. These observations provide a compelling rationale for investigating the Pa in the link between stress and negative emotional behavior, and for including the Pa in the neural pathways of stress-related psychiatric disorders.",
journal = "Front. Behav. Neurosci.",
volume =  8,
pages = "73",
month =  "11~" # mar,
year =  2014,
annote = "- Review of paraventricular thalamus / PVT<div><br></div><div>- Only thalamic nucleus that projects to NAcc (Sh),  BLA, CeA, BNST,   The nearby MedioDorsal Thalamus doesn't !</div><div><br></div><div>- Also projects to IL, subgenual (involved in depression) cortex, Entorhinal, agranular insular cortex.</div><div><br></div><div>- Receives mostly from PL/IL, agranular insular, subiculum of HPC. Also from Hypothalamus (dorsomedial and LHA, arcuate, suprachiasmatic), Periaqueductal Gray (important in responses to pain/stressors), Parabrachial. Also Entorhinal, zona incerta, Amygdala, BNST. </div><div><br></div><div>- Reciprocal connection with SupraChiasmatic Nucleus (circadian)</div><div><br></div><div>- Basically activated by all kinds of stress,  air puff, fear, handling, sleep deprivation.</div><div><br></div><div>- Maybe also activated for all ``emotionally arousing'' environments, both rewarding or aversive - e.g. when place in context that predicts sucrose, or taste aversion, or drug reward, or food shock.</div><div><br></div><div>- Role in drug relapse: ``lesions of the Pa block the conditioned locomotor response to a cocaine-paired environment''</div>",
keywords = "addiction; anxiety; depression; orexin; paraventricular; stress; subgenual; thalamus"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zhu2016-vo,
title = "A thalamic input to the nucleus accumbens mediates opiate dependence",
author = "Zhu, Yingjie and Wienecke, Carl F R and Nachtrab, Gregory and Chen, Xiaoke",
affiliation = "Department of Biology, Stanford University, Stanford, California 94305, USA. Department of Biology, Stanford University, Stanford, California 94305, USA. Department of Biology, Stanford University, Stanford, California 94305, USA. Department of Biology, Stanford University, Stanford, California 94305, USA.",
abstract = "Chronic opiate use induces opiate dependence, which is characterized by extremely unpleasant physical and emotional feelings after drug use is terminated. Both the rewarding effects of a drug and the desire to avoid withdrawal symptoms motivate continued drug use, and the nucleus accumbens is important for orchestrating both processes. While multiple inputs to the nucleus accumbens regulate reward, little is known about the nucleus accumbens circuitry underlying withdrawal. Here we identify the paraventricular nucleus of the thalamus as a prominent input to the nucleus accumbens mediating the expression of opiate-withdrawal-induced physical signs and aversive memory. Activity in the paraventricular nucleus of the thalamus to nucleus accumbens pathway is necessary and sufficient to mediate behavioural aversion. Selectively silencing this pathway abolishes aversive symptoms in two different mouse models of opiate withdrawal. Chronic morphine exposure selectively potentiates excitatory transmission between the paraventricular nucleus of the thalamus and D2-receptor-expressing medium spiny neurons via synaptic insertion of GluA2-lacking AMPA receptors. Notably, in vivo optogenetic depotentiation restores normal transmission at these synapses and robustly suppresses morphine withdrawal symptoms. This links morphine-evoked pathway- and cell-type-specific plasticity in the paraventricular nucleus of the thalamus to nucleus accumbens circuit to opiate dependence, and suggests that reprogramming this circuit holds promise for treating opiate addiction.",
journal = "Nature",
month =  "3~" # feb,
year =  2016,
annote = "<div>[ Together with the PVT - to - central amygdala Penzo et al Nature 2015 paper, PVT seems to be a general center of stress? ]</div><div><br></div><div>[ Simplest understanding: PVT - NAcc is the driver of ``active'' stress responses. Drug dependence is really a massive increase in active stress, driven by LTP in this pathway, temporarily alleviated by drugs ]</div><div><br></div><div>[ Also: clicks with the Ramirez et al. ``Active avoidance'' paper: BLA - NAcc Sh mediates active avoidance in response to conditioned aversive stimuli ! ]</div><div><br></div><div>[ So a specific part of </div><div><br></div>- PVT-to-NAcc mShell projection is aversive, mediates opiate withdrawal symptoms and other aversive reactions <div><br></div><div>- NAcc mShell receives from BLA, vHPC and PFC (rewarding, drives self-stimulation), but also from PVT</div><div><br></div><div>- PVT-to-NAcc is aversive :  optostimulation reduces time in stimulation room </div><div><br></div><div>- Separately: drug-dependent animals on naloxone will get strong wihdrawal, develop strong, days-long CPA if confined in a given room during naloxone</div><div><br></div><div>- Naloxone raises cFos in PVT-to-NAcc neurons, and silencing PVT-Nacc pathway eliminates signs of withdrawal and CPA ! </div><div><br></div><div>- Same thing for simple withdrawal through cessation of drugs</div><div><br></div><div>- Same thing for mild footshocks and LiCl  !!!  cFos in PVT (OK, stress), silencing PVT-NAcc = no CPA !!</div><div><br></div><div>- Chronic morphine exposure induces LTP at PVT -> NAcc D2 MSN , NOT D1 !!</div><div><br></div><div>- Crazy: When you induce  LTD  in PVT -> NAcc pathway after chronic morphine, you reduce withdrawl symptoms (including CPA) of Naloxone !!!</div><div><br></div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Degris2012-oq,
title = "{Model-Free} reinforcement learning with continuous action in practice",
booktitle = "American Control Conference ({ACC)}, 2012",
author = "Degris, T and Pilarski, P M and Sutton, R S",
abstract = "Reinforcement learning methods are often considered as a potential solution to enable a robot to adapt to changes in real time to an unpredictable environment. However, with continuous action, only a few existing algorithms are practical for real-time learning. In such a setting, most effective methods have used a parameterized policy structure, often with a separate parameterized value function. The goal of this paper is to assess such actor-critic methods to form a fully specified practical algorithm. Our specific contributions include 1) developing the extension of existing incremental policy-gradient algorithms to use eligibility traces, 2) an empirical comparison of the resulting algorithms using continuous actions, 3) the evaluation of a gradient-scaling technique that can significantly improve performance. Finally, we apply our actor-critic algorithm to learn on a robotic platform with a fast sensorimotor cycle (10ms). Overall, these results constitute an important step towards practical real-time learning control with continuous action.",
pages = "2177--2182",
month =  jun,
year =  2012,
annote = "- Review of RL for continuous action states<div><br></div><div>- States that REINFORCE is basically actor-critic without a critic ! </div><div><br></div><div>- (The actor critic optimizes both an actor and a value-estimating critic, trains the actor to optimize the value, and the value estimator ?... See also Kimura paper cited therein...)</div>",
keywords = "gradient methods;learning (artificial intelligence);real-time systems;robots;actor-critic algorithm;continuous action;incremental policy-gradient algorithms;model-free reinforcement learning;parameterized policy structure;real-time learning control;robot;sensorimotor cycle;Learning;Mobile robots;Real-time systems;Robot sensing systems;Standards;Vectors"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mnih2016-zd,
title = "Asynchronous Methods for Deep Reinforcement Learning",
author = "Mnih, Volodymyr and Badia, Adri\`{a} Puigdom\`{e}nech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P and Harley, Tim and Silver, David and Kavukcuoglu, Koray",
abstract = "We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task involving finding rewards in random 3D mazes using a visual input.",
month =  "4~" # feb,
year =  2016,
annote = "- Use a new method for Deep Reinforcement learning for Atari AND other games<div><br></div><div>- Instead of using experience replays, have several threads running at once, each sending back their updates to a central server</div><div><br></div><div>- Because the threads will explore different portions of the space, that solves the time-correlation problem !</div><div><br></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Can now use on-policy method such as Sarsa</span></div><div><br></div><div>- Best method is some form of actor-critic - really a gradient method a la Reinforce:</div><div>   ascend the gradient over parameters of Probability(take action I took / state, params) * (Rt - V(t)),</div><div>Where Rt is the  sum of time-discounted rewards after t, and V(t) is the expected value function (estimated by the 'critic')</div><div><br></div><div>- So basically make the taken action more likely in the future, if they produced higher reward than expected.</div><div><br></div><div>- Much faster, stronger</div><div><br></div><div>- Great review of reinforcement learning in the intro !</div><div><br></div><div>[See also Legris paper]</div>",
archivePrefix = "arXiv",
primaryClass = "cs.LG",
eprint = "1602.01783"
}

@ARTICLE{Villa2016-da,
title = "Inhibitory Synapses Are Repeatedly Assembled and Removed at Persistent Sites In Vivo",
author = "Villa, Katherine L and Berry, Kalen P and Subramanian, Jaichandar and Cha, Jae Won and Oh, Won Chan and Kwon, Hyung-Bae and Kubota, Yoshiyuki and So, Peter T C and Nedivi, Elly",
journal = "Neuron",
publisher = "Elsevier",
volume =  0,
number =  0,
month =  "4~" # feb,
year =  2016,
annote = "- [Coiuldn't access paper]<div><br></div><div>- Synapse turnover is strong and real</div><div><br></div><div>- Inhibitory synapses are very dynamic, disappearing and reappearing at the same position</div><div><br></div><div>- ``Dually innervated'' synapses are stable if excitatory, but very dynamic if inhibitory</div><div><br></div><div>- Affected by experience (monocular deprivation)</div><div><br></div><div>- inhibitory plasticity .... but not clear if gross / crude or specific....</div>"
}

@ARTICLE{Kok2016-bh,
title = "Selective Activation of the Deep Layers of the Human Primary Visual Cortex by {Top-Down} Feedback",
author = "Kok, Peter and Bains, Lauren J and van Mourik, Tim and Norris, David G and de Lange, Floris P",
journal = "Curr. Biol.",
publisher = "Elsevier",
volume =  0,
number =  0,
month =  "28~" # jan,
year =  2016,
annote = "- You can do layer-specific fMRI in visual cortex !!<div><br></div><div>- Apparently top-down feedback (elicited by illusory contours) preferentially targets the deep layers of V1, rather than the superficial layers.</div>",
keywords = "perceptual inference; shape perception; predictive coding; laminar fMRI"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bendor_undated-xi,
title = "Does the Hippocampus Map Out the Future?",
author = "Bendor, Daniel and Spiers, Hugo J",
abstract = "Decades of research have established two central roles of the hippocampus -- memory consolidation and spatial navigation. Recently, a third function of the hippocampus has been proposed: simulating future events. However, claims that the neural patterns underlying simulation occur without prior experience have come under fire in light of newly published data.",
journal = "Trends Cogn. Sci.",
annote = "- A skeptical review of replay and  preplay in hippocampus <div><br></div><div>- Very skeptical about pre-play !</div><div><br></div><div>- Not sure about the pre-cognition quip.... It does not seem impossible that whatever process maps pre-existing sequences to new environment, would somehow be able to map intersecting sequences 'correctly' ?...</div>"
}

@ARTICLE{Roseberry2016-mf,
title = "{Cell-Type-Specific} Control of Brainstem Locomotor Circuits by Basal Ganglia",
author = "Roseberry, Thomas K and Moses Lee, A and Lalive, Arnaud L and Wilbrecht, Linda and Bonci, Antonello and Kreitzer, Anatol C",
journal = "Cell",
publisher = "Elsevier",
volume =  164,
number =  3,
pages = "526--537",
month =  "28~" # jan,
year =  2016,
annote = "[ Article not available, going from the abstract ]<div><br></div><div>- BG act on locomotion partly through a brainstem structure calld Mesencephalic Locomotor Region (MLR)</div><div><br></div><div>- Direct pathway stimulates the Glut neurons in MLR, which are sufficient and necessary for locomotion</div><div><br></div><div>- Indirect pathway suppress them (stop!)</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kim2016-gx,
title = "Prefrontal Parvalbumin Neurons in Control of Attention",
author = "Kim, Hoseok and {\"{A}}hrlund-Richter, Sofie and Wang, Xinming and Deisseroth, Karl and Carl\'{e}n, Marie",
affiliation = "Department of Neuroscience, Karolinska Institutet, Retzius v{\"{a}}g 8, 171 77 Stockholm, Sweden. Department of Neuroscience, Karolinska Institutet, Retzius v{\"{a}}g 8, 171 77 Stockholm, Sweden. Department of Neuroscience, Karolinska Institutet, Retzius v{\"{a}}g 8, 171 77 Stockholm, Sweden. Howard Hughes Medical Institute, W080 Clark Center, 318 Campus Drive West, Stanford University, Stanford, CA 94305, USA; Department of Bioengineering, W080 Clark Center, 318 Campus Drive West, Stanford University, Stanford, CA 94305, USA; Department of Psychiatry and Behavioral Sciences, W080 Clark Center, 318 Campus Drive West, Stanford University, Stanford, CA 94305, USA. Department of Neuroscience, Karolinska Institutet, Retzius v{\"{a}}g 8, 171 77 Stockholm, Sweden. Electronic address: marie.carlen@ki.se.",
abstract = "While signatures of attention have been extensively studied in sensory systems, the neural sources and computations responsible for top-down control of attention are largely unknown. Using chronic recordings in mice, we found that fast-spiking parvalbumin (FS-PV) interneurons in medial prefrontal cortex (mPFC) uniformly show increased and sustained firing during goal-driven attentional processing, correlating to the level of attention. Elevated activity of FS-PV neurons on the timescale of seconds predicted successful execution of behavior. Successful allocation of attention was characterized by strong synchronization of FS-PV neurons, increased gamma oscillations, and phase locking of pyramidal firing. Phase-locked pyramidal neurons showed gamma-phase-dependent rate modulation during successful attentional processing. Optogenetic silencing of FS-PV neurons deteriorated attentional processing, while optogenetic synchronization of FS-PV neurons at gamma frequencies had pro-cognitive effects and improved goal-directed behavior. FS-PV neurons thus act as a functional unit coordinating the activity in the local mPFC circuit during goal-driven attentional processing.",
journal = "Cell",
volume =  164,
number = "1-2",
pages = "208--218",
month =  "14~" # jan,
year =  2016,
annote = "<div>[ Note: Just going from the abstract here ]</div><div><br></div>- The effect of gamma oscillation on attention really is causal !<div><br><div>- By opto-stimulating PV neurons in PFC at gamma freq, you observe ``pro-cognitive'' effects </div></div>"
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Silver2016-cq,
title = "Mastering the game of Go with deep neural networks and tree search",
author = "Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis",
journal = "Nature",
publisher = "Nature Publishing Group",
volume =  529,
number =  7587,
pages = "484--489",
month =  "27~" # jan,
year =  2016,
annote = "1: Train a ``Expert-predictor'' network that learns to predict the next move of experts in a given position<div><br></div><div>2: Use this to initialize a RL process to learn a ``Policy'' network, refined through RL and self-play</div><div><br></div><div>3: Use self-play games from the RL network to train a ``Value-prediction'' network, which predicts the final outcome of any given position</div><div><br></div><div>4: Combine all of those, plus a ``weak-but-fast'' policy network, into a Monte-Carlo tree search algorithm </div><div><br></div><div>(This is actually pretty complex. Preliminary understanding: The expert-predicting net is used to assign a 'prior probability' to any move for future traversals during the Monte-Carlo search. Traversals are biased by 'quality', which is the average 'value' of the leaf nodes at the end of this traversal, where value is a mixture of the Value-prediction network + a fast play-to-the-end simulation from that node using the weak-but-fast player. In the end, select the most traversed move !)</div><div><br></div><div><br></div><div>5: ???</div><div><br></div><div>6: Nature cover!<br><div><br></div></div>"
}

@ARTICLE{LaLumiere2010-mx,
title = "The infralimbic cortex regulates the consolidation of extinction after cocaine self-administration",
author = "LaLumiere, Ryan T and Niehoff, Kate E and Kalivas, Peter W",
affiliation = "Neurobiology of Addiction Research Center, Department of Neurosciences, Medical University of South Carolina, Charleston, South Carolina 29425, USA. lalumie@musc.edu",
abstract = "The infralimbic cortex (IL) regulates the consolidation of extinction learning for fear conditioning. Whether the IL influences the consolidation of extinction learning for cocaine self-administration is unknown. To address this issue, male Sprague-Dawley rats underwent 2 wk of cocaine self-administration followed by extinction training. On the first 5 d of extinction, rats underwent brief (15- or 30-min) extinction sessions and received intra-IL microinjections immediately after each extinction session. On days 6-12 of extinction, rats underwent full-length (2-h) extinction sessions that were used to assess the retention of the extinction learning from the short sessions. IL inactivation via microinjections of the GABA agonists baclofen and muscimol (BM) immediately after the extinction sessions (days 1-5) impaired the retention of extinction learning. Control experiments demonstrated that this effect was not due to inactivation of the prelimbic cortex or due to effects of the drugs on the subsequent day's behavior. In contrast, post-training intra-IL microinjections of the allosteric AMPA receptor potentiator 4-[2-(phenylsulfonylamino)ethylthio]-2,6-difluorophenoxyacetamide (PEPA) enhanced retention of the extinction learning. As evidence suggests a role for the beta-adrenergic receptors in memory consolidation, other rats received microinjections of the beta(2)-adrenergic receptor agonist clenbuterol or antagonist ICI-118,551 (ICI). Post-training intra-IL administration of clenbuterol or pre-training administration of ICI enhanced or impaired, respectively, the retention of extinction learning. These data indicate that the IL, and specifically the glutamatergic and beta-adrenergic systems in the IL, regulates the consolidation of extinction of cocaine self-administration and that the IL can be manipulated to influence the retention of extinction.",
journal = "Learn. Mem.",
volume =  17,
number =  4,
pages = "168--175",
month =  apr,
year =  2010,
annote = "- IL cortex (infralimbic, the ventral portion of mPFC) regulates the *consolidation* of extinction learning<div><br></div><div>- Both for *fear* conditioning (aversive) AND for cocaine self-administration (rewarding) !</div><div><br></div><div>[The Lammel papers suggest that DA in mPFC is required for aversive conditioning?....]</div><div>[Dalley 2005 says DA in NAcc Core *after* the learning sessions required for conditioned approach to a food-associated stimulus... ]</div><div><br></div><div><br></div>"
}

@ARTICLE{Van_den_Oord2016-tp,
title = "Pixel Recurrent Neural Networks",
author = "van den Oord, Aaron and Kalchbrenner, Nal and Kavukcuoglu, Koray",
abstract = "Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.",
month =  "25~" # jan,
year =  2016,
annote = "- Generate images by simply 'predicting' each next pixel value, using a deep-RNN (LSTM).<div><br></div><div>- Trick to improve efficiency - fast 2D RNNs</div><div><br></div><div>- Images look ... interesting - all the structure of real natural images without the content. Completions are really good.</div>",
archivePrefix = "arXiv",
primaryClass = "cs.CV",
eprint = "1601.06759"
}

@ARTICLE{Isomura2015-ja,
title = "Cultured Cortical Neurons Can Perform Blind Source Separation According to the {Free-Energy} Principle",
author = "Isomura, Takuya and Kotani, Kiyoshi and Jimbo, Yasuhiko",
affiliation = "Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, The University of Tokyo, Hongo, Bunkyo-ku, Tokyo, Japan. Research Fellow of Japan Society for the Promotion of Science (JSPS), Kojimachi, Chiyoda-ku, Tokyo, Japan. Research Center for Advanced Science and Technology, The University of Tokyo, Komaba, Meguro-ku, Tokyo, Japan. PRESTO, Japan Science and Technology Agency, Honcho, Kawaguchi-shi, Saitama, Japan. Department of Precision Engineering, School of Engineering, The University of Tokyo, Hongo, Bunkyo-ku, Tokyo, Japan.",
abstract = "Blind source separation is the computation underlying the cocktail party effect--a partygoer can distinguish a particular talker's voice from the ambient noise. Early studies indicated that the brain might use blind source separation as a signal processing strategy for sensory perception and numerous mathematical models have been proposed; however, it remains unclear how the neural networks extract particular sources from a complex mixture of inputs. We discovered that neurons in cultures of dissociated rat cortical cells could learn to represent particular sources while filtering out other signals. Specifically, the distinct classes of neurons in the culture learned to respond to the distinct sources after repeating training stimulation. Moreover, the neural network structures changed to reduce free energy, as predicted by the free-energy principle, a candidate unified theory of learning and memory, and by Jaynes' principle of maximum entropy. This implicit learning can only be explained by some form of Hebbian plasticity. These results are the first in vitro (as opposed to in silico) demonstration of neural networks performing blind source separation, and the first formal demonstration of neuronal self-organization under the free energy principle.",
journal = "PLoS Comput. Biol.",
volume =  11,
number =  12,
pages = "e1004643",
month =  dec,
year =  2015,
annote = "- If you expose cultured neurons to a mixture of 2 stimulation streams, with an unequal mixture, they will learn to respond preferentially to the most frequently represented stimulus stream<div><br></div><div>- They call that ``blind source separation''. But given the settings, it seems simply that neurons learn to connect to other neurons that fire with them....?</div><div><br></div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Li2016-lx,
title = "Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis",
author = "Li, Chuan and Wand, Michael",
abstract = "This paper studies a combination of generative Markov random field (MRF) models and discriminatively trained deep convolutional neural networks (dCNNs) for synthesizing 2D images. The generative MRF acts on higher-levels of a dCNN feature pyramid, controling the image layout at an abstract level. We apply the method to both photographic and non-photo-realistic (artwork) synthesis tasks. The MRF regularizer prevents over-excitation artifacts and reduces implausible feature mixtures common to previous dCNN inversion approaches, permitting synthezing photographic content with increased visual plausibility. Unlike standard MRF-based texture synthesis, the combined system can both match and adapt local features with considerable variability, yielding results far out of reach of classic generative MRF methods.",
month =  "18~" # jan,
year =  2016,
annote = "- Amazing deep-style model<div><br></div><div>- The method : optimize the similarity between each patch of the reconstructed  image, and the nearest patch in the 'style' image, at some low-level CNN layer (while minimizing CNN difference with original image).</div><div><br></div><div>- Great results</div>",
archivePrefix = "arXiv",
primaryClass = "cs.CV",
eprint = "1601.04589"
}

@ARTICLE{Bissonette2008-vr,
title = "Double dissociation of the effects of medial and orbital prefrontal cortical lesions on attentional and affective shifts in mice",
author = "Bissonette, Gregory B and Martins, Gabriela J and Franz, Theresa M and Harper, Elizabeth S and Schoenbaum, Geoffrey and Powell, Elizabeth M",
affiliation = "Department of Anatomy and Neurobiology, University of Maryland School of Medicine, Baltimore, Maryland 21201, USA.",
abstract = "Many neuropsychiatric diseases are associated with cognitive rigidity linked to prefrontal dysfunction. For example, schizophrenia and Parkinson's disease are associated with performance deficits on the Wisconsin Card Sorting Test, which evaluates attentional set shifting. Although the genetic underpinnings of these disorders can be reproduced in mice, there are few models for testing the functional consequences. Here, we demonstrate that an analog of the Wisconsin Card Sorting Test, developed in marmosets and recently adapted to rats, is a behavioral model of prefrontal function in mice. Systematic analysis demonstrated that formation of the attentional set in mice is dependent on the number of problem sets. We found that mice, like rats and primates, exhibit both affective and attentional sets, and these functions are disrupted by neurotoxic damage to orbitofrontal and medial prefrontal cortical areas, respectively. These data are identical to studies in rats and similar to the deficits reported after prefrontal damage in a comparable task in marmosets. These results provide a behavioral model to assess prefrontal function in mice.",
journal = "J. Neurosci.",
volume =  28,
number =  44,
pages = "11124--11130",
month =  "29~" # oct,
year =  2008,
annote = "- Mice learn to dig at a specific odor, or tecture, to get food.<div><br></div><div>- After a while, you see that reversal learning b/w previously learnt odors is harder than learning for new pair of odors - mice have deceloped an ``affective set''</div><div><br></div><div>- Furthermore, after several learnings in the same dimension, it becomes harder to learn to discriminate in the other dimension : mice have developed an ``attentional set'' (i.e. learned the rule ``look at odor'')</div><div><br></div><div>- Mice are slower for both than rats</div><div><br></div><div>- Most importantly: OFC lesions make reversal learning harder, no effect on dimension switching</div><div>- mPFC lesions make dimension switching harder, no effect on reversal w/in dimension !!</div><div><br></div><div>- Similar to rats, marmoset (but see Rudebeck et al. 2013)</div>"
}

@MISC{noauthor_undated-fz,
title = "[No title]",
howpublished = "\url{https://www.researchgate.net/profile/Derek_Hamilton/publication/270597321_Behavioral_flexibility_in_rats_and_mice_Contributions_of_distinct_frontocortical_regions/links/54ca79600cf2c70ce521d9fc.pdf}",
note = "Accessed: 2016-1-21"
}

@ARTICLE{Lapish2015-so,
title = "Amphetamine Exerts {Dose-Dependent} Changes in Prefrontal Cortex Attractor Dynamics during Working Memory",
author = "Lapish, Christopher C and Balaguer-Ballester, Emili and Seamans, Jeremy K and Phillips, Anthony G and Durstewitz, Daniel",
affiliation = "Department of Psychology, Stark Neuroscience Institute, Institute for Mathematical Modeling and Computational Sciences, Indiana University-Purdue University Indianapolis, Indianapolis, Indiana 46202, clapish@iupui.edu. Faculty of Science and Technology, Bournemouth University, Poole, BH12 5BB, United Kingdom, Department of Theoretical Neuroscience, Bernstein Center for Computational Neuroscience, Central Institute of Mental Health, Medical Faculty Mannheim/Heidelberg University, D-68159 Mannheim, Germany, and. Department of Psychiatry, Djavad Mowafaghian Centre for Brain Health, University of British Columbia, Vancouver, British Columbia, Canada, V6T 1Z3. Department of Psychiatry, Djavad Mowafaghian Centre for Brain Health, University of British Columbia, Vancouver, British Columbia, Canada, V6T 1Z3. Department of Theoretical Neuroscience, Bernstein Center for Computational Neuroscience, Central Institute of Mental Health, Medical Faculty Mannheim/Heidelberg University, D-68159 Mannheim, Germany, and School of Computing and Mathematics, Faculty of Science and Environment, Plymouth University, Plymouth, PL4 8AA, United Kingdom.",
abstract = "Modulation of neural activity by monoamine neurotransmitters is thought to play an essential role in shaping computational neurodynamics in the neocortex, especially in prefrontal regions. Computational theories propose that monoamines may exert bidirectional (concentration-dependent) effects on cognition by altering prefrontal cortical attractor dynamics according to an inverted U-shaped function. To date, this hypothesis has not been addressed directly, in part because of the absence of appropriate statistical methods required to assess attractor-like behavior in vivo. The present study used a combination of advanced multivariate statistical, time series analysis, and machine learning methods to assess dynamic changes in network activity from multiple single-unit recordings from the medial prefrontal cortex (mPFC) of rats while the animals performed a foraging task guided by working memory after pretreatment with different doses of d-amphetamine (AMPH), which increases monoamine efflux in the mPFC. A dose-dependent, bidirectional effect of AMPH on neural dynamics in the mPFC was observed. Specifically, a 1.0 mg/kg dose of AMPH accentuated separation between task-epoch-specific population states and convergence toward these states. In contrast, a 3.3 mg/kg dose diminished separation and convergence toward task-epoch-specific population states, which was paralleled by deficits in cognitive performance. These results support the computationally derived hypothesis that moderate increases in monoamine efflux would enhance attractor stability, whereas high frontal monoamine levels would severely diminish it. Furthermore, they are consistent with the proposed inverted U-shaped and concentration-dependent modulation of cortical efficiency by monoamines.",
journal = "J. Neurosci.",
volume =  35,
number =  28,
pages = "10172--10187",
month =  "15~" # jul,
year =  2015,
annote = "- More evidence for the U-shaped effect of dopamine on mPFC function(see also the Arnsten /XJ Wang papers)<div><br></div><div>- Small dose of amphetamine (in ACC): better perf, slightly higher firing, high-order correlations are stronger, cortical states are better separated and more attractor-like</div><div><br></div><div>- Large dose of amphetamine: perf crashes, much lower firing, cortical states and trajectories are difficult to discern and less attractor-like</div><div><br></div><div>- Note that they use an ``enriched'' population state, with lags and products of units.</div>",
keywords = "dopamine; multiple single-unit recordings; neural computation; neural dynamics; neuromodulation; prefrontal cortex"
}

@ARTICLE{Amemiya2016-ct,
title = "Manipulating Decisiveness in Decision Making: Effects of Clonidine on Hippocampal Search Strategies",
author = "Amemiya, Seiichiro and Redish, A David",
abstract = "Decisiveness is the ability to commit to a decision quickly and efficiently; in contrast, indecision entails the repeated consideration of multiple alternative possibilities. In humans, the $\alpha$2-adrenergic receptor agonist clonidine increases decisiveness in tasks that require planning through unknown neural mechanisms. In rats, indecision is manifested as reorienting behaviors at choice points (vicarious trial and error [VTE]), during which hippocampal representations alternate between prospective options. To determine whether the increase in decisiveness driven by clonidine also entails changes in hippocampal search processes, we compared the effect of clonidine on spatial representations in hippocampal neural ensembles as rats passed through a T-shaped decision point. Consistent with previous experiments, hippocampal representations reflected both chosen and unchosen paths during VTE events under saline control conditions. Also, consistent with previous experiments, hippocampal representations reflected the chosen path more than the unchosen path when the animal did not show VTE at the choice point. Injection of clonidine suppressed the spatial representation of the unchosen path at the choice point on VTE laps and hastened the differentiation of spatial representations of the chosen path from the unchosen path on non-VTE laps to appear before reaching the choice point. These results suggest that the decisiveness seen under clonidine is due to limited exploration of potential options in hippocampus, and suggest novel roles for noradrenaline as a modulator of the hippocampal search processes.SIGNIFICANCE STATEMENT Clonidine, an $\alpha$2-adrenergic receptor agonist, which decreases the level of noradrenaline in vivo, has an interesting effect in humans and other animals: it makes them more decisive. However, the mechanisms by which clonidine makes them more decisive remain unknown. Researchers have speculated that clonidine limits the amount of mental search that subjects do when planning options. We test this hypothesis by measuring the mental search strategy in rats through hippocampal recordings. We find that clonidine limits the options searched by rats, suggesting that noradrenaline also plays a role in balancing exploration and exploitation in internally simulated behaviors, similar to its role in balancing exploration and exploitation in external behaviors.",
journal = "J. Neurosci.",
volume =  36,
number =  3,
pages = "814--827",
month =  "20~" # jan,
year =  2016,
annote = "10.1523/JNEUROSCI.2595-15.2016<div><br></div><div><br></div><div>- When exploring, at choice points, rats show vicarious trial and error (VTE) behavior (see Tolman)</div><div>- This is reflected in Hippocampus, which shows both chosen and non-chosen trajectories (more so when there is VTE)</div><div><br></div><div>- Under clonidine (Adrenalin/Epinephrin agonist), rats are more decisive, do less VTE</div><div><br></div><div>- This is reflected in the HPC: under clonidine, non-chosen paths are represented less when there is VTE, and separation chosen / non-chosen occurs earlier on non-VTE laps (?)</div>"
}

@ARTICLE{Arie2007-zc,
title = "Reinforcement learning of a continuous motor sequence with hidden states",
author = "Arie, Hiroaki and Ogata, Tetsuya and Tani, Jun and Sugano, Shigeki",
abstract = "Reinforcement learning is the scheme for unsupervised learning in which robots are expected to acquire behavior skills through self-explorations based on reward signals. There are some difficulties, however, in applying conventional reinforcement learning algorithms to motion control tasks of a robot because most algorithms are concerned with discrete state space and based on the assumption of complete observability of the state. Real-world environments often have partial observablility; therefore, robots have to estimate the unobservable hidden states. This paper proposes a method to solve these two problems by combining the reinforcement learning algorithm and a learning algorithm for a continuous time recurrent neural network (CTRNN). The CTRNN can learn spatio-temporal structures in a continuous time and space domain, and can preserve the contextual flow by a self-organizing appropriate internal memory structure. This enables the robot to deal with the hidden state problem. We carried out an experiment on the pendulum swing-up task without rotational speed information. As a result, this task is accomplished in several hundred trials using the proposed algorithm. In addition, it is shown that the information about the rotational speed of the pendulum, which is considered as a hidden state, is estimated and encoded on the activation of a context neuron.",
journal = "Adv. Robot.",
volume =  21,
number =  10,
pages = "1215--1229",
year =  2007,
annote = "- Reinforcement learning in a recurrent neural network (CTRNN)<div><br></div><div>- Seems to be based on node-perturbation (error to be reduced by backpropagation = output-perturbation * RPE</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wyvell2001-nz,
title = "Incentive Sensitization by Previous Amphetamine Exposure: Increased {Cue-Triggered} ``Wanting'' for Sucrose Reward",
author = "Wyvell, Cindy L and Berridge, Kent C",
abstract = "We reported previously that an amphetamine microinjection into the nucleus accumbens enables Pavlovian reward cues in a conditioned incentive paradigm to trigger excessive instrumental pursuit. Here we show that sensitization caused by previous amphetamine administration also causes reward cues to trigger excessive pursuit of their associated reward, even when sensitized rats are tested in a drug-free state. Rats learned to lever press for sucrose pellets, and they separately learned to associate sucrose pellets with Pavlovian cues (30 sec auditory cues). Amphetamine sensitization was induced by six daily injections of amphetamine (3 mg/kg, i.p.; controls received saline). Rats were tested for lever pressing under extinction conditions 10 d later, after a bilateral microinjection of intra-accumbens vehicle or amphetamine (5 $\mu$g/0.5 $\mu$l per side). Cue-triggered pursuit of sucrose reward was assessed by increases in pressing on the sucrose-associated lever during intermittent presentations of a free conditioned stimulus (CS+) sucrose cue. Sensitized rats pressed at normal levels during baseline and during the CS−, but the CS+ triggered 100\% greater increases in pressing from sensitized rats than from control rats after vehicle microinjection. Sensitization therefore enhanced the incentive salience attributed to the CS+ even when rats were tested while drug-free. For control rats, a microinjection of intra-accumbens amphetamine was needed to produce the same enhancement of cue-triggered reward ``wanting.'' The amphetamine microinjection also interacted synergistically in sensitized rats to produce intrusive cue-triggered pursuit behaviors (e.g., investigatory sniffing) that interfered with goal-directed lever pressing. These results support the incentive-sensitization theory postulate that sensitization causes excessive cue-triggered ``wanting'' for an associated reward.",
journal = "J. Neurosci.",
volume =  21,
number =  19,
pages = "7831--7840",
month =  "1~" # oct,
year =  2001,
annote = "<div>- Drug sensitization (increase in the energizing effects of a reward-predicting cue on instrumental behavior) is long lasting even after drug cessation</div><div><br></div><div>-  A Pavlovian cue is associated with sucrose. Separately, rats are trained to press lever for sucrose. Now, showing cue selectively energizes lever pressing. (Basic PIT)</div><div><br></div>- Previously shown: Amphetamine in NAcc mShell dramatically increases the increase in lever pressing (selectively - ``liking'' doesn't increase)<div><br></div><div>- Here: The effects of Amphetamine are long lasting, persist for many days even in drug-free state!</div><div><br></div><div>- Test rats 10d after the multi-day amphetamine sessions: rats that were amphetaminized still show much more energizing in lever pressing when cue is presented !</div><div><br></div><div>[ Possible explanation: the amphetamine somehow basically increase the potentiation of cue stimulus to mVTA, so next time Cue shown it gives more DA in Nacc mShell ? But the drug is in NAcc mSh... So maybe it potentiates stimulus-to-NAcc mShell itself, so you don't need the DA boost anymore?... To test: does it still occur if DA is killed? Or more realistically, if you disconnect mVTA from NAcc mSh?]</div><div>[ mSHELL IS SEAT OF PIT !! ]</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dalley2005-nz,
title = "Time-limited modulation of appetitive Pavlovian memory by {D1} and {NMDA} receptors in the nucleus accumbens",
author = "Dalley, Jeffrey W and L{\"{a}}{\"{a}}ne, Kristjan and Theobald, David E H and Armstrong, Hannah C and Corlett, Philip R and Chudasama, Yogita and Robbins, Trevor W",
affiliation = "Department of Experimental Psychology, Downing Street, University of Cambridge, Cambridge CB2 3EB, United Kingdom. jwd20@cam.ac.uk",
abstract = "Recent research has implicated the nucleus accumbens (NAc) in consolidating recently acquired goal-directed appetitive memories, including spatial learning and other instrumental processes. However, an important but unresolved issue is whether this forebrain structure also contributes to the consolidation of fundamental forms of appetitive learning acquired by Pavlovian associative processes. In addition, although dopaminergic and glutamatergic influences in the NAc have been implicated in instrumental learning, it is unclear whether similar mechanisms operate during Pavlovian conditioning. To evaluate these issues, the effects of posttraining intra-NAc infusions of D1, D2, and NMDA receptor antagonists, as well as d-amphetamine, were determined on Pavlovian autoshaping in rats, which assesses learning by discriminated approach behavior to a visual conditioned stimulus predictive of food reward. Intracerebral infusions were given either immediately after each conditioning session to disrupt early memory consolidation or after a delay of 24 h. Findings indicate that immediate, but not delayed, infusions of both D1 (SCH 23390) and NMDA (AP-5) receptor antagonists significantly impair learning on this task. By contrast, amphetamine and the D2 receptor antagonist sulpiride were without significant effect. These findings provide the most direct demonstration to date that D1 and NMDA receptors in the NAc contribute to, and are necessary for, the early consolidation of appetitive Pavlovian learning.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
volume =  102,
number =  17,
pages = "6189--6194",
month =  "26~" # apr,
year =  2005,
annote = "- DA-- in NAcc selectively disrupts conditioned approach to a CS associated w/ food...<div><br></div><div>- Even if you disrupt the DA just after the learning sessions (but not 24 hrs after !)</div><div><br></div><div>- So DA in NAcc is also required in memory consolidation  !</div><div><br></div><div>- Difficulty: Core, not Shell ! Contradiction with Ikemoto 2007, who seems to ascribe such effects to Shell only?... Not necessarily... may have been instrumental-like? ....</div>"
}

@INCOLLECTION{Wolfe2007-qv,
title = "Guided search 4.0",
booktitle = "Integrated models of cognitive systems",
author = "Wolfe, Jeremy M",
editor = "Gray, W",
publisher = "Oxford University Press New York, NY",
pages = "99--119",
year =  2007
}

@ARTICLE{Green1956-zx,
title = "Color coding in a visual search task",
author = "Green, B F and Anderson, L K",
journal = "J. Exp. Psychol.",
volume =  51,
number =  1,
pages = "19--24",
month =  jan,
year =  1956,
keywords = "COLOR; LEARNING"
}

@ARTICLE{Yang2009-xq,
title = "Visual search is guided to categorically-defined targets",
author = "Yang, Hyejin and Zelinsky, Gregory J",
affiliation = "Department of Psychology, Stony Brook University, Stony Brook, NY 11794, United States.",
abstract = "To determine whether categorical search is guided we had subjects search for teddy bear targets either with a target preview (specific condition) or without (categorical condition). Distractors were random realistic objects. Although subjects searched longer and made more eye movements in the categorical condition, targets were fixated far sooner than was expected by chance. By varying target repetition we also determined that this categorical guidance was not due to guidance from specific previously viewed targets. We conclude that search is guided to categorically-defined targets, and that this guidance uses a categorical model composed of features common to the target class.",
journal = "Vision Res.",
volume =  49,
number =  16,
pages = "2095--2103",
month =  jul,
year =  2009
}

@ARTICLE{Bichot2005-ph,
title = "Parallel and serial neural mechanisms for visual search in macaque area {V4}",
author = "Bichot, Narcisse P and Rossi, Andrew F and Desimone, Robert",
affiliation = "Laboratory of Neuropsychology, National Institute of Mental Health (NIMH), National Institutes of Health, Bethesda, MD 20892, USA. bichotn@mail.nih.gov",
abstract = "To find a target object in a crowded scene, a face in a crowd for example, the visual system might turn the neural representation of each object on and off in a serial fashion, testing each representation against a template of the target item. Alternatively, it might allow the processing of all objects in parallel but bias activity in favor of those neurons that represent critical features of the target, until the target emerges from the background. To test these possibilities, we recorded neurons in area V4 of monkeys freely scanning a complex array to find a target defined by color, shape, or both. Throughout the period of searching, neurons gave enhanced responses and synchronized their activity in the gamma range whenever a preferred stimulus in their receptive field matched a feature of the target, as predicted by parallel models. Neurons also gave enhanced responses to candidate targets that were selected for saccades, or foveation, reflecting a serial component of visual search. Thus, serial and parallel mechanisms of response enhancement and neural synchrony work together to identify objects in a scene. To find a target object in a crowded scene, a face in a crowd for example, the visual system might turn the neural representation of each object on and off in a serial fashion, testing each representation against a template of the target item. Alternatively, it might allow the processing of all objects in parallel but bias activity in favor of those neurons that represent critical features of the target, until the target emerges from the background. To test these possibilities, we recorded neurons in area V4 of monkeys freely scanning a complex array to find a target defined by color, shape, or both. Throughout the period of searching, neurons gave enhanced responses and synchronized their activity in the gamma range whenever a preferred stimulus in their receptive field matched a feature of the target, as predicted by parallel models. Neurons also gave enhanced responses to candidate targets that were selected for saccades, or foveation, reflecting a serial component of visual search. Thus, serial and parallel mechanisms of response enhancement and neural synchrony work together to identify objects in a scene.",
journal = "Science",
volume =  308,
number =  5721,
pages = "529--534",
month =  "22~" # apr,
year =  2005
}

@ARTICLE{Martinez-Trujillo2002-ew,
title = "Attentional modulation strength in cortical area {MT} depends on stimulus contrast",
author = "Mart\'{\i}nez-Trujillo, Julio and Treue, Stefan",
affiliation = "Center for Vision Research, York University, Toronto Ontario, Canada.",
abstract = "The attentional modulation of sensory information processing in the visual system is the result of top-down influences, which can cause a multiplicative modulation of the firing rate of sensory neurons in extrastriate visual cortex, an effect reminiscent of the bottom-up effect of changes in stimulus contrast. This similarity could simply reflect the multiplicity of both effects. But, here we show that in direction-selective neurons in monkey visual cortical area MT, stimulus and attentional effects share a nonlinearity. These neurons show higher response gain for both contrast and attentional changes for intermediate contrast stimuli and smaller gain for low- and high-contrast stimuli. This finding suggests a close relationship between the neural encoding of stimulus contrast and the modulating effect of the behavioral relevance of stimuli.",
journal = "Neuron",
volume =  35,
number =  2,
pages = "365--370",
month =  "18~" # jul,
year =  2002,
annote = "- Claims that attention in MT is contrast-gain<div><br></div><div>-But see Williford \& Maunsell</div>"
}

@ARTICLE{Reynolds2000-nb,
title = "Attention increases sensitivity of {V4} neurons",
author = "Reynolds, J H and Pasternak, T and Desimone, R",
affiliation = "National Institute of Mental Health, National Institutes of Health, Bethesda, Maryland 20892, USA.",
abstract = "When attention is directed to a location in the visual field, sensitivity to stimuli at that location is increased. At the neuronal level, this could arise either through a multiplicative increase in firing rate or through an increase in the effective strength of the stimulus. To test conflicting predictions of these alternative models, we recorded responses of V4 neurons to stimuli across a range of luminance contrasts and measured the change in response when monkeys attended to them in order to discriminate a target stimulus from nontargets. Attention caused greater increases in response at low contrast than at high contrast, consistent with an increase in effective stimulus strength. On average, attention increased the effective contrast of the attended stimulus by a factor of 1.51, an increase of 51\% of its physical contrast.",
journal = "Neuron",
volume =  26,
number =  3,
pages = "703--714",
month =  jun,
year =  2000,
annote = "- Claims that attention in V4 is contrast-gain<div><br></div><div>- But see Williford \& Maunsell</div><div><br></div>"
}

@ARTICLE{Thiele2009-oo,
title = "Additive effects of attention and stimulus contrast in primary visual cortex",
author = "Thiele, Alexander and Pooresmaeili, Arezoo and Delicato, Louise S and Herrero, Jose L and Roelfsema, Pieter R",
affiliation = "Institute of Neuroscience, Newcastle University, Newcastle upon Tyne, NE2 4HH, UK. alex.thiele@ncl.ac.uk",
abstract = "Previous studies have proposed a variety of mechanisms by which attention influences neuronal activity. Here we investigated the mechanisms of attention in the striate cortex of monkeys performing a spatial or an object-based attention task at various stimulus contrasts and compared neuronal contrast response functions with and without attention. Our data are best described by an ``additive'' interaction: The influence of attention on the neuronal response is relatively independent of the stimulus contrast, at least when the stimulus has enough contrast to become visible. This shows that attention adds to the neuronal responses in a largely contrast invariant manner. These data support recent functional magnetic resonance imaging studies and suggest that feedback from higher areas exerts a constant attentional drive that is mostly task not stimulus driven.",
journal = "Cereb. Cortex",
volume =  19,
number =  12,
pages = "2970--2981",
month =  dec,
year =  2009
}

@ARTICLE{Roelfsema1998-sj,
title = "Object-based attention in the primary visual cortex of the macaque monkey",
author = "Roelfsema, P R and Lamme, V A and Spekreijse, H",
affiliation = "Graduate School Neurosciences Amsterdam, Department of Visual System Analysis, Academic Medical Center, The Netherlands. p.roelfsema@ioi.knaw.nl",
abstract = "Typical natural visual scenes contain many objects, which need to be segregated from each other and from the background. Present theories subdivide the processes responsible for this segregation into a pre-attentive and attentive system. The pre-attentive system segregates image regions that 'pop out' rapidly and in parallel across the visual field. In the primary visual cortex, responses to pre-attentively selected image regions are enhanced. When objects do not segregate automatically from the rest of the image, the time-consuming attentive system is recruited. Here we investigate whether attentive selection is also associated with a modulation of firing rates in area V1 of the brain in monkeys trained to perform a curve-tracing task. Neuronal responses to the various segments of a target curve were simultaneously enhanced relative to responses evoked by a distractor curve, even if the two curves crossed each other. This indicates that object-based attention is associated with a response enhancement at the earliest level of the visual cortical processing hierarchy.",
journal = "Nature",
volume =  395,
number =  6700,
pages = "376--381",
month =  "24~" # sep,
year =  1998
}

@ARTICLE{Berke2011-nn,
title = "Functional properties of striatal fast-spiking interneurons",
author = "Berke, Joshua D",
affiliation = "Neuroscience Program, Department of Psychology, University of Michigan Ann Arbor, MI, USA.",
abstract = "Striatal fast-spiking interneurons (FSIs) have a major influence over behavioral output, and a deficit in these cells has been observed in dystonia and Tourette syndrome. FSIs receive cortical input, are coupled together by gap junctions, and make perisomatic GABAergic synapses onto many nearby projection neurons. Despite being critical components of striatal microcircuits, until recently little was known about FSI activity in behaving animals. Striatal FSIs are near-continuously active in awake rodents, but even neighboring FSIs show uncorrelated activity most of the time. A coordinated ``pulse'' of increased FSI firing occurs throughout striatum when rats initiate one chosen action while suppressing a highly trained alternative. This pulse coincides with a drop in globus pallidus population activity, suggesting that pallidostriatal disinhibition may have a important role in timing or coordinating action execution. In addition to changes in firing rate, FSIs show behavior-linked modulation of spike timing. The variability of inter-spike intervals decreases markedly following instruction cues, and FSIs also participate in fast striatal oscillations that are linked to rewarding events and dopaminergic drugs. These studies have revealed novel and unexpected properties of FSIs, that should help inform new models of striatal information processing in both normal and aberrant conditions.",
journal = "Front. Syst. Neurosci.",
volume =  5,
pages = "45",
month =  "20~" # jun,
year =  2011,
annote = "- Fast-spiking inhibitory neurons in striatum<div><br></div><div>- They receive from CTX, usually they are vey heterogenous</div><div><br></div><div>- However, large synchronous burst of activity on choice execution (when choice is between two well-trained actions, following a delay)</div><div><br></div><div>- Seems to involve Pallium-Striatal disinhibition, rather than CTX input ??</div><div><br></div>",
keywords = "GABA; amphetamine; antipsychotic; basal ganglia; dopamine; gamma oscillations; interneuron; striatum"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ferenczi2016-at,
title = "Prefrontal cortical regulation of brainwide circuit dynamics and reward-related behavior",
author = "Ferenczi, Emily A and Zalocusky, Kelly A and Liston, Conor and Grosenick, Logan and Warden, Melissa R and Amatya, Debha and Katovich, Kiefer and Mehta, Hershel and Patenaude, Brian and Ramakrishnan, Charu and Kalanithi, Paul and Etkin, Amit and Knutson, Brian and Glover, Gary H and Deisseroth, Karl",
affiliation = "Department of Bioengineering, Stanford University, Stanford, CA 94305, USA. Neurosciences Program, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA. Neurosciences Program, Stanford University, Stanford, CA 94305, USA. Brain Mind Research Institute, Weill Cornell Medical College, New York, NY 10065, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA. Neurosciences Program, Stanford University, Stanford, CA 94305, USA. Department of Neurobiology and Behavior, Cornell University, Ithaca, NY 14853, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA. Department of Psychology, Stanford University, Stanford, CA 94305, USA. Department of Psychology, Stanford University, Stanford, CA 94305, USA. Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA. Department of Neurosurgery, Stanford University, Stanford, CA 94305, USA. Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA. Department of Psychology, Stanford University, Stanford, CA 94305, USA. Department of Radiology, Stanford University, Stanford, CA, 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA. Department of Neurobiology and Behavior, Cornell University, Ithaca, NY 14853, USA. Howard Hughes Medical Institute, Stanford University, Stanford, CA, 94305, USA. deissero@stanford.edu.",
abstract = "Motivation for reward drives adaptive behaviors, whereas impairment of reward perception and experience (anhedonia) can contribute to psychiatric diseases, including depression and schizophrenia. We sought to test the hypothesis that the medial prefrontal cortex (mPFC) controls interactions among specific subcortical regions that govern hedonic responses. By using optogenetic functional magnetic resonance imaging to locally manipulate but globally visualize neural activity in rats, we found that dopamine neuron stimulation drives striatal activity, whereas locally increased mPFC excitability reduces this striatal response and inhibits the behavioral drive for dopaminergic stimulation. This chronic mPFC overactivity also stably suppresses natural reward-motivated behaviors and induces specific new brainwide functional interactions, which predict the degree of anhedonia in individuals. These findings describe a mechanism by which mPFC modulates expression of reward-seeking behavior, by regulating the dynamical interactions between specific distant subcortical regions.",
journal = "Science",
volume =  351,
number =  6268,
pages = "aac9698",
month =  "1~" # jan,
year =  2016,
annote = "- Increasing Excitability in mPFC (mostly IL) suppresses reward-driven behavior (less preference for sucrose water, less social interaction) <div><br></div><div>- It also reduces the response of striatum to VTA stim,  and conditioned Place Preference induced by VTA stim !!</div><div><br></div><div>- Increasing mPFC excitability increases connectivity w/ Orbital CTX (LO + OFC) and striatum</div><div><br></div><div>- connectivity increase of mPFC with OFC and Ventral, but NOT Dorsal Striatum predicts the amount of anhedonic  effect on behavior !</div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Berridge2009-da,
title = "Wanting and Liking: Observations from the Neuroscience and Psychology Laboratory",
author = "Berridge, Kent C",
affiliation = "University of Michigan, USA.",
abstract = "Different brain mechanisms seem to mediate wanting and liking for the same reward. This may have implications for the modular nature of mental processes, and for understanding addictions, compulsions, free will and other aspects of desire. A few wanting and liking phenomena are presented here, together with discussion of some of these implications.",
journal = "Inquiry",
volume =  52,
number =  4,
pages = "378",
month =  "1~" # aug,
year =  2009,
annote = "- Incentive salience (of a stimulus) is the ability of a cue-stimulus to trigger bursts of ``wanting'' (more lever presses!) for its associated reward - and sometimes, even for itself (approaching/gnawing at the cue itself)<div><br></div><div><br></div><div>- Cue can become the actual target of wanting</div><div><br></div><div>- DA++ specifically increases the cue-triggered wanting - not (usually) wanting in general (sometimes it does)</div><div><br></div><div>- IS also makes you want to work for obtaining the cue itself (also increased by DA) [seems very rational, at least in evolutionary sense? cue associated w/ reward may be necessary condition for obtaining reward..]</div><div>(Gives example of miser attracted to the coins, or academics attracted to the 'symbols' of actual academic success...)</div><div><br></div><div><br></div><div>- DA is the transmitter that most selectively activates ``wanting''</div><div><br></div><div>- Addiction may largely  involve  massively increased cue-triggered ``wanting'' (of drugs, in response to drug cues) through sensitization of VTA DA cells</div><div>- Not constantly hyperactive, but hyperactive in response to drugs or drug cues</div><div><br></div><div>- Liking differs from wanting; ``Liking'': circuit of ``liking'' hotspots seems to be a small subset of the ``Wanting'' circuit!</div><div><br></div><div>- Thus, ``liking'' ++ generally => ``wanting''++, but the reverse not true: liking subsystem more 'finicky', more easily disrupted if one hotspot is blocked!</div><div><br></div><div>- Liking-enhancing hotspots are generally opioid or endocannabinoid receptive...</div><div><br></div><div>- Sometimes ``wanting'' may become unspecific and general to irrelevant stimuli.</div><div><br></div><div>- Subliminal, sub-conscious ``happy'' faces won't make you feel more or less happy - but they will make you like \& want more a subsequent rewarding stimulus (fruit juice) !!! Winkielman \& Berridge 2004.  Also, sub-threshold doses of cocaine are perceived as ``empty'' by addicts, yet still increase wanting/working to get next dose !!</div><div><br></div><div>- Stimulation of different regions of NAcc can generate appetive behavior, but also fearful / active-avoidance behavior ! Modulated by environment ! </div><div><br></div><div>- Soothing environment -> 90\% of NAcc medial shell is appetive / ``desire''; Stressful environment (Iggy Pop!)  -> 90\% of NAcc medial shell is fearful / ``dread'' !    Reynolds \& Berridge 2008</div><div><br></div><div>[Consistent with Ramirez \& al J Neurosci  2015, showing that active avoiance requires Basal Amygdala - NAcc Shell circuit]</div><div><br></div>"
}

@ARTICLE{Pillow_undated-rp,
title = "Adaptive Bayesian methods for closed-loop neurophysiology",
author = "Pillow, Jonathan W and Park, Mijung"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Antzoulatos2011-ik,
title = "Differences between neural activity in prefrontal cortex and striatum during learning of novel abstract categories",
author = "Antzoulatos, Evan G and Miller, Earl K",
affiliation = "The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA 02139, USA.",
abstract = "Learning to classify diverse experiences into meaningful groups, like categories, is fundamental to normal cognition. To understand its neural basis, we simultaneously recorded from multiple electrodes in lateral prefrontal cortex and dorsal striatum, two interconnected brain structures critical for learning. Each day, monkeys learned to associate novel abstract, dot-based categories with a right versus left saccade. Early on, when they could acquire specific stimulus-response associations, striatum activity was an earlier predictor of the corresponding saccade. However, as the number of exemplars increased and monkeys had to learn to classify them, PFC activity began to predict the saccade associated with each category before the striatum. While monkeys were categorizing novel exemplars at a high rate, PFC activity was a strong predictor of their corresponding saccade early in the trial before the striatal neurons. These results suggest that striatum plays a greater role in stimulus-response association and PFC in abstraction of categories.",
journal = "Neuron",
volume =  71,
number =  2,
pages = "243--249",
month =  "28~" # jul,
year =  2011,
annote = "- Train monkeys to categorize between two 'families' of dot patterns<div><br></div><div>- Initially there is only 1 exemplar per family. So you can get away with Stimulus-Response associations</div><div><br></div><div>- But later on it's mostly novel exemplars never seen before, so you need categorization ! (And the monkeys do learn it well)</div><div><br></div><div>- In early, S-R mode, Striatum encodes saccade information very early on stimulus presentation, not PFC (PFC , but not Striatum, encodes response during delay/response time)</div><div><br></div><div>- this is NOT just a motor decision: on error trials, the encoding vanishes! (also in PFC...)</div><div><br></div><div>- Later on, when performance is high and categorization necessary, very little early info in Striatum, but strong early info in PFC! </div><div><br></div><div>- Also, the delay/decision-time encoding is now present both in PFC and Striatum (early in learning, it's only in PFC, not much in Stri)</div><div><br></div><div>- Interpretation: the Striatum 'teaches' the PFC about proper categories....?</div>"
}

@ARTICLE{Bichot2015-kj,
title = "A Source for {Feature-Based} Attention in the Prefrontal Cortex",
author = "Bichot, Narcisse P and Heard, Matthew T and DeGennaro, Ellen M and Desimone, Robert",
affiliation = "Department of Brain and Cognitive Sciences, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. Electronic address: bichot@mit.edu. Department of Brain and Cognitive Sciences, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. Department of Brain and Cognitive Sciences, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. Department of Brain and Cognitive Sciences, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139, USA.",
abstract = "In cluttered scenes, we can use feature-based attention to quickly locate a target object. To understand how feature attention is used to find and select objects for action, we focused on the ventral prearcuate (VPA) region of prefrontal cortex. In a visual search task, VPA cells responded selectively to search cues, maintained their feature selectivity throughout the delay and subsequent saccades, and discriminated the search target in their receptive fields with a time course earlier than in FEF or IT cortex. Inactivation of VPA impaired the animals' ability to find targets, and simultaneous recordings in FEF revealed that the effects of feature attention were eliminated while leaving the effects of spatial attention in FEF intact. Altogether, the results suggest that VPA neurons compute the locations of objects with the features sought and send this information to FEF to guide eye movements to those relevant stimuli.",
journal = "Neuron",
volume =  88,
number =  4,
pages = "832--844",
month =  "18~" # nov,
year =  2015
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Brito2016-qx,
title = "Nonlinear Hebbian learning as a unifying principle in receptive field formation",
author = "Brito, Carlos S N and Gerstner, Wulfram",
abstract = "The development of sensory receptive fields has been modeled in the past by a variety of models including normative models such as sparse coding or independent component analysis and bottom-up models such as spike-timing dependent plasticity or the Bienenstock-Cooper-Munro model of synaptic plasticity. Here we show that the above variety of approaches can all be unified into a single common principle, namely Nonlinear Hebbian Learning. When Nonlinear Hebbian Learning is applied to natural images, receptive field shapes were strongly constrained by the input statistics and preprocessing, but exhibited only modest variation across different choices of nonlinearities in neuron models or synaptic plasticity rules. Neither overcompleteness nor sparse network activity are necessary for the development of localized receptive fields. The analysis of alternative sensory modalities such as auditory models or V2 development lead to the same conclusions. In all examples, receptive fields can be predicted a priori by reformulating an abstract model as nonlinear Hebbian learning. Thus nonlinear Hebbian learning and natural statistics can account for many aspects of receptive field formation across models and sensory modalities.",
month =  "4~" # jan,
year =  2016,
annote = "- This is beautiful.<div><br></div><div>- Almost all forms of Hebbian learning, in various types of networks (BCM, sparse coding, ICA, etc.) can be summarized as a simple equation :  dw ~= x f(w' x), where f=g(h(x)) combines the plasticity and responses nonlinearities</div><div><br></div><div>- Furthermore, when you perform Hebbian learning dw = x f(w' x), you are actually finding the w that maximizes < F(w' x) >, where <> is expectation over input statistics and F is the integral of f (old result on projection pursuit - don't understand it, but plausible from a gradient-descent perspective)</div><div><br></div><div>- As it happens, w arranged in localized oriented edges  produce large values of < F(w' x) > (in comparison to, say, random weights or PCA-like non-localized oriented edge), for many different types of f / F !</div><div><br></div><div>- The suitability of a f/F for learning features can be measured by a how much a certain F is larger for more-kurtotic inputs (because interesting features are expected to be more kurtotic): if more-kurtotic maximizes F, then w will move towards more-kurtotic-producing RFs!</div><div><br></div><div>- So you can predict whether a given algo will learn ``good'' RFs !!!</div>",
archivePrefix = "arXiv",
primaryClass = "q-bio.NC",
eprint = "1601.00701"
}

@ARTICLE{Makhzani2015-up,
title = "Adversarial Autoencoders",
author = "Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian",
abstract = "In this paper we propose a new method for regularizing autoencoders by imposing an arbitrary prior on the latent representation of the autoencoder. Our method, named ``adversarial autoencoder'', uses the recently proposed generative adversarial networks (GAN) in order to match the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior. Matching the aggregated posterior to the prior ensures that there are no ``holes'' in the prior, and generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how adversarial autoencoders can be used to disentangle style and content of images and achieve competitive generative performance on MNIST, Street View House Numbers and Toronto Face datasets.",
month =  "18~" # nov,
year =  2015,
annote = "- This is a method to have auto-encoders, in which the distribution of intermediate 'encoded' vectors can be made to fit any arbitrary pre-defined distribution<div><br></div><div>- Apparently this is useful (presumably to allow for better 'walk' along the encoded inputs, etc.)</div><div><br></div><div>- Can be used with any desired distribution, even non-analytic ones, as long as you can sample from it</div><div><br></div><div>- Uses adversarial networks to tune the encoder so that its output distribution becomes indistinguishable from the target distribution to a discriminator network</div>",
archivePrefix = "arXiv",
primaryClass = "cs.LG",
eprint = "1511.05644"
}

@ARTICLE{Gardner2015-dm,
title = "Deep Manifold Traversal: Changing Labels with Convolutional Features",
author = "Gardner, Jacob R and Kusner, Matt J and Li, Yixuan and Upchurch, Paul and Weinberger, Kilian Q and Hopcroft, John E",
abstract = "Machine learning is increasingly used in high impact applications such as prediction of hospital re-admission, cancer screening or bio-medical research applications. As predictions become increasingly accurate, practitioners may be interested in identifying actionable changes to inputs in order to alter their class membership. For example, a doctor might want to know what changes to a patient's status would predict him/her to not be re-admitted to the hospital soon. Szegedy et al. (2013b) demonstrated that identifying such changes can be very hard in image classification tasks. In fact, tiny, imperceptible changes can result in completely different predictions without any change to the true class label of the input. In this paper we ask the question if we can make small but meaningful changes in order to truly alter the class membership of images from a source class to a target class. To this end we propose deep manifold traversal, a method that learns the manifold of natural images and provides an effective mechanism to move images from one area (dominated by the source class) to another (dominated by the target class).The resulting algorithm is surprisingly effective and versatile. It allows unrestricted movements along the image manifold and only requires few images from source and target to identify meaningful changes. We demonstrate that the exact same procedure can be used to change an individual's appearance of age, facial expressions or even recolor black and white images.",
month =  "19~" # nov,
year =  2015,
annote = "- You find a 'manifold' of natural images within the much larger pixel space, then you move one image to various regions of that manifold associated with your target concept (i.e. towards 'old people', 'frowning', etc.)<div><br></div><div>- The manifold mapper is just PCA on the vector of low-level features from a CNN !</div><div><br></div><div>- Then to move image around you 'optimize' the images to reduce a measure that tells whether they are from a certain distribution (the source one - vectors from images corresponding to the 'source' concept) or another (the target one - vectors from images corresponding to the 'target' concept) - with various regularization terms.</div><div><br></div><div>- Sufficient to get pretty nice images of a 'frowning' or 'younger' Harrisson Ford, also good colorization of images !</div>",
archivePrefix = "arXiv",
primaryClass = "cs.LG",
eprint = "1511.06421"
}

@ARTICLE{Gal2015-un,
title = "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks",
author = "Gal, Yarin",
abstract = "A long strand of empirical research has claimed that dropout cannot be applied between the recurrent connections of a recurrent neural network (RNN). The reasoning has been that the noise hinders the network's ability to model sequences, and instead should be applied to the RNN's inputs and outputs alone. But dropout is a vital tool for regularisation, and without dropout in recurrent layers our models overfit quickly. In this paper we show that a recently developed theoretical framework, casting dropout as approximate Bayesian inference, can give us mathematically grounded tools to apply dropout within the recurrent layers. We apply our new dropout technique in long short-term memory (LSTM) networks and show that the new approach significantly outperforms existing techniques.",
month =  "16~" # dec,
year =  2015,
annote = "- If you want to use dropout in an RNN, use the same dropout mask at each timestep throughout an episode?<div><br></div><div>- Also nice introduction to Bayesian neural networks + variational stuff</div>",
archivePrefix = "arXiv",
primaryClass = "stat.ML",
eprint = "1512.05287"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Glangetas2015-mm,
title = "Ventral Subiculum Stimulation Promotes Persistent Hyperactivity of Dopamine Neurons and Facilitates Behavioral Effects of Cocaine",
author = "Glangetas, Christelle and Fois, Giulia R and Jalabert, Marion and Lecca, Salvatore and Valentinova, Kristina and Meye, Frank J and Diana, Marco and Faure, Philippe and Mameli, Manuel and Caille, St\'{e}phanie and Georges, Fran\c{c}ois",
affiliation = "Universit\'{e} de Bordeaux, Interdisciplinary Institute for Neuroscience, UMR5297, 33076 Bordeaux, France; Centre National de la Recherche Scientifique, Interdisciplinary Institute for Neuroscience, UMR 5297, 33076 Bordeaux, France. Universit\'{e} de Bordeaux, Interdisciplinary Institute for Neuroscience, UMR5297, 33076 Bordeaux, France; Centre National de la Recherche Scientifique, Interdisciplinary Institute for Neuroscience, UMR 5297, 33076 Bordeaux, France. Universit\'{e} de la M\'{e}diterran\'{e}e, UMR S901, Aix-Marseille 2, 13009 Marseille, France; INSERM-INMED, UMR 901, 13009 Marseille, France. Institut du Fer a Moulin, 75005 Paris, France; INSERM/UPMC, UMR-S 839, 75005 Paris, France. Institut du Fer a Moulin, 75005 Paris, France; INSERM/UPMC, UMR-S 839, 75005 Paris, France. Institut du Fer a Moulin, 75005 Paris, France; INSERM/UPMC, UMR-S 839, 75005 Paris, France. ``G. Minardi'' Cognitive Neuroscience Laboratory, Department of Chemistry and Pharmacy, University of Sassari, 07100 Sassari, Italy. CNRS, UMR8246 NPS, 75005 Paris, France; Sorbonne Universit\'{e}s, UPMC Univ Paris 06, UM119, NPS, 75005 Paris, France; INSERM, U1130 NPS, 75005 Paris, France. Institut du Fer a Moulin, 75005 Paris, France; INSERM/UPMC, UMR-S 839, 75005 Paris, France. Universit\'{e} de Bordeaux, INCIA, BP31, 33076 Bordeaux, France; CNRS, UMR5287 INCIA, 33076 Bordeaux, France. Universit\'{e} de Bordeaux, Interdisciplinary Institute for Neuroscience, UMR5297, 33076 Bordeaux, France; Centre National de la Recherche Scientifique, Interdisciplinary Institute for Neuroscience, UMR 5297, 33076 Bordeaux, France. Electronic address: francois.georges@u-bordeaux.fr.",
abstract = "The ventral subiculum (vSUB) plays a key role in addiction, and identifying the neuronal circuits and synaptic mechanisms by which vSUB alters the excitability of dopamine neurons is a necessary step to understand the motor changes induced by cocaine. Here, we report that high-frequency stimulation of the vSUB (HFSvSUB) over-activates ventral tegmental area (VTA) dopamine neurons in vivo and triggers long-lasting modifications of synaptic transmission measured ex vivo. This potentiation is caused by NMDA-dependent plastic changes occurring in the bed nucleus of the stria terminalis (BNST). Finally, we report that the modification of the BNST-VTA neural circuits induced by HFSvSUB potentiates locomotor activity induced by a sub-threshold dose of cocaine. Our findings unravel a neuronal circuit encoding behavioral effects of cocaine in rats and highlight the importance of adaptive modifications in the BNST, a structure that influences motivated behavior as well as maladaptive behaviors associated with addiction.",
journal = "Cell Rep.",
month =  "23~" # nov,
year =  2015,
annote = "- vSub (output of ventral hippocampus) stim excites VTA and produces DA release in NAcc, increasing locomotion <div><br></div><div>- Here they show that it's indirect, through plastic changes in the BNST.</div><div><br></div><div>- So there are 2 pathways from vSub to VTA: vSub-VP-NAcc-VTA disinhibits VTA and increases baseline activity (Floresco et al. 2001).  vSub-BNST-VTA increases phasic firing and bursting</div><div><br></div><div>- Single vSub stimulation -> Plastic changes in BNST -> increased excitability of VTA -> Locomotor effects of cocaine increase</div><div><br></div><div>- NOTE: vSub stimulation creates both Exc in 60\% of VTA neurons, and Inh in 40\% of VTA neurons...</div>"
}

@ARTICLE{Levine2013-rw,
title = "Exploring Deep and Recurrent Architectures for Optimal Control",
author = "Levine, Sergey",
abstract = "Sophisticated multilayer neural networks have achieved state of the art results on multiple supervised tasks. However, successful applications of such multilayer networks to control have so far been limited largely to the perception portion of the control pipeline. In this paper, we explore the application of deep and recurrent neural networks to a continuous, high-dimensional locomotion task, where the network is used to represent a control policy that maps the state of the system (represented by joint angles) directly to the torques at each joint. By using a recent reinforcement learning algorithm called guided policy search, we can successfully train neural network controllers with thousands of parameters, allowing us to compare a variety of architectures. We discuss the differences between the locomotion control task and previous supervised perception tasks, present experimental results comparing various architectures, and discuss future directions in the application of techniques from deep learning to the problem of optimal control.",
month =  "7~" # nov,
year =  2013,
archivePrefix = "arXiv",
primaryClass = "cs.LG",
eprint = "1311.1761"
}

@ARTICLE{Friedman2015-ry,
title = "A Corticostriatal Path Targeting Striosomes Controls {Decision-Making} under Conflict",
author = "Friedman, Alexander and Homma, Daigo and Gibb, Leif G and Amemori, Ken-Ichi and Rubin, Samuel J and Hood, Adam S and Riad, Michael H and Graybiel, Ann M",
affiliation = "McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. McGovern Institute for Brain Research and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. Electronic address: graybiel@mit.edu.",
abstract = "A striking neurochemical form of compartmentalization has been found in the striatum of humans and other species, dividing it into striosomes and matrix. The function of this organization has been unclear, but the anatomical connections of striosomes indicate their relation to emotion-related brain regions, including the medial prefrontal cortex. We capitalized on this fact by combining pathway-specific optogenetics and electrophysiology in behaving rats to search for selective functions of striosomes. We demonstrate that a medial prefronto-striosomal circuit is selectively active in and causally necessary for cost-benefit decision-making under approach-avoidance conflict conditions known to evoke anxiety in humans. We show that this circuit has unique dynamic properties likely reflecting striatal interneuron function. These findings demonstrate that cognitive and emotion-related functions are, like sensory-motor processing, subject to encoding within compartmentally organized representations in the forebrain and suggest that striosome-targeting corticostriatal circuits can underlie neural processing of decisions fundamental for survival.",
journal = "Cell",
volume =  161,
number =  6,
pages = "1320--1333",
month =  "4~" # jun,
year =  2015
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Terrence_C_Stewart_Xuan_Choo_Chris_Eliasmith2010-xi,
title = "Dynamic Behaviour of a Spiking Model of Action Selection in the Basal Ganglia",
booktitle = "10th Int. Conf. on Cognitive Modeling",
author = "{Terrence C. Stewart, Xuan Choo, Chris Eliasmith}",
abstract = "CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep Teregowda): A fundamental process for cognition is action selection: choosing a particular action out of the many possible actions available. This process is widely believed to involve the basal ganglia, and we present here a model of action selection that uses spiking neurons and is in accordance with the connectivity and neuron types found in this area. Since the parameters of the model are set by neurological data, we can produce timing predictions for different action selection situations without requiring parameter tweaking. Our results show that, while an action can be selected in 14 milliseconds (or longer for actions with similar utilities), it requires 3444 milliseconds to go from one simple action to the next. For complex actions (whose effect involves routing information between cortical areas), 5973 milliseconds are needed. This suggests a change to the standard cognitive modelling approach of requiring 50 milliseconds for all types of actions.",
year =  2010,
annote = "- Mostly useful in showing one aspect of the Eliasmith framework: <div><br></div><div>- How you can find a linear combination of spiking neurons. with varying I-f curves, to produce one overall 'meta-neuron' with an arbitrary tuning I-f cure, with simple linear algebra </div><div><br></div><div>- (shows the equation, not its derivation / explanation)</div>"
}

@ARTICLE{Ioffe2015-cr,
title = "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
author = "Ioffe, Sergey and Szegedy, Christian",
abstract = "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.",
month =  "11~" # feb,
year =  2015,
archivePrefix = "arXiv",
primaryClass = "cs.LG",
eprint = "1502.03167"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lake_undated-ej,
title = "Human-level concept learning through probabilistic program induction",
author = "Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B",
annote = "- You can build ``character-writing programs'' which specify sequences of strokes<div><br></div><div>- You can initialize these programs with ``prior'' parameter distributions (number of parts, part shapes, etc.)  taken from a vast database of human-written characters</div><div><br></div><div>- Once you have this, when you see a new character image, you can find a character-writing program from your distribution that matches it well</div><div><br></div><div>- Now you can generate many new exemplars of this same character, and your exemplars are indistinguishable from human-generated ones!</div><div><br></div><div>- Also: if you can find one single program that matches two different images well, these images are likely of the same character (``one-shot'' character recognition)</div>"
}

@ARTICLE{Montijn2012-yu,
title = "Divisive normalization and neuronal oscillations in a single hierarchical framework of selective visual attention",
author = "Montijn, Jorrit Steven and Klink, P Christaan and van Wezel, Richard J A",
affiliation = "Center for Neuroscience, Swammerdam Institute for Life Sciences, University of Amsterdam Amsterdam, Netherlands.",
abstract = "Divisive normalization models of covert attention commonly use spike rate modulations as indicators of the effect of top-down attention. In addition, an increasing number of studies have shown that top-down attention increases the synchronization of neuronal oscillations as well, particularly in gamma-band frequencies (25-100 Hz). Although modulations of spike rate and synchronous oscillations are not mutually exclusive as mechanisms of attention, there has thus far been little effort to integrate these concepts into a single framework of attention. Here, we aim to provide such a unified framework by expanding the normalization model of attention with a multi-level hierarchical structure and a time dimension; allowing the simulation of a recently reported backward progression of attentional effects along the visual cortical hierarchy. A simple cascade of normalization models simulating different cortical areas is shown to cause signal degradation and a loss of stimulus discriminability over time. To negate this degradation and ensure stable neuronal stimulus representations, we incorporate a kind of oscillatory phase entrainment into our model that has previously been proposed as the ``communication-through-coherence'' (CTC) hypothesis. Our analysis shows that divisive normalization and oscillation models can complement each other in a unified account of the neural mechanisms of selective visual attention. The resulting hierarchical normalization and oscillation (HNO) model reproduces several additional spatial and temporal aspects of attentional modulation and predicts a latency effect on neuronal responses as a result of cued attention.",
journal = "Front. Neural Circuits",
volume =  6,
pages = "22",
month =  "4~" # may,
year =  2012,
keywords = "attention; communication-through-coherence; computational model; divisive normalization; hierarchical normalization and oscillation; neuronal oscillations; phase-locking; visual cortex"
}

@ARTICLE{Joel2015-sz,
title = "Sex beyond the genitalia: The human brain mosaic",
author = "Joel, Daphna and Berman, Zohar and Tavor, Ido and Wexler, Nadav and Gaber, Olga and Stein, Yaniv and Shefi, Nisan and Pool, Jared and Urchs, Sebastian and Margulies, Daniel S and Liem, Franziskus and H{\"{a}}nggi, J{\"{u}}rgen and J{\"{a}}ncke, Lutz and Assaf, Yaniv",
affiliation = "School of Psychological Sciences, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; Sagol School of Neuoroscience, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; djoel@post.tau.ac.il. Sagol School of Neuoroscience, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; Department of Neurobiology, Faculty of Life Sciences, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; School of Mathematical Sciences, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; School of Psychological Sciences, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; School of Mathematical Sciences, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; School of Psychological Sciences, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; Sagol School of Neuoroscience, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; Max Planck Research Group for Neuroanatomy \& Connectivity, Max Planck Institute for Human Cognitive and Brain Sciences, 04103 Leipzig, Germany; Max Planck Research Group for Neuroanatomy \& Connectivity, Max Planck Institute for Human Cognitive and Brain Sciences, 04103 Leipzig, Germany; Max Planck Research Group for Neuroanatomy \& Connectivity, Max Planck Institute for Human Cognitive and Brain Sciences, 04103 Leipzig, Germany; Max Planck Research Group for Neuroanatomy \& Connectivity, Max Planck Institute for Human Cognitive and Brain Sciences, 04103 Leipzig, Germany; Division Neuropsychology, Department of Psychology, University of Zurich, 8050 Zurich, Switzerland. Division Neuropsychology, Department of Psychology, University of Zurich, 8050 Zurich, Switzerland. Division Neuropsychology, Department of Psychology, University of Zurich, 8050 Zurich, Switzerland. Sagol School of Neuoroscience, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel; Department of Neurobiology, Faculty of Life Sciences, Tel-Aviv University, Ramat Aviv, Tel-Aviv 6997801, Israel;",
abstract = "Whereas a categorical difference in the genitals has always been acknowledged, the question of how far these categories extend into human biology is still not resolved. Documented sex/gender differences in the brain are often taken as support of a sexually dimorphic view of human brains (``female brain'' or ``male brain''). However, such a distinction would be possible only if sex/gender differences in brain features were highly dimorphic (i.e., little overlap between the forms of these features in males and females) and internally consistent (i.e., a brain has only ``male'' or only ``female'' features). Here, analysis of MRIs of more than 1,400 human brains from four datasets reveals extensive overlap between the distributions of females and males for all gray matter, white matter, and connections assessed. Moreover, analyses of internal consistency reveal that brains with features that are consistently at one end of the ``maleness-femaleness'' continuum are rare. Rather, most brains are comprised of unique ``mosaics'' of features, some more common in females compared with males, some more common in males compared with females, and some common in both females and males. Our findings are robust across sample, age, type of MRI, and method of analysis. These findings are corroborated by a similar analysis of personality traits, attitudes, interests, and behaviors of more than 5,500 individuals, which reveals that internal consistency is extremely rare. Our study demonstrates that, although there are sex/gender differences in the brain, human brains do not belong to one of two distinct categories: male brain/female brain.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
month =  "30~" # nov,
year =  2015,
keywords = "behavior; brain connectivity; brain structure; gender differences; sex differences"
}

@ARTICLE{Miconi2015-ld,
title = "There's Waldo! A Normalization Model of Visual Search Predicts {Single-Trial} Human Fixations in an Object Search Task",
author = "Miconi, Thomas and Groomes, Laura and Kreiman, Gabriel",
affiliation = "Children's Hospital, Harvard Medical School, Boston, MA, USA The Neurosciences Institute, La Jolla, CA 92037, USA. Children's Hospital, Harvard Medical School, Boston, MA, USA. Children's Hospital, Harvard Medical School, Boston, MA, USA Center for Brain Science Swartz Center for Theoretical Neuroscience, Harvard University, Cambridge, MA, USA.",
abstract = "When searching for an object in a scene, how does the brain decide where to look next? Visual search theories suggest the existence of a global ``priority map'' that integrates bottom-up visual information with top-down, target-specific signals. We propose a mechanistic model of visual search that is consistent with recent neurophysiological evidence, can localize targets in cluttered images, and predicts single-trial behavior in a search task. This model posits that a high-level retinotopic area selective for shape features receives global, target-specific modulation and implements local normalization through divisive inhibition. The normalization step is critical to prevent highly salient bottom-up features from monopolizing attention. The resulting activity pattern constitues a priority map that tracks the correlation between local input and target features. The maximum of this priority map is selected as the locus of attention. The visual input is then spatially enhanced around the selected location, allowing object-selective visual areas to determine whether the target is present at this location. This model can localize objects both in array images and when objects are pasted in natural scenes. The model can also predict single-trial human fixations, including those in error and target-absent trials, in a search task involving complex objects.",
journal = "Cereb. Cortex",
month =  "19~" # jun,
year =  2015,
keywords = "computational modeling; normalization; object recognition; visual attention; visual search"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lim2015-gn,
title = "Inferring learning rules from distributions of firing rates in cortical neurons",
author = "Lim, Sukbin and McKee, Jillian L and Woloszyn, Luke and Amit, Yali and Freedman, David J and Sheinberg, David L and Brunel, Nicolas",
affiliation = "Department of Neurobiology, University of Chicago, Chicago, Illinois, USA. Department of Neurobiology, University of Chicago, Chicago, Illinois, USA. Department of Neuroscience, Columbia University, New York, New York, USA. Department of Statistics, University of Chicago, Chicago, Illinois, USA. Department of Computer Science, University of Chicago, Chicago, Illinois, USA. Department of Neurobiology, University of Chicago, Chicago, Illinois, USA. Department of Neuroscience, Brown University, Providence, Rhode Island, USA. Department of Neurobiology, University of Chicago, Chicago, Illinois, USA. Department of Statistics, University of Chicago, Chicago, Illinois, USA.",
abstract = "Information about external stimuli is thought to be stored in cortical circuits through experience-dependent modifications of synaptic connectivity. These modifications of network connectivity should lead to changes in neuronal activity as a particular stimulus is repeatedly encountered. Here we ask what plasticity rules are consistent with the differences in the statistics of the visual response to novel and familiar stimuli in inferior temporal cortex, an area underlying visual object recognition. We introduce a method that allows one to infer the dependence of the presumptive learning rule on postsynaptic firing rate, and we show that the inferred learning rule exhibits depression for low postsynaptic rates and potentiation for high rates. The threshold separating depression from potentiation is strongly correlated with both mean and s.d. of the firing rate distribution. Finally, we show that network models implementing a rule extracted from data show stable learning dynamics and lead to sparser representations of stimuli.",
journal = "Nat. Neurosci.",
volume =  18,
number =  12,
pages = "1804--1810",
month =  dec,
year =  2015,
annote = "- Deriving cortical plasticity rule from neural responses and basic calculus! <div><br></div><div>- Distribution of responses are more bimodal for familiar stimuli than for novel stimuli</div><div><br></div><div>- By looking at the distribution of responses and doing some calculus, you can find out the plasticity rule based on post-synaptic firing rate.<span style=``word-spacing: normal; line-height: 1.5em;''> Result: Yup, it's BCM !</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- See also Journal Club from Pillow lab : </span>https://pillowlab.wordpress.com/2015/12/03/inferring-synaptic-plasticity-rules-from-spike-counts/</div>"
}


@ARTICLE{Druckmann2012-ob,
title = "Neuronal circuits underlying persistent representations despite time varying activity",
author = "Druckmann, Shaul and Chklovskii, Dmitri B",
affiliation = "Janelia Farm Research Campus, Howard Hughes Medical Institute, 19700 Helix Drive, Ashburn, VA 20176, USA.",
abstract = "BACKGROUND: Our brains are capable of remarkably stable stimulus representations despite time-varying neural activity. For instance, during delay periods in working memory tasks, while stimuli are represented in working memory, neurons in the prefrontal cortex, thought to support the memory representation, exhibit time-varying neuronal activity. Since neuronal activity encodes the stimulus, its time-varying dynamics appears to be paradoxical and incompatible with stable network stimulus representations. Indeed, this finding raises a fundamental question: can stable representations only be encoded with stable neural activity, or, its corollary, is every change in activity a sign of change in stimulus representation? RESULTS: Here we explain how different time-varying representations offered by individual neurons can be woven together to form a coherent, time-invariant, representation. Motivated by two ubiquitous features of the neocortex-redundancy of neural representation and sparse intracortical connections-we derive a network architecture that resolves the apparent contradiction between representation stability and changing neural activity. Unexpectedly, this network architecture exhibits many structural properties that have been measured in cortical sensory areas. In particular, we can account for few-neuron motifs, synapse weight distribution, and the relations between neuronal functional properties and connection probability. CONCLUSIONS: We show that the intuition regarding network stimulus representation, typically derived from considering single neurons, may be misleading and that time-varying activity of distributed representation in cortical circuits does not necessarily imply that the network explicitly encodes time-varying properties.",
journal = "Curr. Biol.",
volume =  22,
number =  22,
pages = "2095--2103",
month =  "20~" # nov,
year =  2012,
annote = "- You can reliably encode a constant stimulus with dynamic, time-varying neuron activities.<div><br></div><div>- Assume each individual neuron codes for a certain feature vector (with the actual stimulus being the sum of these feature vectors, weighted by neural activity)... (Basic population coding)</div><div><br></div><div>- Then the condition is that the feature vector of each neuron should equal the feature vector of all target neurons, weighted by the outgoing weights: F\_i = sum( w\_i->j * F\_j ) - the FEVER network.</div><div><br></div><div>- If that is the case, then neural activities will vary under network action, but the decoded stimulus will remain identical !</div><div><br></div><div>- Additional requirement: minimize the total connection weight (otherwise, infinity of possible solutions)</div><div><br></div><div>- Reproduces some weird effects of the Romo task: neurons with time-varying activity, mostly a slow monotonic change over time (Machens) with some sharp fluctuations... !!</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bruno2015-ku,
title = "Modular deconstruction reveals the dynamical and physical building blocks of a locomotion motor program",
author = "Bruno, Angela M and Frost, William N and Humphries, Mark D",
affiliation = "Department of Neuroscience, The Chicago Medical School, Rosalind Franklin University of Medicine and Science, North Chicago, IL 60064-3095, USA. Department of Cell Biology and Anatomy, The Chicago Medical School, Rosalind Franklin University of Medicine and Science, North Chicago, IL 60064-3095, USA. Electronic address: william.frost@rosalindfranklin.edu. Faculty of Life Sciences, University of Manchester, Manchester, M13 9PT, UK. Electronic address: mark.humphries@manchester.ac.uk.",
abstract = "The neural substrates of motor programs are only well understood for small, dedicated circuits. Here we investigate how a motor program is constructed within a large network. We imaged populations of neurons in the Aplysia pedal ganglion during execution of a locomotion motor program. We found that the program was built from a very small number of dynamical building blocks, including both neural ensembles and low-dimensional rotational dynamics. These map onto physically discrete regions of the ganglion, so that the motor program has a corresponding modular organization in both dynamical and physical space. Using this dynamic map, we identify the population potentially implementing the rhythmic pattern generator and find that its activity physically traces a looped trajectory, recapitulating its low-dimensional rotational dynamics. Our results suggest that, even in simple invertebrates, neural motor programs are implemented by large, distributed networks containing multiple dynamical systems.",
journal = "Neuron",
volume =  86,
number =  1,
pages = "304--318",
month =  "8~" # apr,
year =  2015,
annote = "- In an Aplysia motor ganglion, you can identify (through unsupervised classification on imaging data) sub-classes of neurons <div><br></div><div>- First, divide neurons into assemblies/ensembles of neurons with very correlated spiking.</div><div><br></div><div>- One sub-class of ensembles constitutes is a set of oscillators, with circular trajectories in population-PCA space, a la Churchland.</div><div><br></div><div>- These neurons are arranges as *physical* ring of neurons, with a bump of activity running through the ring! These seem to control the oscillatory part of the movement !</div><div><br></div><div>- Various sub-classes (including the oscillators, bursters, etc.), which are physically segregated over the ganglion</div><div><br></div><div><br></div>"
}

@ARTICLE{Eliasmith2005-px,
title = "A unified approach to building and controlling spiking attractor networks",
author = "Eliasmith, Chris",
affiliation = "Department of Philosophy, Design Engineering, University of Waterloo, Waterloo, Ontario, Canada. celiasmith@uwaterloo.ca",
abstract = "Extending work in Eliasmith and Anderson (2003), we employ a general framework to construct biologically plausible simulations of the three classes of attractor networks relevant for biological systems: static (point, line, ring, and plane) attractors, cyclic attractors, and chaotic attractors. We discuss these attractors in the context of the neural systems that they have been posited to help explain: eye control, working memory, and head direction; locomotion (specifically swimming); and olfaction, respectively. We then demonstrate how to introduce control into these models. The addition of control shows how attractor networks can be used as subsystems in larger neural systems, demonstrates how a much larger class of networks can be related to attractor networks, and makes it clear how attractor networks can be exploited for various information processing tasks in neurobiological systems.",
journal = "Neural Comput.",
volume =  17,
number =  6,
pages = "1276--1314",
month =  jun,
year =  2005,
annote = "- Tells you how to build a spiking system that can perform any dynamical system that can be defined by linear (?) equations, such as x' = Ax + Bu<div><br></div><div>- The systems are controllable</div><div><br></div><div>- Builds upon a book, Eliasmith \& Anderson 2003.</div><div><br></div><div>- Very difficult to understand... Not sure how it differs from the Deneve stuff on the same subject...</div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hamid2015-wg,
title = "Mesolimbic dopamine signals the value of work",
author = "Hamid, Arif A and Pettibone, Jeffrey R and Mabrouk, Omar S and Hetrick, Vaughn L and Schmidt, Robert and Vander Weele, Caitlin M and Kennedy, Robert T and Aragona, Brandon J and Berke, Joshua D",
abstract = "Seeking insight into dopamine's contribution to motivation and learning, the authors examined dopamine release in the rat nucleus accumbens during adaptive decision-making. Dopamine levels convey a running estimate of available future reward, which is used to decide whether it's worthwhile to engage in a behavioral task. Abrupt fluctuations serve as reward prediction errors, reinforcing behavioral choices.",
journal = "Nat. Neurosci.",
publisher = "Nature Publishing Group",
month =  "23~" # nov,
year =  2015,
annote = "- [DA] in NAcc = V(t)  !<div><br></div><div>- NAcc DA encodes V, the expected sum of temporally discounted future rewards, at any given time - rather than the RPE</div><div><br></div><div>- As a result, NAcc [DA] encodes motivation / willingness to exert time \& effort for not-immediately-rewarded  <span style=``word-spacing: normal; line-height: 1.5em;''>actions !</span></div><div><br></div><div>- Main proof: over successive rewarded trials, the absolute [DA] peak on reward does not decrease; rather, the baseline increases (as expected if DA = V, but not if DA = RPE) !!</div><div><br></div><div>- Fast, abrupt changes in DA (NOT small, continuous changes in DA) do encode RPE (as expected from TD framework)</div><div><br></div><div>- NAcc DA increases from one ``task event'' to the next, especially  at task-initiation and reward-cue delivery</div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Legenstein2010-qn,
title = "A reward-modulated hebbian learning rule can explain experimentally observed network reorganization in a brain control task",
author = "Legenstein, Robert and Chase, Steven M and Schwartz, Andrew B and Maass, Wolfgang",
affiliation = "Institute for Theoretical Computer Science, Graz University of Technology, 8010 Graz, Austria. legi@igi.tugraz.at",
abstract = "It has recently been shown in a brain-computer interface experiment that motor cortical neurons change their tuning properties selectively to compensate for errors induced by displaced decoding parameters. In particular, it was shown that the three-dimensional tuning curves of neurons whose decoding parameters were reassigned changed more than those of neurons whose decoding parameters had not been reassigned. In this article, we propose a simple learning rule that can reproduce this effect. Our learning rule uses Hebbian weight updates driven by a global reward signal and neuronal noise. In contrast to most previously proposed learning rules, this approach does not require extrinsic information to separate noise from signal. The learning rule is able to optimize the performance of a model system within biologically realistic periods of time under high noise levels. Furthermore, when the model parameters are matched to data recorded during the brain-computer interface learning experiments described above, the model produces learning effects strikingly similar to those found in the experiments.",
journal = "J. Neurosci.",
volume =  30,
number =  25,
pages = "8400--8410",
month =  "23~" # jun,
year =  2010,
annote = "<div>[Feedforward only, requires real-time, online reward signal]</div><div><br></div>- Learning to control a cursor, using time-varying inputs which instruct the desired direction at time t <div><br></div><div>- The inputs are a fixed, non-modifiable function of the desired direction at any time (computed from the original, pre-learning input weights and preferred directions of neurons)</div><div><br></div><div>- Learning only at the input-to-output feedforward weights.</div><div><br></div><div>- Learning rule: input(t) * [ activ(t) - activ\_trace ] * [ R(t) - R\_trace ]</div><div>- activ(t) = input(t) + rand(t)</div><div><br></div><div>- Basically approximates the Fiete \& Seung rule, using the trace to filter out rand(t) out of the activ(t). Explicitly requires that rand(t) be large and input(t) varies slowly (p.8404)! </div><div>- Also totally requires a permanent, online reward signal ! This is how it avoids the problem that deviation from traces necessarily lead to a cumulatively equal deviation in the other direction afterwards?</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Molina-Luna2009-hz,
title = "Dopamine in motor cortex is necessary for skill learning and synaptic plasticity",
author = "Molina-Luna, Katiuska and Pekanovic, Ana and R{\"{o}}hrich, Sebastian and Hertler, Benjamin and Schubring-Giese, Maximilian and Rioult-Pedotti, Mengia-Seraina and Luft, Andreas R",
affiliation = "Clinical Neurorehabilitation, Department of Neurology, University of Zurich, Zurich, Switzerland.",
abstract = "Preliminary evidence indicates that dopamine given by mouth facilitates the learning of motor skills and improves the recovery of movement after stroke. The mechanism of these phenomena is unknown. Here, we describe a mechanism by demonstrating in rat that dopaminergic terminals and receptors in primary motor cortex (M1) enable motor skill learning and enhance M1 synaptic plasticity. Elimination of dopaminergic terminals in M1 specifically impaired motor skill acquisition, which was restored upon DA substitution. Execution of a previously acquired skill was unaffected. Reversible blockade of M1 D1 and D2 receptors temporarily impaired skill acquisition but not execution, and reduced long-term potentiation (LTP) within M1, a form of synaptic plasticity critically involved in skill learning. These findings identify a behavioral and functional role of dopaminergic signaling in M1. DA in M1 optimizes the learning of a novel motor skill.",
journal = "PLoS One",
volume =  4,
number =  9,
pages = "e7082",
month =  "17~" # sep,
year =  2009,
annote = "<div>- Selectively damaging DA terminals in M1 impairs learning, but not execution, of a motor skill.</div><div><br></div><div>- This is rescued by L-DOPA injection ! Hmm, tonic rather than phasic?...</div><div><br></div><div>- Blocking either D1 or D2 receptors also impairs learning. </div><div><br></div><div>- Note that both D1 and D2 blocking increase spontaneous firing in M1 pyramidal, maybe explained by D1 being on Pyr and D2 on Inh (they say)...</div><div><br></div>- Nice review of motor skill learning in M1, DA, etc."
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rioult-Pedotti1998-rq,
title = "Strengthening of horizontal cortical connections following skill learning",
author = "Rioult-Pedotti, M S and Friedman, D and Hess, G and Donoghue, J P",
affiliation = "Department of Neuroscience, Brown University, Providence, Rhode Island 02912, USA.",
abstract = "Learning a new motor skill requires an alteration in the spatiotemporal pattern of muscle activation. Motor areas of cerebral neocortex are thought to be involved in this type of learning, possibly by functional reorganization of cortical connections. Here we show that skill learning is accompanied by changes in the strength of connections within adult rat primary motor cortex (M1). Rats were trained for three or five days in a skilled reaching task with one forelimb, after which slices of motor cortex were examined to determine the effect of training on the strength of horizontal intracortical connections in layer II/III. The amplitude of field potentials in the forelimb region contralateral to the trained limb was significantly increased relative to the opposite 'untrained' hemisphere. No differences were seen in the hindlimb region. Moreover, the amount of long-term potentiation (LTP) that could be induced in trained M1 was less than in controls, suggesting that the effect of training was at least partly due to LTP-like mechanisms. These data represent the first direct evidence that plasticity of intracortical connections is associated with learning a new motor skill.",
journal = "Nat. Neurosci.",
volume =  1,
number =  3,
pages = "230--234",
month =  jul,
year =  1998,
annote = "- Rats learning a motor skill have stronger lateral connections in contralateral, limb-specific M1  !<div><br></div><div>- (estimated by recording LFP in response to electrostim - old school! - suggests very much a blunt, gross-quantitative effect, rather than fine sculpting...?)</div><div><br></div><div>- Furthermore, trained rat cortex has more difficulty in generating further LTP than control rat cortex - i.e. skill learning depletes / exhausts capacity for LTP in cortex ?.... </div><div><br></div><div>- See also other references in Molina-Luna et al. PLoS One 2009</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yagishita2014-qn,
title = "A critical time window for dopamine actions on the structural plasticity of dendritic spines",
author = "Yagishita, S and Hayashi-Takagi, A and Ellis-Davies, G C R and Urakubo, H and Ishii, S and Kasai, H",
journal = "Science",
volume =  345,
number =  6204,
pages = "1616--1620",
month =  "26~" # sep,
year =  2014,
annote = "- Dopamine bursts potentiate plasticity if they occur DURING or JUST AFTER (up to ~3s), but not BEFORE the STDP event.<div><br></div><div>- .. in the spines of rodent striatum (NAcc) D1 MSNs (not cortical...), in slices</div><div><br></div><div>- If DA burst occurs just 1s before the plasticity event, no effect at all ! </div><div><br></div><div>- Potentiation and plasticity are spine-specific !</div><div><br></div><div>- Here STDP is induced by micro-delivery of glutamate followed by 3 fast induced spikes at the studied spine.</div><div><br></div><div>- Lots of pharmacology to explain what's going on, including the time asymmetry.</div>"
}

@ARTICLE{Frenkel2006-vw,
title = "Instructive effect of visual experience in mouse visual cortex",
author = "Frenkel, Mikhail Y and Sawtell, Nathaniel B and Diogo, Antonia Cinira M and Yoon, Bongjune and Neve, Rachael L and Bear, Mark F",
affiliation = "The Picower Institute for Learning and Memory, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, Massachusetts 02139, USA.",
abstract = "We describe a form of experience-dependent response enhancement in the visual cortex of awake mice. Repeated presentations of grating stimuli of a single orientation result in a persistent enhancement of responses evoked by the test stimulus. Response potentiation is specific to the orientation of the test stimulus, develops gradually over the course of several training sessions, and occurs in both juvenile and adult mice. The stimulus-selective response potentiation (SRP) can mask deprivation-induced response depression in adult mice. SRP requires NMDA receptor activation and is prevented by viral delivery of a peptide that interferes with AMPA receptor trafficking. SRP may reveal the mechanisms involved in certain forms of perceptual learning.",
journal = "Neuron",
volume =  51,
number =  3,
pages = "339--349",
month =  "3~" # aug,
year =  2006
}

@ARTICLE{Hofer2006-vr,
title = "Lifelong learning: ocular dominance plasticity in mouse visual cortex",
author = "Hofer, Sonja B and Mrsic-Flogel, Thomas D and Bonhoeffer, Tobias and H{\"{u}}bener, Mark",
affiliation = "Max-Planck-Institut f{\"{u}}r Neurobiologie, Am Klopferspitz 18, 82152 Martinsried, Germany.",
abstract = "Ocular dominance plasticity has long served as a successful model for examining how cortical circuits are shaped by experience. In this paradigm, altered retinal activity caused by unilateral eye-lid closure leads to dramatic shifts in the binocular response properties of neurons in the visual cortex. Much of the recent progress in identifying the cellular and molecular mechanisms underlying ocular dominance plasticity has been achieved by using the mouse as a model system. In this species, monocular deprivation initiated in adulthood also causes robust ocular dominance shifts. Research on ocular dominance plasticity in the mouse is starting to provide insight into which factors mediate and influence cortical plasticity in juvenile and adult animals.",
journal = "Curr. Opin. Neurobiol.",
volume =  16,
number =  4,
pages = "451--459",
month =  aug,
year =  2006
}

@ARTICLE{Sawtell2003-ap,
title = "{NMDA} receptor-dependent ocular dominance plasticity in adult visual cortex",
author = "Sawtell, Nathaniel B and Frenkel, Mikhail Y and Philpot, Benjamin D and Nakazawa, Kazu and Tonegawa, Susumu and Bear, Mark F",
affiliation = "Howard Hughes Medical Institute, The Picower Center for Learning \& Memory, Department of Brain \& Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA.",
abstract = "The binocular region of mouse visual cortex is strongly dominated by inputs from the contralateral eye. Here we show in adult mice that depriving the dominant contralateral eye of vision leads to a persistent, NMDA receptor-dependent enhancement of the weak ipsilateral-eye inputs. These data provide in vivo evidence for metaplasticity as a mechanism for binocular competition and demonstrate that an ocular dominance shift can occur solely by the mechanisms of response enhancement. They also show that adult mouse visual cortex has a far greater potential for experience-dependent plasticity than previously appreciated. These insights may force a revision in how data on ocular dominance plasticity in mutant mice have been interpreted.",
journal = "Neuron",
volume =  38,
number =  6,
pages = "977--985",
month =  "19~" # jun,
year =  2003,
annote = "- Plasticity in adult mouse V1<div><br></div><div>- Ocular dominance of binocular cells are strongly affected, in an NMDA-dependent manner, by deprivation of experience in adult mice</div>"
}

@ARTICLE{Litwin-Kumar2012-kk,
title = "Slow dynamics and high variability in balanced cortical networks with clustered connections",
author = "Litwin-Kumar, Ashok and Doiron, Brent",
affiliation = "Program for Neural Computation, Carnegie Mellon University and University of Pittsburgh, Pittsburgh, Pennsylvania, USA. alk@cmu.edu",
abstract = "Anatomical studies demonstrate that excitatory connections in cortex are not uniformly distributed across a network but instead exhibit clustering into groups of highly connected neurons. The implications of clustering for cortical activity are unclear. We studied the effect of clustered excitatory connections on the dynamics of neuronal networks that exhibited high spike time variability owing to a balance between excitation and inhibition. Even modest clustering substantially changed the behavior of these networks, introducing slow dynamics during which clusters of neurons transiently increased or decreased their firing rate. Consequently, neurons exhibited both fast spiking variability and slow firing rate fluctuations. A simplified model shows how stimuli bias networks toward particular activity states, thereby reducing firing rate variability as observed experimentally in many cortical areas. Our model thus relates cortical architecture to the reported variability in spontaneous and evoked spiking activity.",
journal = "Nat. Neurosci.",
volume =  15,
number =  11,
pages = "1498--1505",
month =  nov,
year =  2012
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Litwin-Kumar2014-ax,
title = "Formation and maintenance of neuronal assemblies through synaptic plasticity",
author = "Litwin-Kumar, Ashok and Doiron, Brent",
affiliation = "1] Program for Neural Computation, Carnegie Mellon University and University of Pittsburgh, Pittsburgh, Pennsylvania 15260, USA [2] Department of Mathematics, University of Pittsburgh, Pittsburgh, Pennsylvania 15260, USA [3] Center for the Neural Basis of Cognition, Pittsburgh, Pennsylvania 15213, USA. 1] Department of Mathematics, University of Pittsburgh, Pittsburgh, Pennsylvania 15260, USA [2] Center for the Neural Basis of Cognition, Pittsburgh, Pennsylvania 15213, USA.",
abstract = "The architecture of cortex is flexible, permitting neuronal networks to store recent sensory experiences as specific synaptic connectivity patterns. However, it is unclear how these patterns are maintained in the face of the high spike time variability associated with cortex. Here we demonstrate, using a large-scale cortical network model, that realistic synaptic plasticity rules coupled with homeostatic mechanisms lead to the formation of neuronal assemblies that reflect previously experienced stimuli. Further, reverberation of past evoked states in spontaneous spiking activity stabilizes, rather than erases, this learned architecture. Spontaneous and evoked spiking activity contains a signature of learned assembly structures, leading to testable predictions about the effect of recent sensory experience on spike train statistics. Our work outlines requirements for synaptic plasticity rules capable of modifying spontaneous dynamics and shows that this modification is beneficial for stability of learned network architectures.",
journal = "Nat. Commun.",
volume =  5,
pages = "5319",
month =  "14~" # nov,
year =  2014,
annote = "- A large network with Clopath vSTDP + inhibitory iSTDP + some kind of synaptic scaling + fixed random FF connections onto each neuron = well-formed, stable assemblies (groups) that also occur (with slow switching dynamics) in spointaneous activity.<div><br></div><div>- The spontaneous dynamics are basically slow switching between groups/assemblies... Is that compatible with the Carandini stuff?</div><div><br></div><div>- They claim that similar models without iSTDP led to runaway excitation due to unstable STDP... But these didn't seem to use the Clopath rule. </div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Luczak2013-cs,
title = "Gating of sensory input by spontaneous cortical activity",
author = "Luczak, Artur and Bartho, Peter and Harris, Kenneth D",
affiliation = "Center for Molecular and Behavioral Neuroscience, Rutgers University, Newark, New Jersey 07102, USA. luczak@uleth.ca",
abstract = "The activity of neural populations is determined not only by sensory inputs but also by internally generated patterns. During quiet wakefulness, the brain produces spontaneous firing events that can spread over large areas of cortex and have been suggested to underlie processes such as memory recall and consolidation. Here we demonstrate a different role for spontaneous activity in sensory cortex: gating of sensory inputs. We show that population activity in rat auditory cortex is composed of transient 50-100 ms packets of spiking activity that occur irregularly during silence and sustained tone stimuli, but reliably at tone onset. Population activity within these packets had broadly consistent spatiotemporal structure, but the rate and also precise relative timing of action potentials varied between stimuli. Packet frequency varied with cortical state, with desynchronized state activity consistent with superposition of multiple overlapping packets. We suggest that such packets reflect the sporadic opening of a ``gate'' that allows auditory cortex to broadcast a representation of external sounds to other brain regions.",
journal = "J. Neurosci.",
volume =  33,
number =  4,
pages = "1684--1695",
month =  "23~" # jan,
year =  2013,
annote = "- The PSTH is a lie!  In single-trials, activity occurs in 50-100ms bursts, or 'packets' of spikes (with a roughly preserved temporal structure acorss neurons) , which are as large in spontaneous as in stimulus-evoked activity!<div><br></div><div>- The peak in PSTH at stimulus onset occurs because the packets occur reliably at stimulus onset (and, a bit less so, during sustained response) while they are sporadic in spontaneous activity - so they tend to average out in the PSTH</div><div><br></div><div>- The actual content of the packets (i.e. which neurons actually fire) depends on stimulus.</div><div><br></div><div>- Stimulus identity also slightly influence the temporal structure of packets - but influence is limited (larger variation between neurons than between stimuli for the same neuron).</div><div><br></div><div>- Packets/bursts may represent gating of the population activity...</div><div><br></div><div>- Not clear whether this is related to stimulus-specific assemblies, or to the large stimulus-agnostic fluctuations in spontaneous activity from the Carandini lab (choristers / soloists, etc.)</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Han2008-pi,
title = "Reverberation of recent visual experience in spontaneous cortical waves",
author = "Han, Feng and Caporale, Natalia and Dan, Yang",
affiliation = "Group in Vision Science, University of California Berkeley, Berkeley, CA 94720, USA.",
abstract = "Spontaneous waves of activity propagating across large cortical areas may play important roles in sensory processing and circuit refinement. However, whether these waves are in turn shaped by sensory experience remains unclear. Here we report that visually evoked cortical activity reverberates in subsequent spontaneous waves. Voltage-sensitive dye imaging in rat visual cortex shows that following repetitive presentation of a given visual stimulus, spatiotemporal activity patterns resembling the evoked response appear more frequently in the spontaneous waves. This effect is specific to the response pattern evoked by the repeated stimulus, and it persists for several minutes without further visual stimulation. Such wave-mediated reverberation could contribute to short-term memory and help to consolidate the transient effects of recent sensory experience into long-lasting cortical modifications.",
journal = "Neuron",
volume =  60,
number =  2,
pages = "321--327",
month =  "23~" # oct,
year =  2008,
annote = "- If you show a spatial stimulus, the activation in brain follows a 'wave' spatial pattern, starting from a 'seed' point and going into a specific trajectory.<div><br></div><div>- Waves / trajectories are also observed in spontaneous activity, though they are much less reproducible and more random (obviously)</div><div><br></div><div>- But when you show a stimulus repeatedly, the subsequent spontaneous waves resemble the stimulus-evoked waves much more! </div><div>- This is specific to the actually shown stimulus - they are not more similar to other stimulus-evoked waves!</div><div><br></div><div>- Not clear how much of that is simply modulation of spatial excitability... The controls are spatially randomized and 'flipped' trajectories.</div><div><br></div><div> - Also applies to more complex, wide-field stimuli (bars, gratings), though the p-values are much higher.</div><div><br></div><div>- Effect is seen from 50 repetitions up. Lasts for ~1 min. If 125 reps, effect lasts for >6min !!</div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zenke2015-ay,
title = "Diverse synaptic plasticity mechanisms orchestrated to form and retrieve memories in spiking neural networks",
author = "Zenke, Friedemann and Agnes, Everton J and Gerstner, Wulfram",
affiliation = "School of Computer and Communication Sciences and School of Life Sciences, Brain-Mind Institute, \'{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne, Lausanne EPFL 1015, Switzerland. 1] School of Computer and Communication Sciences and School of Life Sciences, Brain-Mind Institute, \'{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne, Lausanne EPFL 1015, Switzerland [2] Instituto de F\'{\i}sica, Universidade Federal do Rio Grande do Sul, Caixa Postal 15051, Porto Alegre RS 91501-970, Brazil. School of Computer and Communication Sciences and School of Life Sciences, Brain-Mind Institute, \'{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne, Lausanne EPFL 1015, Switzerland.",
abstract = "Synaptic plasticity, the putative basis of learning and memory formation, manifests in various forms and across different timescales. Here we show that the interaction of Hebbian homosynaptic plasticity with rapid non-Hebbian heterosynaptic plasticity is, when complemented with slower homeostatic changes and consolidation, sufficient for assembly formation and memory recall in a spiking recurrent network model of excitatory and inhibitory neurons. In the model, assemblies were formed during repeated sensory stimulation and characterized by strong recurrent excitatory connections. Even days after formation, and despite ongoing network activity and synaptic plasticity, memories could be recalled through selective delay activity following the brief stimulation of a subset of assembly neurons. Blocking any component of plasticity prevented stable functioning as a memory network. Our modelling results suggest that the diversity of plasticity phenomena in the brain is orchestrated towards achieving common functional goals.",
journal = "Nat. Commun.",
volume =  6,
pages = "6922",
month =  "21~" # apr,
year =  2015,
annote = "- Basically, a model of stable, robust Hebbian assembly learning<div><br></div><div>- Uses sevral forms of plasticity (short-term, STDP, heterosynaptic, homeostatic, etc.) together. Shows nice theoretical analyses of their effects, e.g. in ensuring bistability of both firing rates and synaptic weights</div><div><br></div><div>- Claims that Mongillo/Amit/Brunel was good but too simple in their phenomenal plasticity and binary weights. </div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Luczak2009-an,
title = "Spontaneous events outline the realm of possible sensory responses in neocortical populations",
author = "Luczak, Artur and Barth\'{o}, Peter and Harris, Kenneth D",
affiliation = "Center for Molecular and Behavioural Neuroscience, Rutgers University, Newark, NJ 07102, USA.",
abstract = "Neocortical assemblies produce complex activity patterns both in response to sensory stimuli and spontaneously without sensory input. To investigate the structure of these patterns, we recorded from populations of 40-100 neurons in auditory and somatosensory cortices of anesthetized and awake rats using silicon microelectrodes. Population spike time patterns were broadly conserved across multiple sensory stimuli and spontaneous events. Although individual neurons showed timing variations between stimuli, these were not sufficient to disturb a generally conserved sequential organization observed at the population level, lasting for approximately 100 ms with spiking reliability decaying progressively after event onset. Preserved constraints were also seen in population firing rate vectors, with vectors evoked by individual stimuli occupying subspaces of a larger but still constrained space outlined by the set of spontaneous events. These results suggest that population spike patterns are drawn from a limited ``vocabulary,'' sampled widely by spontaneous events but more narrowly by sensory responses.",
journal = "Neuron",
volume =  62,
number =  3,
pages = "413--425",
month =  "14~" # may,
year =  2009,
annote = "- In mouse auditory  AND somatosensory cortex, each neuron has its own time-course of responses, independently of evoked firing rate / preference for current stimulus<div><br></div><div>- The relative time courses of neuron groups are preserved in (upstate-event) spontaneous and evoked responses !</div><div><br></div><div>- Also, only a sub-space of all firing-rate patterns is possible. This is observed for both evoked responses and (less so, but still significant) spontaneous activity. Hmm, the sub-spaces for single-tone and natural stimuli are different / don't overlap much?....<br><div><br></div><div><br></div><div>- NOTE: this means that spike-timing actually does NOT carry much info about stimulus identity (it does have a bit, but largely determined by stereotypical sequence) ! They basically say as much in the intro to the other ``gating'' paper: ``population timing patterns evoked by different stimuli consist of variations on a common sequential structure, with smaller differences in the spike timing of one cell between stimuli than between different cells' responses to one stimulus (Luczak et al. 2009)''</div><div><br></div><div>- Question: are spontaneous firing rates really as high as simulus-evoked firing? ...</div><div><br></div></div>"
}

@ARTICLE{Schneidman2006-nr,
title = "Weak pairwise correlations imply strongly correlated network states in a neural population",
author = "Schneidman, Elad and Berry, 2nd, Michael J and Segev, Ronen and Bialek, William",
affiliation = "Joseph Henry Laboratories of Physics, Princeton University, Princeton, New Jersey 08544, USA. elads@princeton.edu",
abstract = "Biological networks have so many possible states that exhaustive sampling is impossible. Successful analysis thus depends on simplifying hypotheses, but experiments on many systems hint that complicated, higher-order interactions among large groups of elements have an important role. Here we show, in the vertebrate retina, that weak correlations between pairs of neurons coexist with strongly collective behaviour in the responses of ten or more neurons. We find that this collective behaviour is described quantitatively by models that capture the observed pairwise correlations but assume no higher-order interactions. These maximum entropy models are equivalent to Ising models, and predict that larger networks are completely dominated by correlation effects. This suggests that the neural code has associative or error-correcting properties, and we provide preliminary evidence for such behaviour. As a first test for the generality of these ideas, we show that similar results are obtained from networks of cultured cortical neurons.",
journal = "Nature",
volume =  440,
number =  7087,
pages = "1007--1012",
month =  "20~" # apr,
year =  2006,
annote = "- In retina, weak pairwise correlations between neurons actually lead to very strong population-level grouping of neural spikes!<div><br></div><div>- Furthermore, you only need to take into account the pair-wise correlations to reproduce population behavior. No need to consider triplets, quadruplets, etc. interactions.</div><div><br></div><div>- Uses some statistical mechanics and maximum-entropy model. Didn't follow the derivations,</div>"
}

@ARTICLE{Mongillo2003-je,
title = "Retrospective and prospective persistent activity induced by Hebbian learning in a recurrent cortical network",
author = "Mongillo, Gianluigi and Amit, Daniel J and Brunel, Nicolas",
journal = "Eur. J. Neurosci.",
volume =  18,
number =  7,
pages = "2011--2024",
month =  oct,
year =  2003,
annote = "- Spiking neurons (E and I) with plastic synapses (a simple rate-based, threshold-based Hebbian LTP/LTD rule) = you get both ``working memory'' delay activity of previous stimuli AND ``anticipatory'' firing of the associated ``response'' stimuli.<div><br></div><div>- Learns attractors AND a minimal cognitive decision.<br><br></div>"
}

@ARTICLE{Rokni2007-yk,
title = "Motor learning with unstable neural representations",
author = "Rokni, Uri and Richardson, Andrew G and Bizzi, Emilio and Seung, H Sebastian",
affiliation = "Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. rokniu@mit.edu",
abstract = "It is often assumed that learning takes place by changing an otherwise stable neural representation. To test this assumption, we studied changes in the directional tuning of primate motor cortical neurons during reaching movements performed in familiar and novel environments. During the familiar task, tuning curves exhibited slow random drift. During learning of the novel task, random drift was accompanied by systematic shifts of tuning curves. Our analysis suggests that motor learning is based on a surprisingly unstable neural representation. To explain these results, we propose that motor cortex is a redundant neural network, i.e., any single behavior can be realized by multiple configurations of synaptic strengths. We further hypothesize that synaptic modifications underlying learning contain a random component, which causes wandering among synaptic configurations with equivalent behaviors but different neural representations. We use a simple model to explore the implications of these assumptions.",
journal = "Neuron",
volume =  54,
number =  4,
pages = "653--666",
month =  "24~" # may,
year =  2007
}

@ARTICLE{Fiete2010-xd,
title = "Spike-time-dependent plasticity and heterosynaptic competition organize networks to produce long scale-free sequences of neural activity",
author = "Fiete, Ila R and Senn, Walter and Wang, Claude Z H and Hahnloser, Richard H R",
affiliation = "Center for Learning and Memory, University of Texas at Austin, Austin, TX 78712, USA. fiete@mail.clm.utexas.edu <fiete@mail.clm.utexas.edu>",
abstract = "Sequential neural activity patterns are as ubiquitous as the outputs they drive, which include motor gestures and sequential cognitive processes. Neural sequences are long, compared to the activation durations of participating neurons, and sequence coding is sparse. Numerous studies demonstrate that spike-time-dependent plasticity (STDP), the primary known mechanism for temporal order learning in neurons, cannot organize networks to generate long sequences, raising the question of how such networks are formed. We show that heterosynaptic competition within single neurons, when combined with STDP, organizes networks to generate long unary activity sequences even without sequential training inputs. The network produces a diversity of sequences with a power law length distribution and exponent -1, independent of cellular time constants. We show evidence for a similar distribution of sequence lengths in the recorded premotor song activity of songbirds. These results suggest that neural sequences may be shaped by synaptic constraints and network circuitry rather than cellular time constants.",
journal = "Neuron",
volume =  65,
number =  4,
pages = "563--576",
month =  "25~" # feb,
year =  2010,
annote = "- In a recurrent neural spiking network, when you combine classic STDP with a special kind of synaptic scaling (that subtracts a constant amount from all weights, thus penalizing the smaller ones more relatively), you get nice sequences / chains of neurons, or of neural groups (dep. on parameters)!<div><br></div><div>- Includes certain conditions on the maximum weights, the inputs, etc.</div><div><br></div><div>- Nice description of 'hacks' to obtain sequences of groups rather than single-neuron sequences (lowering individual wmax wrt the global Wmax, etc.)</div><div><br></div><div><br></div>"
}

@ARTICLE{Motter2015-ze,
title = "Networkcontrology",
author = "Motter, Adilson E",
affiliation = "Department of Physics and Astronomy, Northwestern University, Evanston, Illinois 60208, USA and Northwestern Institute on Complex Systems (NICO), Northwestern University, Evanston, Illinois 60208, USA.",
abstract = "An increasing number of complex systems are now modeled as networks of coupled dynamical entities. Nonlinearity and high-dimensionality are hallmarks of the dynamics of such networks but have generally been regarded as obstacles to control. Here, I discuss recent advances on mathematical and computational approaches to control high-dimensional nonlinear network dynamics under general constraints on the admissible interventions. I also discuss the potential of network control to address pressing scientific problems in various disciplines.",
journal = "Chaos",
volume =  25,
number =  9,
pages = "097621",
month =  sep,
year =  2015,
annote = "- Discusses the concepts of complex networks, defines 'controllability', etc.<div><br></div><div>- Shows an efficient method that can be used to set the current X to within the basin of a desired attractor, under specific constraints on the X, and even if you don't really know the actual basin of attraction (though you need to know the actual attractor itself)!</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Fiete2007-uk,
title = "Model of birdsong learning based on gradient estimation by dynamic perturbation of neural conductances",
author = "Fiete, Ila R and Fee, Michale S and Seung, H Sebastian",
affiliation = "Kavli Institute for Theoretical Physics, University of California Santa Barbara, Santa Barbara, CA, USA. ilafiete@caltech.edu",
abstract = "We propose a model of songbird learning that focuses on avian brain areas HVC and RA, involved in song production, and area LMAN, important for generating song variability. Plasticity at HVC --> RA synapses is driven by hypothetical ``rules'' depending on three signals: activation of HVC --> RA synapses, activation of LMAN --> RA synapses, and reinforcement from an internal critic that compares the bird's own song with a memorized template of an adult tutor's song. Fluctuating glutamatergic input to RA from LMAN generates behavioral variability for trial-and-error learning. The plasticity rules perform gradient-based reinforcement learning in a spiking neural network model of song production. Although the reinforcement signal is delayed, temporally imprecise, and binarized, the model learns in a reasonable amount of time in numerical simulations. Varying the number of neurons in HVC and RA has little effect on learning time. The model makes specific predictions for the induction of bidirectional long-term plasticity at HVC --> RA synapses.",
journal = "J. Neurophysiol.",
volume =  98,
number =  4,
pages = "2038--2057",
month =  oct,
year =  2007,
annote = "- USes the Fiete and Seung node-perturbation rule to learn birdsong in a FEEDFORWARD network.<div><br></div><div>- HVC produces fixed sequences. RA produces actual song (through remarkable simulation of song system). LMAN produces variable perturbations of RA. </div><div><br></div><div>- Only HVC-to-RA synapses are plastic.</div><div><br></div><div>- Works well. Hebbian learning rule (using presyn x postsyn x reward rather than presyn x perturbation x reward) doesn't !</div><div><br></div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Fiete2006-fm,
title = "Gradient learning in spiking neural networks by dynamic perturbation of conductances",
author = "Fiete, Ila R and Seung, H Sebastian",
affiliation = "Kavli Institute for Theoretical Physics, University of California, Santa Barbara, California 93106, USA.",
abstract = "We present a method of estimating the gradient of an objective function with respect to the synaptic weights of a spiking neural network. The method works by measuring the fluctuations in the objective function in response to dynamic perturbation of the membrane conductances of the neurons. It is compatible with recurrent networks of conductance-based model neurons with dynamic synapses. The method can be interpreted as a biologically plausible synaptic learning rule, if the dynamic perturbations are generated by a special class of ``empiric'' synapses driven by random spike trains from an external source.",
journal = "Phys. Rev. Lett.",
volume =  97,
number =  4,
pages = "048104",
month =  "28~" # jul,
year =  2006,
annote = "- Introduces the node-perturbation method for training arbitrary (including recurrent)  neural networks with delayed, sparse rewards (reinforcement learning - like) <div><br></div><div>- Basically exactly identical to my method...</div><div><br></div><div>- No simulation in this paper, but they mention a companion paper about birdsong learning, ``to be published'' - actually Fiete Fee \& Seun J Neurophysiology 2007 [Also in paperpile]</div><div><br></div><div>- See the REINFORCE Algorithm by Williams 1992 - it's basically very much the same thing.</div>"
}

@ARTICLE{Sebastian_Seung2003-wv,
title = "Learning in Spiking Neural Viewpoint Networks by Reinforcement of Stochastic Synaptic Transmission",
author = "Sebastian Seung, H",
journal = "Neuron",
volume =  40,
pages = "1063--1073",
year =  2003
}

@ARTICLE{Werbos1990-yj,
title = "Backpropagation through time: what it does and how to do it",
author = "Werbos, Paul J",
abstract = "This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis. Next, it presents the basic equations for backpropagation through time, and discusses applications to areas like ...",
journal = "Proc. IEEE",
publisher = "IEEE",
volume =  78,
number =  10,
pages = "1550--1560",
year =  1990
}

@ARTICLE{Barak2014-ul,
title = "Working models of working memory",
author = "Barak, Omri and Tsodyks, Misha",
affiliation = "Faculty of Medicine, Technion - Israel Institute of Technology, 1 Efron St., Haifa 31096, Israel. Department of Neurobiology, Weizmann Institute of Science, Herzl St., Rehovot 76100, Israel. Electronic address: misha@weizmann.ac.il.",
abstract = "Working memory is a system that maintains and manipulates information for several seconds during the planning and execution of many cognitive tasks. Traditionally, it was believed that the neuronal underpinning of working memory is stationary persistent firing of selective neuronal populations. Recent advances introduced new ideas regarding possible mechanisms of working memory, such as short-term synaptic facilitation, precise tuning of recurrent excitation and inhibition, and intrinsic network dynamics. These ideas are motivated by computational considerations and careful analysis of experimental data. Taken together, they may indicate the plethora of different processes underlying working memory in the brain.",
journal = "Curr. Opin. Neurobiol.",
volume =  25,
pages = "20--24",
month =  apr,
year =  2014
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lewis-Peacock2012-el,
title = "Neural evidence for a distinction between short-term memory and the focus of attention",
author = "Lewis-Peacock, Jarrod A and Drysdale, Andrew T and Oberauer, Klaus and Postle, Bradley R",
affiliation = "University of Wisconsin-Madison, USA. jalewpea@princeton.edu",
abstract = "It is widely assumed that the short-term retention of information is accomplished via maintenance of an active neural trace. However, we demonstrate that memory can be preserved across a brief delay despite the apparent loss of sustained representations. Delay period activity may, in fact, reflect the focus of attention, rather than STM. We unconfounded attention and memory by causing external and internal shifts of attention away from items that were being actively retained. Multivariate pattern analysis of fMRI indicated that only items within the focus of attention elicited an active neural trace. Activity corresponding to representations of items outside the focus quickly dropped to baseline. Nevertheless, this information was remembered after a brief delay. Our data also show that refocusing attention toward a previously unattended memory item can reactivate its neural signature. The loss of sustained activity has long been thought to indicate a disruption of STM, but our results suggest that, even for small memory loads not exceeding the capacity limits of STM, the active maintenance of a stimulus representation may not be necessary for its short-term retention.",
journal = "J. Cogn. Neurosci.",
volume =  24,
number =  1,
pages = "61--79",
month =  jan,
year =  2012,
annote = "- Items can be kept in STM  while disappearing from fMRI MVPA ! fMRI only reflects the currently attended items.<div><br></div><div>[- Caveat: they could not decode any WM from PFC !! They had to decode from whole-brain... so maybe doesn't apply to super-complex PFC activity?]</div><div><br></div><div>- Concept of ``activated LTM'', or non-attended WM, etc.: some items may be outside current attentional focus but still ``active'' (harder to reject recently encountered negatives) and ready to be retrieved.</div><div><br></div><div>- You can decode memorized stimulus from fMRI MVPA. BUT only the currently attended one !</div><div><br></div><div>- When distractor occurs, the distractor takes over the fMRI MVPA, even though item is still fully memorized with no effect on perf. and small effect on RT.</div><div><br></div><div>- When two stimuli must be kept, with currently relevant being indicated by positional cue (arrow), the uncued stimulus quickly disappears from fMRI, even though it's still in STM - quickly reappears \& takes over fMRI if re-cued ! </div><div><br></div><div>- Also note two possible strategies for paired-associated test:  either keep 1st item in mem, retrieve associate when needed (retrospective); or directly retrieve \& maintain the associate from onset (prospective). Both generate fMRI activity for the corresponding actively maintained stimulus!</div><div><br></div>"
}

@ARTICLE{Markram2008-vh,
title = "Fixing the location and dimensions of functional neocortical columns",
author = "Markram, Henry",
affiliation = "Brain Mind Institute, Ecole Polytechnique Federale de Lausanne, Switzerland.",
abstract = "The quest to understand the way in which neurons interconnect to form circuits that function as a unit began when Ramon y Cajal concluded that axo-dendritic apposition were too conspicuous to be incidental and proposed that two neurons must be communicating through these points of contact (see Shepherd and Erulkar, 1997, Trends Neurosci., 20, 385-392). Lorente de N\'{o} was probably the first to predict that a defined group of vertically displaced neurons in the neocortex could form functional units (Lorente de N\'{o}, 1938, Physiology of the Nervous System, 20, OUP: 291-330) for which Mountcastle found experimental evidence (see Mountcastle, 1997, Brain, 120, 701-722) and which was ultimately demonstrated by Hubel and Wiesel in their elegant discovery of the orientation selective columns (Hubel and Wiesel, 1959, J. Physiol., 148, 574-591). Until today, however, it is still not clear what shapes functional columns. Anatomical units, as in the barrel cortex, would make it easier to explain, but the neocortex is largely a continuous slab of closely packed neurons from which multiple modules emerge that can overlap partially or even completely on the same anatomical space. Are the columns in fixed anatomical locations or are they dynamically assigned and what anatomical and physiological properties are operating to shape their dimensions? A recent study explores how the geometry of single neurons places structural constraints on the dimensions of columns in the visual cortex (Stepanyants et al., 2008, Cereb Cortex, 18, 13-24).",
journal = "HFSP J.",
volume =  2,
number =  3,
pages = "132--135",
month =  jun,
year =  2008,
annote = "- States that *structural* connectivity within a small neighbourhood is basically all-to-all, so any pair of neurons can produce actual synapses (though only a minority of pairs do)."
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Markram2015-rz,
title = "Reconstruction and Simulation of Neocortical Microcircuitry",
author = "Markram, Henry and Muller, Eilif and Ramaswamy, Srikanth and Reimann, Michael W and Abdellah, Marwan and Sanchez, Carlos Aguado and Ailamaki, Anastasia and Alonso-Nanclares, Lidia and Antille, Nicolas and Arsever, Selim and Kahou, Guy Antoine Atenekeng and Berger, Thomas K and Bilgili, Ahmet and Buncic, Nenad and Chalimourda, Athanassia and Chindemi, Giuseppe and Courcol, Jean-Denis and Delalondre, Fabien and Delattre, Vincent and Druckmann, Shaul and Dumusc, Raphael and Dynes, James and Eilemann, Stefan and Gal, Eyal and Gevaert, Michael Emiel and Ghobril, Jean-Pierre and Gidon, Albert and Graham, Joe W and Gupta, Anirudh and Haenel, Valentin and Hay, Etay and Heinis, Thomas and Hernando, Juan B and Hines, Michael and Kanari, Lida and Keller, Daniel and Kenyon, John and Khazen, Georges and Kim, Yihwa and King, James G and Kisvarday, Zoltan and Kumbhar, Pramod and Lasserre, S\'{e}bastien and Le B\'{e}, Jean-Vincent and Magalh\~{a}es, Bruno R C and Merch\'{a}n-P\'{e}rez, Angel and Meystre, Julie and Morrice, Benjamin Roy and Muller, Jeffrey and Mu\~{n}oz-C\'{e}spedes, Alberto and Muralidhar, Shruti and Muthurasa, Keerthan and Nachbaur, Daniel and Newton, Taylor H and Nolte, Max and Ovcharenko, Aleksandr and Palacios, Juan and Pastor, Luis and Perin, Rodrigo and Ranjan, Rajnish and Riachi, Imad and Rodr\'{\i}guez, Jos\'{e}-Rodrigo and Riquelme, Juan Luis and R{\"{o}}ssert, Christian and Sfyrakis, Konstantinos and Shi, Ying and Shillcock, Julian C and Silberberg, Gilad and Silva, Ricardo and Tauheed, Farhan and Telefont, Martin and Toledo-Rodriguez, Maria and Tr{\"{a}}nkler, Thomas and Van Geit, Werner and D\'{\i}az, Jafet Villafranca and Walker, Richard and Wang, Yun and Zaninetta, Stefano M and DeFelipe, Javier and Hill, Sean L and Segev, Idan and Sch{\"{u}}rmann, Felix",
journal = "Cell",
publisher = "Elsevier",
volume =  163,
number =  2,
pages = "456--492",
month =  "10~" # aug,
year =  2015,
annote = "- Starts with a super-review of the cortical microcircuit / neuron types<div>- Contains a neat review of morphological, electrophysiological, and synaptic types (m-types, e-types, s-types), as well as the correspondences between all of them (how many of each combination do you see), for each layer!</div><div><br></div><div>- VIP does not cleanly separate from SOM ?? All VIP+++ are also SOM++?</div><div><br></div><div>- Main ``result'' : in vivo-like / low Ca = asynchronous state,  in vitro / high Ca = (very!) synchronous, ~1Hz burst state (?) </div><div>- Depending on async vs. sync state, external excitation can result either in an all-or-none, ``regenerative'' state (epileptic?) or in a localized, controlled excitation (non-regenerative). Presumably because in former case inhibition cannot act fast enough to counter recurrent excitation</div><div><br></div><div>- Possibly aiming at a Hodgkin-Huxley for the circuit level: a model so accurate and powerful that it can be used as a surrogate of actual biological experiments for testing other, higher-level models (either in their predictions or in their assumptions)</div><div><br></div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lim2014-wy,
title = "Balanced cortical microcircuitry for spatial working memory based on corrective feedback control",
author = "Lim, Sukbin and Goldman, Mark S",
affiliation = "Center for Neuroscience and sukbin@uchicago.edu msgoldman@ucdavis.edu. Center for Neuroscience and Departments of Neurobiology, Physiology, and Behavior, and Ophthalmology and Vision Science, University of California, Davis, Davis, California 95618 sukbin@uchicago.edu msgoldman@ucdavis.edu.",
abstract = "A hallmark of working memory is the ability to maintain graded representations of both the spatial location and amplitude of a memorized stimulus. Previous work has identified a neural correlate of spatial working memory in the persistent maintenance of spatially specific patterns of neural activity. How such activity is maintained by neocortical circuits remains unknown. Traditional models of working memory maintain analog representations of either the spatial location or the amplitude of a stimulus, but not both. Furthermore, although most previous models require local excitation and lateral inhibition to maintain spatially localized persistent activity stably, the substrate for lateral inhibitory feedback pathways is unclear. Here, we suggest an alternative model for spatial working memory that is capable of maintaining analog representations of both the spatial location and amplitude of a stimulus, and that does not rely on long-range feedback inhibition. The model consists of a functionally columnar network of recurrently connected excitatory and inhibitory neural populations. When excitation and inhibition are balanced in strength but offset in time, drifts in activity trigger spatially specific negative feedback that corrects memory decay. The resulting networks can temporally integrate inputs at any spatial location, are robust against many commonly considered perturbations in network parameters, and, when implemented in a spiking model, generate irregular neural firing characteristic of that observed experimentally during persistent activity. This work suggests balanced excitatory-inhibitory memory circuits implementing corrective negative feedback as a substrate for spatial working memory.",
journal = "J. Neurosci.",
volume =  34,
number =  20,
pages = "6790--6806",
month =  "14~" # may,
year =  2014,
annote = "- Working memory activity can be maintained stable by ``Negative-derivative feedback'': Slow excitatory feedback + fast inhibitory feedback.<div><br></div><div>- Results in a -r*dr/dt term in the rate diff. eq.. </div><div><br></div><div><div><br class=``Apple-interchange-newline''>- Much more stable than simple excitatory FB to counter-act decay, resilient against various network manip (changes in gain ,loss of neurons/synapses, etc.).</div><div><br></div></div><div><br></div><div>- In this paper, shows that it can also be applied to maintain stable *spatial* firing patterns on a plane.</div><div><span style=``word-spacing: normal; line-height: 1.5em;''> </span></div>",
keywords = "balanced networks; computational model; decision making; derivative feedback; integration; working memory"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Glimcher2011-cg,
title = "Understanding dopamine and reinforcement learning: the dopamine reward prediction error hypothesis",
author = "Glimcher, Paul W",
affiliation = "Center for Neuroeconomics, New York University, New York, NY 10003, USA. glimcher@cns.nyu.edu",
abstract = "A number of recent advances have been achieved in the study of midbrain dopaminergic neurons. Understanding these advances and how they relate to one another requires a deep understanding of the computational models that serve as an explanatory framework and guide ongoing experimental inquiry. This intertwining of theory and experiment now suggests very clearly that the phasic activity of the midbrain dopamine neurons provides a global mechanism for synaptic modification. These synaptic modifications, in turn, provide the mechanistic underpinning for a specific class of reinforcement learning mechanisms that now seem to underlie much of human and animal behavior. This review describes both the critical empirical findings that are at the root of this conclusion and the fantastic theoretical advances from which this conclusion is drawn.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
volume = "108 Suppl 3",
pages = "15647--15654",
month =  "13~" # sep,
year =  2011,
annote = " - Explains the TD / RPE account of phasic dopamine.<div><br></div><div>- Claims that DA neurons are homogenous, all behave the same - uh, no.</div><div><br></div><div>- Suggests that DA ramping is an expected consequence of lesser negative than positive RPEs, together with probabilistic reward delivery! (from Niv Duff \& Dayan 2005 ). </div><div><br></div><div>- BUT !! The Graybiel lab ramps (Howe et al.) occur even without unpredictability?... Well, the rat still makes mistakes... But Niv's commentary </div>"
}

@ARTICLE{Williams1992-wy,
title = "Simple statistical gradient-following algorithms for connectionist reinforcement learning",
author = "Williams, Ronald J",
journal = "Mach. Learn.",
publisher = "Kluwer Academic Publishers",
volume =  8,
number = "3-4",
pages = "229--256",
year =  1992,
annote = "- The REINFORCE algorithm, when applied to recurrent networks with episodic reinforcement at the end of the trial, IS the node-perturbation learning !<div><br></div><div>- See the equation on p. 237</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Belin2008-xf,
title = "Cocaine seeking habits depend upon dopamine-dependent serial connectivity linking the ventral with the dorsal striatum",
author = "Belin, David and Everitt, Barry J",
affiliation = "Department of Experimental Psychology, University of Cambridge, Cambridge CB2 3EB, UK. bdb26@cam.ac.uk",
abstract = "A neuroanatomical principle of striatal organization has been established through which ventral domains, including the nucleus accumbens, exert control over dorsal striatal processes mediated by so-called ``spiraling,'' striato-nigro-striatal, circuitry. We have investigated the functional significance of this circuitry in the control over a cocaine-seeking habit by using an intrastriatal disconnection procedure that combined a selective, unilateral lesion of the nucleus accumbens core and infusion of a dopamine receptor antagonist into the contralateral dorsolateral striatum, thereby disrupting striato-midbrain-striatal serial connectivity bilaterally. We show that this disconnection selectively decreased drug-seeking behavior in rats extensively trained under a second-order schedule of cocaine reinforcement. These data thereby define the importance of interactions between ventral and dorsal domains of the striatum, mediated by dopaminergic transmission, in the neural mechanisms underlying the development and performance of cocaine-seeking habits that are a key characteristic of drug addiction.",
journal = "Neuron",
volume =  57,
number =  3,
pages = "432--441",
month =  "7~" # feb,
year =  2008,
annote = "- Neat and clean: if you cut out the DA pathway from NAcc Core to DL Striatum, you selectively impair (habitual, super-overtrained)  cue-controlled drug-seeking, without preventing instrumental (goal-directed, non-habit) learning!<div><br></div><div>- So it's not just DA in the DLS that generates (habitual) drug-seeking. </div><div><br></div><div>- But problem: NAcc/VS -> VTA/SNc is inhibitory........</div><div><br></div><div>- Very cool review in discussion...</div><div><br></div><div>===<br><div><br></div><div>- ``Spiral'' b/w the BG and the DA system: NAcc Shell projects not only to its own VTA inputs, but also those of NAcc Core. Similarly, NAcc Core projects to its own VTA inputs, but also to those that target more dorsal Striatum, etc... all the way to SNc and DLS</div><div>- Confirmed in both primates (Haber 2000) and rats (Ikemoto 2007)</div><div><br></div><div>- Unilateral killing of NAcc Core + DA-antagonists in DLS = the DA chain from NAcc Core to DLS is cut !</div><div><br></div><div>- Result: overtrained, habit cocaine seeking is impaired, in dose-dependent manner, exactly as under bilateral DA-antagonists in DLS.</div><div><br></div><div>- So cue-generated cocaine seeking (after habit/overtraining) is not just caused by any ole' DA in the DLS: it's DA regulated through NAcc Core ! But wait, NAcc -> DA is inhibitory?....</div></div><div><br></div><div>- By contrast, disconnected rats still learn to pull chain to get sucrose solution, so instrumental learning is OK</div><div><br></div><div>- Note : Ito et al. Nat Neurosci 2004 show that NAcc Core is necessary for the *acquisition* of the cue-controlled drug-seeking habit, not its execution</div><div>- Note2: damaging either NAcc Core OR DMS reduces A-O and increases S-R, while damaging DLS has opposite effect</div>"
}

@BOOK{Dreher2009-ti,
title = "Handbook of reward and decision making",
author = "Dreher, Jean-Claude and Tremblay, L\'{e}on",
abstract = "This book addresses a fundamental question about the nature of behavior: how does the brain process reward and makes decisions when facing multiple options? The book presents the most recent and compelling lesion, neuroimaging, electrophysiological and ...",
publisher = "Academic Press",
year =  2009
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Nyhus2015-vw,
title = "Functional Organization of Frontal Cortex",
author = "Nyhus, Erika and Badre, David",
abstract = "To be adaptive, the long‐term memory system must support retrieval of previously stored knowledge that has high utility given our current task and goals. In this framing, the problem of memory retrieval concerns balancing the recovery of useful information on the one ...",
journal = "The Wiley Handbook on The Cognitive Neuroscience of Memory",
publisher = "John Wiley \& Sons",
pages = "131",
year =  2015,
annote = "- (left) VLPFC is involved in memory retrieval (semantic/lexical? It overlaps with Broca's area!<span style=``line-height: 1.5em; word-spacing: normal;''>)</span><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Separation between anterior / ventral VLPFC and mid- / dorsal VLPFC</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- aVLPFC involved in ``controlled retrieval'', generating cue for retrieving appropriate data (e.g. when primers are too weak to create automatic retrieval)</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- mid-VLPFC is maybv involved in post-retrieval selection/control, interference suppression, etc.</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Two frontal subnetworks: dorsal PFC connected with PPC/IPS (and similar to 'multiple-demand' network?), ventral PFC connected with MTL (and similar to the 'default-mode' network) !!</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- aVLPFC is part of the ventral network, midVLPFC is part of the dorsal network!</span></div>"
}

@ARTICLE{Kim2013-xu,
title = "Signals for previous goal choice persist in the dorsomedial, but not dorsolateral striatum of rats",
author = "Kim, Hoseok and Lee, Daeyeol and Jung, Min Whan",
affiliation = "Neuroscience Laboratory, Institute for Medical Sciences and Neuroscience Graduate Program, Ajou University School of Medicine, Suwon 443-721, Korea.",
abstract = "The cortico-basal ganglia network has been proposed to consist of parallel loops serving distinct functions. However, it is still uncertain how the content of processed information varies across different loops and how it is related to the functions of each loop. We investigated this issue by comparing neuronal activity in the dorsolateral (sensorimotor) and dorsomedial (associative) striatum, which have been linked to habitual and goal-directed action selection, respectively, in rats performing a dynamic foraging task. Both regions conveyed significant neural signals for the animal's goal choice and its outcome. Moreover, both regions conveyed similar levels of neural signals for action value before the animal's goal choice and chosen value after the outcome of the animal's choice was revealed. However, a striking difference was found in the persistence of neural signals for the animal's chosen action. Signals for the animal's goal choice persisted in the dorsomedial striatum until the outcome of the animal's next goal choice was revealed, whereas they dissipated rapidly in the dorsolateral striatum. These persistent choice signals might be used for causally linking temporally discontiguous responses and their outcomes in the dorsomedial striatum, thereby contributing to its role in goal-directed action selection.",
journal = "J. Neurosci.",
volume =  33,
number =  1,
pages = "52--63",
month =  "2~" # jan,
year =  2013,
annote = "- Rat DMS, but Not DLS, keeps encoding about previous choice and previous reward, all the way to new-trial reward !<div><br></div><div>- NOTE: task is special: unvisited sites keep their reward, so you need to change ever now and then (cuz then the previously unchosen site is almost sure to have some reward!) In previous, independent-trials task (2-arm bandit), they also found previous-choice signalsin DLS AND Ventral Striatum (VS), but weaker !</div><div><br></div><div>- Rat DLS only encode previous reward, not choice, and only briefly aounrd the time of new reward.</div><div><br></div><div>- NOTE: DMS and DLS encode current choice only at the time of choice! They can't be used to predict upcoming choice!</div><div><br></div><div>- DMS and DLS both contain information about action values and (after reward delivered) chosen-action value!</div><div><br></div><div><br></div>"
}

@ARTICLE{Tian2015-xo,
title = "Habenula Lesions Reveal that Multiple Mechanisms Underlie Dopamine Prediction Errors",
author = "Tian, Ju and Uchida, Naoshige",
affiliation = "Department of Molecular and Cellular Biology, Center for Brain Science, Harvard University, Cambridge, MA 01238, USA. Department of Molecular and Cellular Biology, Center for Brain Science, Harvard University, Cambridge, MA 01238, USA. Electronic address: uchida@mcb.harvard.edu.",
abstract = "Dopamine (DA) neurons are thought to facilitate learning by signaling reward prediction errors (RPEs), the discrepancy between actual and expected reward. However, how RPEs are calculated remains unknown. It has been hypothesized that DA neurons receive RPE signals from the lateral habenula. Here, we tested how lesions of the habenular complex affect the response of optogenetically identified DA neurons in mice. We found that lesions impaired specific aspects of RPE signaling in DA neurons. The inhibitory responses caused by reward omission were greatly diminished while inhibitory responses to aversive stimuli, such as air puff-predictive cues or air puff, remained unimpaired. Furthermore, we found that after habenula lesions, DA neurons' ability to signal graded levels of positive RPEs became unreliable, yet significant excitatory responses still remained. These results demonstrate that the habenula plays a critical role in DA RPE signaling but suggest that it is not the exclusive source of RPE signals.",
journal = "Neuron",
volume =  87,
number =  6,
pages = "1304--1316",
month =  "23~" # sep,
year =  2015
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Carr2000-ui,
title = "Projections from the rat prefrontal cortex to the ventral tegmental area: target specificity in the synaptic associations with mesoaccumbens and mesocortical neurons",
author = "Carr, D B and Sesack, S R",
affiliation = "Departments of Neuroscience and Psychiatry, University of Pittsburgh, Pittsburgh, Pennsylvania 15260, USA.",
abstract = "Excitatory projections from the prefrontal cortex (PFC) to the ventral tegmental area (VTA) play an important role in regulating the activity of VTA neurons and the extracellular levels of dopamine (DA) within forebrain regions. Previous investigations have demonstrated that PFC terminals synapse on the dendrites of DA and non-DA neurons in the VTA. However, the projection targets of these cells are not known. To address whether PFC afferents innervate different populations of VTA neurons that project to the nucleus accumbens (NAc) or to the PFC, a triple labeling method was used that combined peroxidase markers for anterograde and retrograde tract-tracing with pre-embedding immunogold-silver labeling for either tyrosine hydroxylase (TH) or GABA. Within the VTA, PFC terminals formed asymmetric synapses onto dendritic shafts that were immunoreactive for either TH or GABA. PFC terminals also synapsed on VTA dendrites that were retrogradely labeled from the NAc or the PFC. Dendrites retrogradely labeled from the NAc and postsynaptic to PFC afferents were sometimes immunoreactive for GABA but were never TH-labeled. Conversely, dendrites retrogradely labeled from the PFC and postsynaptic to PFC afferents were sometimes immunoreactive for TH but were never GABA-labeled. These results provide the first demonstration of PFC afferents synapsing on identified cell populations in the VTA and indicate a considerable degree of specificity in the targets of the PFC projection. The unexpected finding of selective PFC synaptic input to GABA-containing mesoaccumbens neurons and DA-containing mesocortical neurons suggests novel mechanisms through which the PFC can influence the activity of ascending DA and GABA projections.",
journal = "J. Neurosci.",
volume =  20,
number =  10,
pages = "3864--3873",
month =  "15~" # may,
year =  2000,
annote = "<div>- Rat PFC neurons project to VTA neurons, both GABA and DA.  BUT! They project only to DA neurons that project back to PFC, and GABA neurons that project to NAcc! Never the other way round!! </div><div><br></div><div>-  (DA-ergic assessed by TH) </div><div><br></div><div>- However PFc is known to regulate DA in NAcc, apparently poly-synaptic manner through a Glutamate intermediary, perhaps from pedunculopontine tegmentum (PPT) </div><div><br></div><div>- Claim 'most in vivo studies report that DA suppresses PFC cell activity', so this could be just negative feedback - hmmmm..</div><div><br></div><div>- Also, VTA projection to PFC is also largely GABA !!</div><div><br></div>"
}

@ARTICLE{Arnsten2012-ja,
title = "Neuromodulation of thought: flexibilities and vulnerabilities in prefrontal cortical network synapses",
author = "Arnsten, Amy F T and Wang, Min J and Paspalas, Constantinos D",
affiliation = "Department of Neurobiology, Yale Medical School, New Haven, CT 06510, USA. amy.arnsten@yale.edu",
abstract = "This review describes unique neuromodulatory influences on working memory prefrontal cortical (PFC) circuits that coordinate cognitive strength with arousal state. Working memory arises from recurrent excitation within layer III PFC pyramidal cell NMDA circuits, which are afflicted in aging and schizophrenia. Neuromodulators rapidly and flexibly alter the efficacy of these synaptic connections, while leaving the synaptic architecture unchanged, a process called dynamic network connectivity (DNC). Increases in calcium-cAMP signaling open ion channels in long, thin spines, gating network connections. Inhibition of calcium-cAMP signaling by stimulating $\alpha$2A-adrenoceptors on spines strengthens synaptic efficacy and increases network firing, whereas optimal stimulation of dopamine D1 receptors sculpts network inputs to refine mental representation. Generalized increases in calcium-cAMP signaling during fatigue or stress disengage dlPFC recurrent circuits, reduce firing and impair top-down cognition. Impaired DNC regulation contributes to age-related cognitive decline, while genetic insults to DNC proteins are commonly linked to schizophrenia.",
journal = "Neuron",
volume =  76,
number =  1,
pages = "223--239",
month =  "4~" # oct,
year =  2012
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yosinski2015-nc,
title = "Understanding Neural Networks Through Deep Visualization",
author = "Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod",
abstract = "Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup.",
month =  "22~" # jun,
year =  2015,
annote = "- About, essentially, 'Deep  dreaming' - though just before the publication of deep dream<div><br></div><div>- Introduces the previous literature about visualizing cell's preference by optimizing the input image for the cell's response!</div><div><br></div><div>- Shows that you should 'regularize' the results in various way. Simplest: Gaussian blur the images (largely similar to the total-loss based on nearby correlation).  Also simple L2 decay, and clipping pixels with low values and low 'contribution'</div>",
archivePrefix = "arXiv",
primaryClass = "cs.CV",
eprint = "1506.06579"
}

@ARTICLE{Domingos2012-xb,
title = "A Few Useful Things to Know About Machine Learning",
author = "Domingos, Pedro",
journal = "Commun. ACM",
publisher = "ACM",
volume =  55,
number =  10,
pages = "78--87",
month =  oct,
year =  2012,
address = "New York, NY, USA"
}

@ARTICLE{Schroff2015-fu,
title = "{FaceNet}: A Unified Embedding for Face Recognition and Clustering",
author = "Schroff, Florian and Kalenichenko, Dmitry and Philbin, James",
abstract = "Despite significant recent advances in the field of face recognition, implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-art face recognition performance using only 128-bytes per face. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63\%. On YouTube Faces DB it achieves 95.12\%. Our system cuts the error rate in comparison to the best published result by 30\% on both datasets. We also introduce the concept of harmonic embeddings, and a harmonic triplet loss, which describe different versions of face embeddings (produced by different networks) that are compatible to each other and allow for direct comparison between each other.",
month =  "12~" # mar,
year =  2015,
archivePrefix = "arXiv",
primaryClass = "cs.CV",
eprint = "1503.03832"
}

@ARTICLE{Goodfellow2014-mb,
title = "Generative Adversarial Networks",
author = "Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua",
abstract = "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.",
month =  "10~" # jun,
year =  2014,
annote = "tor",
archivePrefix = "arXiv",
primaryClass = "stat.ML",
eprint = "1406.2661"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Braver2012-xr,
title = "The variable nature of cognitive control: a dual mechanisms framework",
author = "Braver, Todd S",
affiliation = "Department of Psychology, Washington University in St. Louis, St. Louis, MO 63130, USA. tbraver@artsci.wustl.edu",
abstract = "A core component of cognitive control - the ability to regulate thoughts and actions in accordance with internally represented behavioral goals - might be its intrinsic variability. In this article, I describe the dual mechanisms of control (DMC) framework, which postulates that this variability might arise from qualitative distinctions in temporal dynamics between proactive and reactive modes of control. Proactive control reflects the sustained and anticipatory maintenance of goal-relevant information within lateral prefrontal cortex (PFC) to enable optimal cognitive performance, whereas reactive control reflects transient stimulus-driven goal reactivation that recruits lateral PFC (plus a wider brain network) based on interference demands or episodic associations. I summarize recent research that demonstrates how the DMC framework provides a coherent explanation of three sources of cognitive control variation - intra-individual, inter-individual and between-groups - in terms of proactive versus reactive control biases.",
journal = "Trends Cogn. Sci.",
volume =  16,
number =  2,
pages = "106--113",
month =  feb,
year =  2012,
annote = "- There might be TWO modes of cognitive control: a pro-active, 'store context in PFC for future' one, and a reactive, 'retrieve context-defining info from episodic memory when needed' one.<div><br></div><div>-``proactive <span style=''word-spacing: normal; line-height: 1.5em;``>control relies upon the anticipation and prevention of </span><span style=''word-spacing: normal; line-height: 1.5em;``>interference before it occurs, whereas reactive control </span><span style=''word-spacing: normal; line-height: 1.5em;``>relies upon the detection and resolution of interference </span><span style=''word-spacing: normal; line-height: 1.5em;``>after its onset''</span></div><div><br></div><div>- Exemple of the recent-probe task: when recent-negative probes are rare, the control is mostly reactive (when you hit a recent negative probe, you try to retrieve the previous array), but if they are frequent, you switch to pro-active (keep the previous array in WM?). fMRI 'proof': low-freq leads to higher probe-time activation of left inferior PFC on recent-negative probes (reactive), while hi-freq leads to higher delay-time activation in dlPFC across all trials (proactive) !</div><div><br></div><div>- Exemple of AX-CPT task: proactive control is beneficial (at probe time) on BX trials ('don't bother!'), but 'harmful' on AY trials (hmmm...). Most common deficit: AY is OK, BX is damaged.They suggest a 'shift to reactive control' [rather than just dumb loss of STM??] because they see decrease cue-time, but ALSO increase probe-time PFC activation...</div>"
}

@ARTICLE{Baddeley2012-kw,
title = "Working memory: theories, models, and controversies",
author = "Baddeley, Alan",
affiliation = "Department of Psychology, University of York, United Kingdom. ab50@york.ac.uk",
abstract = "I present an account of the origins and development of the multicomponent approach to working memory, making a distinction between the overall theoretical framework, which has remained relatively stable, and the attempts to build more specific models within this framework. I follow this with a brief discussion of alternative models and their relationship to the framework. I conclude with speculations on further developments and a comment on the value of attempting to apply models and theories beyond the laboratory studies on which they are typically based.",
journal = "Annu. Rev. Psychol.",
volume =  63,
pages = "1--29",
year =  2012
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Boerlin2013-wh,
title = "Predictive coding of dynamical variables in balanced spiking networks",
author = "Boerlin, Martin and Machens, Christian K and Den\`{e}ve, Sophie",
affiliation = "Group for Neural Theory, D\'{e}partement d'\'{E}tudes Cognitives, \'{E}cole Normale Sup\'{e}rieure, Paris, France.",
abstract = "Two observations about the cortex have puzzled neuroscientists for a long time. First, neural responses are highly variable. Second, the level of excitation and inhibition received by each neuron is tightly balanced at all times. Here, we demonstrate that both properties are necessary consequences of neural networks that represent information efficiently in their spikes. We illustrate this insight with spiking networks that represent dynamical variables. Our approach is based on two assumptions: We assume that information about dynamical variables can be read out linearly from neural spike trains, and we assume that neurons only fire a spike if that improves the representation of the dynamical variables. Based on these assumptions, we derive a network of leaky integrate-and-fire neurons that is able to implement arbitrary linear dynamical systems. We show that the membrane voltage of the neurons is equivalent to a prediction error about a common population-level signal. Among other things, our approach allows us to construct an integrator network of spiking neurons that is robust against many perturbations. Most importantly, neural variability in our networks cannot be equated to noise. Despite exhibiting the same single unit properties as widely used population code models (e.g. tuning curves, Poisson distributed spike trains), balanced networks are orders of magnitudes more reliable. Our approach suggests that spikes do matter when considering how the brain computes, and that the reliability of cortical representations could have been strongly underestimated.",
journal = "PLoS Comput. Biol.",
volume =  9,
number =  11,
pages = "e1003258",
month =  "14~" # nov,
year =  2013,
annote = "- How to build a spiking RNN, such that its linear readout through a FIXED matrix Gamma reproduces a given dynamical system dx/dt = Ax + Input(t) ?<div><br></div><div>- Posit that you only want to spike when this would reduce the error between the actual readout x and the expected x (and also keep firing rates low)</div><div><br></div><div>- Then, minimizing this cost function leads to a complete ANALYTICAL network + neuron description! </div><div><br></div><div>- Spike only when V > Thres, where V depends on current error, weights and current firing rate, and Thres depends on time constants and sum-weight magnitude.</div><div><br></div><div>- In turn, use the expression of V to compute the necessary recurrent and input weights !! Turns out the input weights are just Gamma'.</div><div><br></div><div>- Recurrent W seems to include a 'slow' component and a 'fast' inhibitory component based on Gamma * Gamma', i.e. cells with correlated output/input weights inhibit each other fast - as in Foldiak's paper / LCA stuff ?!</div><div><br></div><div>- I think they have another paper where they show how you can also derive a STDP-like learning rule from it!</div>"
}

@ARTICLE{Wallis2001-zb,
title = "Single neurons in prefrontal cortex encode abstract rules",
author = "Wallis, J D and Anderson, K C and Miller, E K",
affiliation = "Center for Learning and Memory, RIKEN-MIT Neuroscience Research Center, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge 02139, USA.",
abstract = "The ability to abstract principles or rules from direct experience allows behaviour to extend beyond specific circumstances to general situations. For example, we learn the 'rules' for restaurant dining from specific experiences and can then apply them in new restaurants. The use of such rules is thought to depend on the prefrontal cortex (PFC) because its damage often results in difficulty in following rules. Here we explore its neural basis by recording from single neurons in the PFC of monkeys trained to use two abstract rules. They were required to indicate whether two successively presented pictures were the same or different depending on which rule was currently in effect. The monkeys performed this task with new pictures, thus showing that they had learned two general principles that could be applied to stimuli that they had not yet experienced. The most prevalent neuronal activity observed in the PFC reflected the coding of these abstract rules.",
journal = "Nature",
volume =  411,
number =  6840,
pages = "953--956",
month =  "21~" # jun,
year =  2001,
annote = "- Delayed match OR non-match to sample: monkeys learn to release lever when they see a test stim. that is same as, OR different than, sample stimulus.<div><br></div><div>- The rule (``react when see same'' or ``react when see different'') is randomly chosen for each trial, indicated by a sensory cue.</div><div><br></div><div>- Many neurons are strongly selective for the abstract rule - 'same' vs. 'different' - rather than cue/stimulus features!</div><div><br></div><div>- Difference in firing starts early, but grows over the delay period (>1000ms)<br><div><br></div></div><div>- Difference not caused by cue, because different cues are used for each rule, and most neurons don't care.</div><div><br></div><div>- Very few neurons selective for sample identity? Though significantly more in ventrolateral than in either OFC or dlPFC (rule seems equally represented across areas)</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Miller1994-xh,
title = "Parallel neuronal mechanisms for short-term memory",
author = "Miller, E K and Desimone, R",
affiliation = "Laboratory of Neuropsychology, National Institute of Mental Health, Bethesda, MD 20892.",
abstract = "Although objects that have just been seen may persist in memory automatically for a time and interact passively with incoming stimulation, some tasks require that the memory be actively maintained and used. To test for the existence of separate automatic and volitional mechanisms of short-term memory, recordings were made from neurons in the inferior temporal cortex of monkeys while the monkeys held a sample picture ``in mind'' and signaled when it was repeated in a sequence of pictures, ignoring other stimulus repetitions. Some neurons were suppressed by any picture repetition, regardless of relevance, whereas others were enhanced, but only when a picture matched the sample. Short-term memory appears to reflect the parallel operation of these two mechanisms--one being automatic and the other active.",
journal = "Science",
volume =  263,
number =  5146,
pages = "520--522",
month =  "28~" # jan,
year =  1994,
annote = "<div>[ In monkey IT, cells show either repetition suppression OR enhancement of target, with very few having both! Weird...]</div><div><br></div><div>[ Note: Apparently Eskandar 1992 found strong stimulus information in temporal time-course of the response, but Miller 1993 cited in Desimone, Miller and Chelazz in the Koch \& Davis book found none; difference may be due to fact that Eskandar only had short trials with no-intervening distractors? Does long trials / distractors really do stabilize coding?... But note that this is not about delay activity, only response]</div><div><br></div>- Visual match to sample, with intervening distractors. Recording in monkey IT.<div><br></div><div>- Monkeys learn very well, but when you introduce repeating distractors they respond to them! They had merely learned a repetition rule!<span style=``word-spacing: normal; line-height: 1.5em;''> After a while, they learn the proper task and perform well even with repeating distractors</span></div><div><br></div><div>- About half the cells have memory effect (Response affected by target identity, even after many distractors).</div><div><br></div><div>- Apparently no delay activity after the first distractor.</div><div><br></div><div>- Of these, 62\% of cells show mere suppression of any repeated stimulus.</div><div><br></div><div>- 35\% of cells show no suppression of repeated stimuli, but show enhanced response to the matching stimuli (independently of which stimulus is the target)!</div><div><br></div><div>- These populations are distinct: only ~2\% of the cells show both repetition-suppression AND target-enhancement !!</div><div><br></div>"
}

@ARTICLE{Vann2009-ij,
title = "What does the retrosplenial cortex do?",
author = "Vann, Seralynne D and Aggleton, John P and Maguire, Eleanor A",
affiliation = "School of Psychology, Cardiff University, Tower Building, Park Place, Cardiff, CF10 3AT, UK. vannsd@Cardiff.ac.uk",
abstract = "The past decade has seen a transformation in research on the retrosplenial cortex (RSC). This cortical area has emerged as a key member of a core network of brain regions that underpins a range of cognitive functions, including episodic memory, navigation, imagination and planning for the future. It is now also evident that the RSC is consistently compromised in the most common neurological disorders that impair memory. Here we review advances on multiple fronts, most notably in neuroanatomy, animal studies and neuroimaging, that have highlighted the importance of the RSC for cognition, and consider why specifying its precise functions remains problematic.",
journal = "Nat. Rev. Neurosci.",
volume =  10,
number =  11,
pages = "792--802",
month =  nov,
year =  2009,
annote = "- The Restrosplenial cortex: it's complicated.<div><br></div><div>- Mutually connected with hippocampus (subiculum, etc.) and anterior dorsal Thalamus (which are connected together).</div><div><br></div><div>- Also connected to PFC, may provide a route from HPC to PFC?</div><div><br></div><div>- Lesions lead to navigation deficits</div><div><br></div><div>- First area damaged in Alzheimer! Correlates with memory deficits?...</div><div><br></div><div>- Massively activated in fMRI by episodic memory retrieval and navigation tasks</div>"
}

@ARTICLE{Olafsdottir2015-mh,
title = "Hippocampal place cells construct reward related sequences through unexplored space",
author = "\'{O}lafsd\'{o}ttir, H Freyja and Barry, Caswell and Saleem, Aman B and Hassabis, Demis and Spiers, Hugo J",
affiliation = "Institute of Behavioural Neuroscience, Department of Experimental Psychology, Division of Psychology and Language Sciences, University College London, London, United Kingdom. Department of Cell and Developmental Biology, University College London, London, United Kingdom. UCL Institute of Ophthalmology, University College London, London, United Kingdom. Gatsby Computational Neuroscience Unit, University College London, London, United Kingdom. Institute of Behavioural Neuroscience, Department of Experimental Psychology, Division of Psychology and Language Sciences, University College London, London, United Kingdom.",
abstract = "Dominant theories of hippocampal function propose that place cell representations are formed during an animal's first encounter with a novel environment and are subsequently replayed during off-line states to support consolidation and future behaviour. Here we report that viewing the delivery of food to an unvisited portion of an environment leads to off-line pre-activation of place cells sequences corresponding to that space. Such 'preplay' was not observed for an unrewarded but otherwise similar portion of the environment. These results suggest that a hippocampal representation of a visible, yet unexplored environment can be formed if the environment is of motivational relevance to the animal. We hypothesise such goal-biased preplay may support preparation for future experiences in novel environments.",
journal = "Elife",
volume =  4,
month =  "26~" # jun,
year =  2015,
annote = "- Rat in the stem of a T-maze can't access the left-right arms (because transparent barrier), but sees you put some food in one arm<div><br></div><div>- As a result, during period of rest, you get significant pre-play of the place cell sequences that will later be active during the (as yet unvisited) food arm !</div><div><br></div><div>- No significant pre-play of the non-food arm.</div><div><br></div><div>- Include a Bayesian position decoder for spiking place cells..</div>",
keywords = "consolidation; hippocampus; neuroscience; place cells; preplay; rat; replay; spatial memory"
}

@ARTICLE{Menegas2015-wd,
title = "Dopamine neurons projecting to the posterior striatum form an anatomically distinct subclass",
author = "Menegas, William and Bergan, Joseph F and Ogawa, Sachie K and Isogai, Yoh and Venkataraju, Kannan Umadevi and Osten, Pavel and Uchida, Naoshige and Watabe-Uchida, Mitsuko and Nelson, Sacha B",
abstract = "Combining rabies-virus tracing, optical clearing (CLARITY), and whole-brain light-sheet imaging, we mapped the monosynaptic inputs to midbrain dopamine neurons projecting to different targets (different parts of the striatum, cortex, amygdala, etc.) in mice. We found that most populations of dopamine neurons receive a similar set of inputs rather than forming strong reciprocal connections with their target areas. A common feature among most populations of dopamine neurons was the existence of dense 'clusters' of inputs within the ventral striatum. However, we found that dopamine neurons projecting to the posterior striatum were outliers, receiving relatively few inputs from the ventral striatum and instead receiving more inputs from the globus pallidus, subthalamic nucleus, and zona incerta. These results lay a foundation for understanding the input/output structure of the midbrain dopamine circuit and demonstrate that dopamine neurons projecting to the posterior striatum constitute a unique class of dopamine neurons regulated by different inputs.",
journal = "eLife Sciences",
publisher = "eLife Sciences Publications Limited",
pages = "e10032",
month =  "31~" # aug,
year =  2015
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lammel2014-tu,
title = "Reward and aversion in a heterogeneous midbrain dopamine system",
author = "Lammel, Stephan and Lim, Byung Kook and Malenka, Robert C",
affiliation = "Nancy Pritzker Laboratory, Department of Psychiatry and Behavioral Sciences, Stanford University School of Medicine, 265 Campus Drive, Stanford, CA 94305, USA.",
abstract = "The ventral tegmental area (VTA) is a heterogeneous brain structure that serves a central role in motivation and reward processing. Abnormalities in the function of VTA dopamine (DA) neurons and the targets they influence are implicated in several prominent neuropsychiatric disorders including addiction and depression. Recent studies suggest that the midbrain DA system is composed of anatomically and functionally heterogeneous DA subpopulations with different axonal projections. These findings may explain a number of previously confusing observations that suggested a role for DA in processing both rewarding as well as aversive events. Here we will focus on recent advances in understanding the neural circuits mediating reward and aversion in the VTA and how stress as well as drugs of abuse, in particular cocaine, alter circuit function within a heterogeneous midbrain DA system. This article is part of a Special Issue entitled 'NIDA 40th Anniversary Issue'.",
journal = "Neuropharmacology",
volume = "76 Pt B",
pages = "351--359",
month =  jan,
year =  2014,
annote = "<p>xtin[ That seems in direct contraiction with a Watanabe-Uchida paper, elife 2015, which found all DA neurons receive largely similar inputs except those projecting to ``posterior'' striatum....?]</p><p><br></p><p>- Before: DA neurons are just SNc and VTA. Now: Uh, no, VTA is full of separate, parallel lines to different targets!</p><p>- VTA has (at least) two populations of DAs:</p><p>    -lateral VTA: project to NAcc Lateral Shell, look like ``classical'' SNc DA neurons</p><p>    -Medial-posterior VTA: project to NAcc mShell, Core, mPFC, blAmygdala. Different properties/shapes/firing patterns.</p><p> </p><p>- SNc neurons seem more homogenous, but still different properties and targets.</p><p>    - medial SN DA project do DM Stri, not to DL Stri.</p><p>    - lateral SN (and VTA) DA project to DL Stri.</p><p> </p><p>- VTA also has projecting GABA neurons! Which target NAcc ACh interneurons! Promoting stimulus-outcome leaning!</p><p> </p><p>-
 Some DA neurons do the Schultz RPE thing, but aversive/salient events 
can also excite some DAs and cause DA release in target structure</p><p> </p><p>- Says Cohen et al. 2012 show many  DA neurons that react ++ to aversive??</p><p> </p><p>-LDTegmentum sends Exc to VTA DAs that target NAcc LatShell, maybe Inh to PFC-targeting DA neurons</p><p> </p><p>-LHab
 sends Exc to GABAs in 'rostromedial tegmental nucleus' = VTA tail, 
which inhibit the NAcc LatShell -targeting DAs! Same neurons also send 
Exc to DAs that project to mPFC.</p><p> </p><p>- Stress and DA: VTA DA 
stimulation either promotes, or combats stress-caused depression, 
depending on the study!! This might be effect of different VTA DA pops 
being targeted (though both studies seemed to look at terminal, 
target-located effects...)</p><p> </p><p>- Both all drugs of abuse AND acute stress potentiate AMPA receptors in [some!] VTA DAs....</p><p> </p>",
keywords = "AADC; AMPAR; ATP sensitive potassium channel; Aversion; BLA; CLi; CM; ChR2; D2R; DA; DAT; Dopamine; GAD; IF; IPN; KATP; LDT; LHb; MSN; MT; Mesocortical; Mesolimbic; N-methyl-d-aspartate; NAc; NMDAR; PBP; PFC; PN; RLi; RMTg; RRF; Reward; SN; SNc; SNr; TH; VGluT2; VMAT2; VTA; Ventral tegmental area; amino acid decarboxylase; basolateral amygdala; caudal linear nucleus; channelrhodopsin 2; dopamine; dopamine D2 receptor; dopamine transporter; fasciculus retroflexus; fr; glutamic acid decarboxylase; interfascicular nucleus; interpeduncular nucleus; lVTA; lateral VTA; lateral habenula; laterodorsal tegmentum; mVTA; mammillary body; medial VTA; medial lemniscus; medial terminal nucleus of the accessory optical tract; medium spiny neuron; ml; nucleus accumbens; parabrachial pigmented nucleus; paranigral nucleus; prefrontal cortex; retrorubral field; rostral linear nucleus of the raphe; rostromedial tegmental nucleus; substantia nigra; substantia nigra pars reticulata; substantia nirgra pars compacta; tyrosine hydroxylase; ventral tegmental area; vesicular glutamate transporter 2; vesicular monoamine transporter 2; $\alpha$-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid receptor"
}

@ARTICLE{Sit2009-rn,
title = "Complex dynamics of {V1} population responses explained by a simple gain-control model",
author = "Sit, Yiu Fai and Chen, Yuzhi and Geisler, Wilson S and Miikkulainen, Risto and Seidemann, Eyal",
affiliation = "Department of Computer Sciences, The University of Texas at Austin, 1 University Station, A8000, Austin, TX 78712, USA.",
abstract = "To understand sensory encoding and decoding, it is essential to characterize the dynamics of population responses in sensory cortical areas. Using voltage-sensitive dye imaging in awake, fixating monkeys, we obtained complete quantitative measurements of the spatiotemporal dynamics of V1 responses over the entire region activated by small, briefly presented stimuli. The responses exhibit several complex properties: they begin to rise approximately simultaneously over the entire active region, but reach their peak more rapidly at the center. However, at stimulus offset the responses fall simultaneously and at the same rate at all locations. Although response onset depends on stimulus contrast, both the peak spatial profile and the offset dynamics are independent of contrast. We show that these results are consistent with a simple population gain-control model that generalizes earlier single-neuron contrast gain-control models. This model provides valuable insight and is likely to be applicable to other brain areas.",
journal = "Neuron",
volume =  64,
number =  6,
pages = "943--956",
month =  "24~" # dec,
year =  2009
}

@ARTICLE{Gatys2015-vh,
title = "A Neural Algorithm of Artistic Style",
author = "Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias",
abstract = "In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery.",
month =  "26~" # aug,
year =  2015,
annote = "- Transform an image to imitate the style of random painters - Vangogh, Much, etc !!<div><br></div><div>- The key is to compute style / ``texture'' information (a la Simoncelli) by computing, for each DNN layer, the Gram / correlation matrix between the feature maps for this layer (across all positions, how much is this feature activity correlated with that feature activity?)</div><div><br></div><div>- Then you can just take any input picture and gradient-descent / backprop pixels to make the Gram matrix closer to that particular style's Gram matrix!</div>",
archivePrefix = "arXiv",
primaryClass = "cs.CV",
eprint = "1508.06576"
}

@ARTICLE{Greenhouse2015-ok,
title = "Nonspecific Inhibition of the Motor System during Response Preparation",
author = "Greenhouse, Ian and Sias, Ana and Labruna, Ludovica and Ivry, Richard B",
affiliation = "Department of Psychology, University of California, Berkeley, Berkeley, California 94720 igreenhouse@berkeley.edu. Department of Psychology, University of California, Berkeley, Berkeley, California 94720. Department of Psychology, University of California, Berkeley, Berkeley, California 94720. Department of Psychology, University of California, Berkeley, Berkeley, California 94720.",
abstract = "UNLABELLED: Motor system excitability is transiently inhibited during the preparation of responses. Previous studies have attributed this inhibition to the operation of two mechanisms, one hypothesized to help resolve competition between alternative response options, and the other to prevent premature response initiation. By this view, inhibition should be restricted to task-relevant muscles. Although this prediction is supported in one previous study (Duque et al., 2010), studies of stopping ongoing actions suggest that some forms of motor inhibition may be widespread (Badry et al., 2009). This motivated us to conduct a series of transcranial magnetic stimulation (TMS) experiments to examine in detail the specificity of preparatory inhibition in humans. Motor-evoked potentials were inhibited in task-irrelevant muscles during response preparation, even when the muscles were contralateral and not homologous to the responding effector. Inhibition was also observed in both choice and simple response task conditions, with and without a preparatory interval. Control experiments ruled out that this inhibition is due to expectancy of TMS or a possible need to cancel the prepared response. These findings suggest that motor inhibition during response preparation broadly influences the motor system and likely reflects a process that occurs whenever a response is selected. We propose a reinterpretation of the functional significance of preparatory inhibition, one by which inhibition reduces noise to enhance signal processing and modulates the gain of a selected response. SIGNIFICANCE STATEMENT: Motor preparation entails the recruitment of excitatory and inhibitory neural mechanisms. The current experiments address the specificity of inhibitory mechanisms, asking whether preparatory inhibition affects task-irrelevant muscles. Participants prepared a finger movement to be executed at the end of a short delay period. Transcranial magnetic stimulation over primary motor cortex provided an assay of corticospinal excitability. Consistent with earlier work, the agonist muscle for the forthcoming response was inhibited during the preparatory period. Moreover, this inhibition was evident in task-irrelevant muscles, although the magnitude of inhibition depended on whether the response was fixed or involved a choice. These results implicate a broadly tuned inhibitory mechanism that facilitates response preparation, perhaps by lowering background activity before response initiation.",
journal = "J. Neurosci.",
volume =  35,
number =  30,
pages = "10675--10684",
month =  "29~" # jul,
year =  2015,
annote = "- There is inhibition of the motor system during movement preparation<div><br></div><div>- Inhibition of muscular excitability measured by the amount of ``motor evoked potential'' after TMS....</div><div><br></div><div>- Apparently (much of) this inhibition is non-specific, affecting both the relevant and non-relevant muscle, whether there are multiple possible actions or just one, and both when catch trials are present or absent</div>",
keywords = "action selection; decision-making; gain modulation; inhibition; response preparation; transcranial magnetic stimulation"
}

@ARTICLE{Alemi2015-ku,
title = "A {Three-Threshold} Learning Rule Approaches the Maximal Capacity of Recurrent Neural Networks",
author = "Alemi, Alireza and Baldassi, Carlo and Brunel, Nicolas and Zecchina, Riccardo",
affiliation = "Human Genetics Foundation (HuGeF), Turin, Italy; DISAT, Politecnico di Torino, Turin, Italy. Human Genetics Foundation (HuGeF), Turin, Italy; DISAT, Politecnico di Torino, Turin, Italy. Departments of Statistics and Neurobiology, University of Chicago, Chicago, Illinois, United States of America. Human Genetics Foundation (HuGeF), Turin, Italy; DISAT, Politecnico di Torino, Turin, Italy.",
abstract = "Understanding the theoretical foundations of how memories are encoded and retrieved in neural populations is a central challenge in neuroscience. A popular theoretical scenario for modeling memory function is the attractor neural network scenario, whose prototype is the Hopfield model. The model simplicity and the locality of the synaptic update rules come at the cost of a poor storage capacity, compared with the capacity achieved with perceptron learning algorithms. Here, by transforming the perceptron learning rule, we present an online learning rule for a recurrent neural network that achieves near-maximal storage capacity without an explicit supervisory error signal, relying only upon locally accessible information. The fully-connected network consists of excitatory binary neurons with plastic recurrent connections and non-plastic inhibitory feedback stabilizing the network dynamics; the memory patterns to be memorized are presented online as strong afferent currents, producing a bimodal distribution for the neuron synaptic inputs. Synapses corresponding to active inputs are modified as a function of the value of the local fields with respect to three thresholds. Above the highest threshold, and below the lowest threshold, no plasticity occurs. In between these two thresholds, potentiation/depression occurs when the local field is above/below an intermediate threshold. We simulated and analyzed a network of binary neurons implementing this rule and measured its storage capacity for different sizes of the basins of attraction. The storage capacity obtained through numerical simulations is shown to be close to the value predicted by analytical calculations. We also measured the dependence of capacity on the strength of external inputs. Finally, we quantified the statistics of the resulting synaptic connectivity matrix, and found that both the fraction of zero weight synapses and the degree of symmetry of the weight matrix increase with the number of stored patterns.",
journal = "PLoS Comput. Biol.",
volume =  11,
number =  8,
pages = "e1004439",
month =  aug,
year =  2015,
annote = "<div><font color=``\#000000''><span style=``line-height: normal;''>[ NOTE: requires 1- fixed input connections (so can't apply to my stuff ??...) and 2- STRONG inputs during learning, that 'clamp' the network (hmm, can do that with attention?]</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''><br></span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>Hi Joe,</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''><br></span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>This is a very clever, and apparently biologically plausible learning</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>method for learning input patterns in a recurrent network of binary</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>neurons, similar to the Hopfield network. The goal is to ``learn'' patterns,</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>in the sense that after learning, any initial activation pattern over the</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>network will automatically move towards one of the stored patterns</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>(presumably the stored pattern closest to current network activity).</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''><br></span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>The advantage of this particular rule, as opposed to simple Hebbian rules,</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>is that it can store many more patterns without interference (i.e. many</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>more different patterns can be reliably reconstructed from partial input).</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''><br></span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>The ``trick'' is that, during learning, the inputs must be very strong. This</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>ensures that, when you present a pattern of activity to the network for</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>learning, the network's activity is ``clamped'' to this incoming pattern,</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>independently of whatever the lateral connections are! Every cell's</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>activity during the stimulus presentation is exactly its expected value in</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>the presented pattern.</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''><br></span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>When that happens, it is easy to modify the synapses in such a way that</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>the network will tend to reproduce this same pattern in the future: if a</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>cell is active, you want to increase its connections from other</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>currently-active cells (so it will tend to activate again when these same</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>cells are also active in the future); and if it is inactive, you want to</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>decrease its connections from other currently-active cells (so it tends to</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>de-activate when the same cells are also active in the future).</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''><br></span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>In addition, once the weights are ``strong enough'' in the appropriate</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>direction to withstand a certain amount of noise, you stop the learning</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>(otherwise you would end up with infinite-magnitude weights). This is what</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>the additional thresholds Theta0 and Theta1 do - when the total incoming</span></font></div><div><font color=``\#000000''><span style=``line-height: normal;''>inputs become lower or higher than this, stop modifying weights.</span></font></div><div><br></div>"
}

@ARTICLE{Michalka2015-hl,
title = "{Short-Term} Memory for Space and Time Flexibly Recruit Complementary {Sensory-Biased} Frontal Lobe Attention Networks",
author = "Michalka, Samantha W and Kong, Lingqiang and Rosen, Maya L and Shinn-Cunningham, Barbara G and Somers, David C",
affiliation = "Center for Computational Neuroscience and Neural Technology, Boston University, Boston, MA 02215, USA; Graduate Program for Neuroscience, Boston University, Boston, MA 02215, USA. Electronic address: samantha.michalka@gmail.com. Center for Computational Neuroscience and Neural Technology, Boston University, Boston, MA 02215, USA; Department of Psychological and Brain Sciences, Boston University, Boston, MA 02215, USA. Department of Psychological and Brain Sciences, Boston University, Boston, MA 02215, USA. Center for Computational Neuroscience and Neural Technology, Boston University, Boston, MA 02215, USA; Biomedical Engineering, Boston University, Boston, MA 02215, USA. Center for Computational Neuroscience and Neural Technology, Boston University, Boston, MA 02215, USA; Department of Psychological and Brain Sciences, Boston University, Boston, MA 02215, USA; Graduate Program for Neuroscience, Boston University, Boston, MA 02215, USA. Electronic address: somers@bu.edu.",
abstract = "The frontal lobes control wide-ranging cognitive functions; however, functional subdivisions of human frontal cortex are only coarsely mapped. Here, functional magnetic resonance imaging reveals two distinct visual-biased attention regions in lateral frontal cortex, superior precentral sulcus (sPCS) and inferior precentral sulcus (iPCS), anatomically interdigitated with two auditory-biased attention regions, transverse gyrus intersecting precentral sulcus (tgPCS) and caudal inferior frontal sulcus (cIFS). Intrinsic functional connectivity analysis demonstrates that sPCS and iPCS fall within a broad visual-attention network, while tgPCS and cIFS fall within a broad auditory-attention network. Interestingly, we observe that spatial and temporal short-term memory (STM), respectively, recruit visual and auditory attention networks in the frontal lobe, independent of sensory modality. These findings not only demonstrate that both sensory modality and information domain influence frontal lobe functional organization, they also demonstrate that spatial processing co-localizes with visual processing and that temporal processing co-localizes with auditory processing in lateral frontal cortex.",
journal = "Neuron",
volume =  87,
number =  4,
pages = "882--892",
month =  "19~" # aug,
year =  2015
}

@ARTICLE{Lerner2015-mi,
title = "{Intact-Brain} Analyses Reveal Distinct Information Carried by {SNc} Dopamine Subcircuits",
author = "Lerner, Talia N and Shilyansky, Carrie and Davidson, Thomas J and Evans, Kathryn E and Beier, Kevin T and Zalocusky, Kelly A and Crow, Ailey K and Malenka, Robert C and Luo, Liqun and Tomer, Raju and Deisseroth, Karl",
affiliation = "Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA. Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA. Department of Biology, Stanford University, Stanford, CA 94305, USA. Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA; Department of Biology, Stanford University, Stanford, CA 94305, USA; Nancy Pritzker Laboratory, Stanford University, Stanford, CA 94305, USA; Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA; Neuroscience Program, Stanford University, Stanford, CA 94305, USA. CNC Program, Stanford University, Stanford, CA 94305, USA. Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA; Nancy Pritzker Laboratory, Stanford University, Stanford, CA 94305, USA. Department of Biology, Stanford University, Stanford, CA 94305, USA; Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA; Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA; Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA. Electronic address: deissero@stanford.edu.",
abstract = "Recent progress in understanding the diversity of midbrain dopamine neurons has highlighted the importance-and the challenges-of defining mammalian neuronal cell types. Although neurons may be best categorized using inclusive criteria spanning biophysical properties, wiring of inputs, wiring of outputs, and activity during behavior, linking all of these measurements to cell types within the intact brains of living mammals has been difficult. Here, using an array of intact-brain circuit interrogation tools, including CLARITY, COLM, optogenetics, viral tracing, and fiber photometry, we explore the diversity of dopamine neurons within the substantia nigra pars compacta (SNc). We identify two parallel nigrostriatal dopamine neuron subpopulations differing in biophysical properties, input wiring, output wiring to dorsomedial striatum (DMS) versus dorsolateral striatum (DLS), and natural activity patterns during free behavior. Our results reveal independently operating nigrostriatal information streams, with implications for understanding the logic of dopaminergic feedback circuits and the diversity of mammalian neuronal cell types.",
journal = "Cell",
volume =  162,
number =  3,
pages = "635--647",
month =  "30~" # jul,
year =  2015,
annote = "- SNc DA neurons sends distinct inputs to DMS and DLS: medial, DMS-projecting SNcDA neurons are excited by reward, inhibited by shock; lateral, DLS-projecting are excited by BOTH reward AND shock !!<div><br></div><div>- Also receive strong reciprocal inputs from Striatum, biased according to projection target: DLS-proj receive more DLS Striatal input, DMS-proj receive more from DLS (note: all inhibitory, bcz striatum!)</div><div><br></div><div>- DMS-proj and DLS-proj are very strongly segregated, with little cross-branching of axons to the ``other'' target zone. By contrast, both DMS and DLS project to both of these two populations, but in a biased manner.</div><div><br></div><div>- DLS-originating Striatal (inhibitory) input to both lateral and medial SNcDA n's is much stronger than DMS-originating.</div><div><br></div><div><br></div>"
}

@MISC{noauthor_undated-vv,
title = "Download Limit Exceeded",
howpublished = "\url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.862&rep=rep1&type=pdf}",
note = "Accessed: 2015-8-21"
}

@ARTICLE{Montague1996-mv,
title = "A framework for mesencephalic dopamine systems based on predictive Hebbian learning",
author = "Montague, P R and Dayan, P and Sejnowski, T J",
affiliation = "Division of Neuroscience, Baylor College of Medicine, Houston, Texas 77030, USA.",
abstract = "We develop a theoretical framework that shows how mesencephalic dopamine systems could distribute to their targets a signal that represents information about future expectations. In particular, we show how activity in the cerebral cortex can make predictions about future receipt of reward and how fluctuations in the activity levels of neurons in diffuse dopamine systems above and below baseline levels would represent errors in these predictions that are delivered to cortical and subcortical targets. We present a model for how such errors could be constructed in a real brain that is consistent with physiological results for a subset of dopaminergic neurons located in the ventral tegmental area and surrounding dopaminergic neurons. The theory also makes testable predictions about human choice behavior on a simple decision-making task. Furthermore, we show that, through a simple influence on synaptic plasticity, fluctuations in dopamine release can act to change the predictions in an appropriate manner.",
journal = "J. Neurosci.",
volume =  16,
number =  5,
pages = "1936--1947",
month =  "1~" # mar,
year =  1996
}

@ARTICLE{Saddoris2015-ct,
title = "Differential Dopamine Release Dynamics in the Nucleus Accumbens Core and Shell Reveal Complementary Signals for Error Prediction and Incentive Motivation",
author = "Saddoris, Michael P and Cacciapaglia, Fabio and Wightman, R Mark and Carelli, Regina M",
abstract = "Mesolimbic dopamine (DA) is phasically released during appetitive behaviors, though there is substantive disagreement about the specific purpose of these DA signals. For example, prediction error (PE) models suggest a role of learning, while incentive salience (IS) models argue that the DA signal imbues stimuli with value and thereby stimulates motivated behavior. However, within the nucleus accumbens (NAc) patterns of DA release can strikingly differ between subregions, and as such, it is possible that these patterns differentially contribute to aspects of PE and IS. To assess this, we measured DA release in subregions of the NAc during a behavioral task that spatiotemporally separated sequential goal-directed stimuli. Electrochemical methods were used to measure subsecond NAc dopamine release in the core and shell during a well learned instrumental chain schedule in which rats were trained to press one lever (seeking; SL) to gain access to a second lever (taking; TL) linked with food delivery, and again during extinction. In the core, phasic DA release was greatest following initial SL presentation, but minimal for the subsequent TL and reward events. In contrast, phasic shell DA showed robust release at all task events. Signaling decreased between the beginning and end of sessions in the shell, but not core. During extinction, peak DA release in the core showed a graded decrease for the SL and pauses in release during omitted expected rewards, whereas shell DA release decreased predominantly during the TL. These release dynamics suggest parallel DA signals capable of supporting distinct theories of appetitive behavior. SIGNIFICANCE STATEMENT Dopamine signaling in the brain is important for a variety of cognitive functions, such as learning and motivation. Typically, it is assumed that a single dopamine signal is sufficient to support these cognitive functions, though competing theories disagree on how dopamine contributes to reward-based behaviors. Here, we have found that real-time dopamine release within the nucleus accumbens (a primary target of midbrain dopamine neurons) strikingly varies between core and shell subregions. In the core, dopamine dynamics are consistent with learning-based theories (such as reward prediction error) whereas in the shell, dopamine is consistent with motivation-based theories (e.g., incentive salience). These findings demonstrate that dopamine plays multiple and complementary roles based on discrete circuits that help animals optimize rewarding behaviors.",
journal = "J. Neurosci.",
volume =  35,
number =  33,
pages = "11572--11582",
month =  "19~" # aug,
year =  2015
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Markowitz2015-bw,
title = "Multiple component networks support working memory in prefrontal cortex",
author = "Markowitz, David A and Curtis, Clayton E and Pesaran, Bijan",
abstract = "Lateral prefrontal cortex (PFC) is regarded as the hub of the brain’s working memory (WM) system, but it remains unclear whether WM is supported by a single distributed network or multiple specialized network components in this region. To investigate this problem, we recorded from neurons in PFC while monkeys made delayed eye movements guided by memory or vision. We show that neuronal responses during these tasks map to three anatomically specific modes of persistent activity. The first two modes encode early and late forms of information storage, whereas the third mode encodes response preparation. Neurons that reflect these modes are concentrated at different anatomical locations in PFC and exhibit distinct patterns of coordinated firing rates and spike timing during WM, consistent with distinct networks. These findings support multiple component models of WM and consequently predict distinct failures that could contribute to neurologic dysfunction.",
journal = "Proceedings of the National Academy of Sciences",
month =  "17~" # aug,
year =  2015,
annote = "- There seems to be several 'modes', or populations, encoding various aspects of WM in PFC <div><br></div><div>- One 'early storage' (sensory w/ small memory) population</div><div>- One 'late storage' population (higher for mem than for vis-guided, diff grows over time)</div><div>- One 'response' population (encodes response location indep of vis or mem-guided; stronger for fast-RT than slow-RT)</div><div><br></div><div>- Spatially segregated ?? Seem connected within. not connect b/w populations (shown by noise correlations for similarly tuned cells of various pops)</div>"
}

@ARTICLE{Corbetta2008-gf,
title = "The reorienting system of the human brain: from environment to theory of mind",
author = "Corbetta, Maurizio and Patel, Gaurav and Shulman, Gordon L",
affiliation = "Department of Neurology, Washington University School of Medicine, St. Louis, MO 63110, USA. mau@npg.wustl.edu",
abstract = "Survival can depend on the ability to change a current course of action to respond to potentially advantageous or threatening stimuli. This ``reorienting'' response involves the coordinated action of a right hemisphere dominant ventral frontoparietal network that interrupts and resets ongoing activity and a dorsal frontoparietal network specialized for selecting and linking stimuli and responses. At rest, each network is distinct and internally correlated, but when attention is focused, the ventral network is suppressed to prevent reorienting to distracting events. These different patterns of recruitment may reflect inputs to the ventral attention network from the locus coeruleus/norepinephrine system. While originally conceptualized as a system for redirecting attention from one object to another, recent evidence suggests a more general role in switching between networks, which may explain recent evidence of its involvement in functions such as social cognition.",
journal = "Neuron",
volume =  58,
number =  3,
pages = "306--324",
month =  "8~" # may,
year =  2008
}

@ARTICLE{Arnsten2012-mn,
title = "Neuromodulation of thought: flexibilities and vulnerabilities in prefrontal cortical network synapses",
author = "Arnsten, Amy F T and Wang, Min J and Paspalas, Constantinos D",
affiliation = "Department of Neurobiology, Yale Medical School, New Haven, CT 06510, USA. amy.arnsten@yale.edu",
abstract = "This review describes unique neuromodulatory influences on working memory prefrontal cortical (PFC) circuits that coordinate cognitive strength with arousal state. Working memory arises from recurrent excitation within layer III PFC pyramidal cell NMDA circuits, which are afflicted in aging and schizophrenia. Neuromodulators rapidly and flexibly alter the efficacy of these synaptic connections, while leaving the synaptic architecture unchanged, a process called dynamic network connectivity (DNC). Increases in calcium-cAMP signaling open ion channels in long, thin spines, gating network connections. Inhibition of calcium-cAMP signaling by stimulating $\alpha$2A-adrenoceptors on spines strengthens synaptic efficacy and increases network firing, whereas optimal stimulation of dopamine D1 receptors sculpts network inputs to refine mental representation. Generalized increases in calcium-cAMP signaling during fatigue or stress disengage dlPFC recurrent circuits, reduce firing and impair top-down cognition. Impaired DNC regulation contributes to age-related cognitive decline, while genetic insults to DNC proteins are commonly linked to schizophrenia.",
journal = "Neuron",
volume =  76,
number =  1,
pages = "223--239",
month =  "4~" # oct,
year =  2012
}

@ARTICLE{Puig2014-cb,
title = "Prefrontal dopamine in associative learning and memory",
author = "Puig, M V and Antzoulatos, E G and Miller, E K",
affiliation = "The Picower Institute for Learning and Memory and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. Electronic address: mvpuig@mit.edu. Center for Neuroscience, Department of Neurobiology, Physiology and Behavior, University of California, Davis, CA 95618, USA. The Picower Institute for Learning and Memory and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA.",
abstract = "Learning to associate specific objects or actions with rewards and remembering the associations are everyday tasks crucial for our flexible adaptation to the environment. These higher-order cognitive processes depend on the prefrontal cortex (PFC) and frontostriatal circuits that connect areas in the frontal lobe with the striatum in the basal ganglia. Both structures are densely innervated by dopamine (DA) afferents that originate in the midbrain. Although the activity of DA neurons is thought to be important for learning, the exact role of DA transmission in frontostriatal circuits during learning-related tasks is still unresolved. Moreover, the neural substrates of this modulation are poorly understood. Here, we review our recent work in monkeys utilizing local pharmacology of DA agents in the PFC to investigate the cellular mechanisms of DA modulation of associative learning and memory. We show that blocking both D1 and D2 receptors in the lateral PFC impairs learning of new stimulus-response associations and cognitive flexibility, but not the memory of highly familiar associations. In addition, D2 receptors may also contribute to motivation. The learning deficits correlated with reductions of neural information about the associations in PFC neurons, alterations in global excitability and spike synchronization, and exaggerated alpha and beta neural oscillations. Our findings provide new insights into how DA transmission modulates associative learning and memory processes in frontostriatal systems.",
journal = "Neuroscience",
volume = "282C",
pages = "217--229",
month =  "18~" # sep,
year =  2014,
keywords = "dopamine receptors; learning and memory; macaque monkey; neural oscillations; prefrontal cortex"
}

@ARTICLE{Tetzlaff2015-vq,
title = "The Use of Hebbian Cell Assemblies for Nonlinear Computation",
author = "Tetzlaff, Christian and Dasgupta, Sakyasingha and Kulvicius, Tomas and W{\"{o}}rg{\"{o}}tter, Florentin",
affiliation = "1] Institute for Physics - Biophysics, Georg-August-University, Friedrich-Hund Platz 1, 37077, G{\"{o}}ttingen, Germany [2] Bernstein Center for Computational Neuroscience, Georg-August-University, Friedrich-Hund Platz 1, 37077, G{\"{o}}ttingen, Germany [3]. 1] Institute for Physics - Biophysics, Georg-August-University, Friedrich-Hund Platz 1, 37077, G{\"{o}}ttingen, Germany [2] Bernstein Center for Computational Neuroscience, Georg-August-University, Friedrich-Hund Platz 1, 37077, G{\"{o}}ttingen, Germany [3]. 1] Institute for Physics - Biophysics, Georg-August-University, Friedrich-Hund Platz 1, 37077, G{\"{o}}ttingen, Germany [2] Bernstein Center for Computational Neuroscience, Georg-August-University, Friedrich-Hund Platz 1, 37077, G{\"{o}}ttingen, Germany [3]. 1] Institute for Physics - Biophysics, Georg-August-University, Friedrich-Hund Platz 1, 37077, G{\"{o}}ttingen, Germany [2] Bernstein Center for Computational Neuroscience, Georg-August-University, Friedrich-Hund Platz 1, 37077, G{\"{o}}ttingen, Germany.",
abstract = "When learning a complex task our nervous system self-organizes large groups of neurons into coherent dynamic activity patterns. During this, a network with multiple, simultaneously active, and computationally powerful cell assemblies is created. How such ordered structures are formed while preserving a rich diversity of neural dynamics needed for computation is still unknown. Here we show that the combination of synaptic plasticity with the slower process of synaptic scaling achieves (i) the formation of cell assemblies and (ii) enhances the diversity of neural dynamics facilitating the learning of complex calculations. Due to synaptic scaling the dynamics of different cell assemblies do not interfere with each other. As a consequence, this type of self-organization allows executing a difficult, six degrees of freedom, manipulation task with a robot where assemblies need to learn computing complex non-linear transforms and - for execution - must cooperate with each other without interference. This mechanism, thus, permits the self-organization of computationally powerful sub-structures in dynamic networks for behavior control.",
journal = "Sci. Rep.",
volume =  5,
pages = "12866",
month =  "7~" # aug,
year =  2015
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kim1999-wf,
title = "Neural correlates of a decision in the dorsolateral prefrontal cortex of the macaque",
author = "Kim, J N and Shadlen, M N",
affiliation = "Department of Physiology and Biophysics, University of Washington Medical School, Seattle, Washington 98195-7290, USA.",
abstract = "To make a visual discrimination, the brain must extract relevant information from the retina, represent appropriate variables in the visual cortex and read out this representation to decide which of two or more alternatives is more likely. We recorded from neurons in the dorsolateral prefrontal cortex (areas 8 and 46) of the rhesus monkey while it performed a motion discrimination task. The monkey indicated its judgment of direction by making appropriate eye movements. As the monkey viewed the motion stimulus, the neural response predicted the monkey's subsequent gaze shift, hence its judgment of direction. The response comprised a mixture of high-level oculomotor signals and weaker visual sensory signals that reflected the strength and direction of motion. This combination of sensory integration and motor planning could reflect the conversion of visual motion information into a categorical decision about direction and thus give insight into the neural computations behind a simple cognitive act.",
journal = "Nat. Neurosci.",
volume =  2,
number =  2,
pages = "176--185",
month =  feb,
year =  1999,
annote = "- The Shadlen motion discrimination task, in dlPFC + FEF, with a delay (stimulus - delay - response)<div><br></div><div>- CUE-PERIOD NEURONS ARE NOT JUST SENSORY NEURONS!! They reflect a CHOICE/saccade towards the neuron's RF, based on stimulus (RDP) occurring OUTSIDE the RF  !!  (Note that the RF was detected with memory-guided saccades based on flashes in the RF!)</div><div><br></div><div>- Some neurons (Figure 2) reflect saccade to their RF during motion viewing only. Others (figure 3) reflect it during delay only, NOT when RDP is present !</div><div><br></div><div>- Selectivity during stimulus is (mildly) dependent on motion strength. Late in the delay (just before response), it's independent of motion strength, just ramps up right until the saccade.</div>"
}

@ARTICLE{Volkow2015-zw,
title = "The Brain on Drugs: From Reward to Addiction",
author = "Volkow, Nora D and Morales, Marisela",
affiliation = "National Institute on Drug Abuse, National Institutes of Health, Bethesda, MD 20892, USA. Electronic address: nvolkow@nida.nih.gov. National Institute on Drug Abuse, National Institutes of Health, Bethesda, MD 20892, USA.",
abstract = "Advances in neuroscience identified addiction as a chronic brain disease with strong genetic, neurodevelopmental, and sociocultural components. We here discuss the circuit- and cell-level mechanisms of this condition and its co-option of pathways regulating reward, self-control, and affect. Drugs of abuse exert their initial reinforcing effects by triggering supraphysiologic surges of dopamine in the nucleus accumbens that activate the direct striatal pathway via D1 receptors and inhibit the indirect striato-cortical pathway via D2 receptors. Repeated drug administration triggers neuroplastic changes in glutamatergic inputs to the striatum and midbrain dopamine neurons, enhancing the brain's reactivity to drug cues, reducing the sensitivity to non-drug rewards, weakening self-regulation, and increasing the sensitivity to stressful stimuli and dysphoria. Drug-induced impairments are long lasting; thus, interventions designed to mitigate or even reverse them would be beneficial for the treatment of addiction.",
journal = "Cell",
volume =  162,
number =  4,
pages = "712--725",
month =  "13~" # aug,
year =  2015
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Pasupathy2005-lj,
title = "Different time courses of learning-related activity in the prefrontal cortex and striatum",
author = "Pasupathy, Anitha and Miller, Earl K",
affiliation = "The Picower Center for Learning and Memory, RIKEN-MIT Neuroscience Research Center and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139 USA. anitha@mit.edu",
abstract = "To navigate our complex world, our brains have evolved a sophisticated ability to quickly learn arbitrary rules such as 'stop at red'. Studies in monkeys using a laboratory test of this capacity--conditional association learning--have revealed that frontal lobe structures (including the prefrontal cortex) as well as subcortical nuclei of the basal ganglia are involved in such learning. Neural correlates of associative learning have been observed in both brain regions, but whether or not these regions have unique functions is unclear, as they have typically been studied separately using different tasks. Here we show that during associative learning in monkeys, neural activity in these areas changes at different rates: the striatum (an input structure of the basal ganglia) showed rapid, almost bistable, changes compared with a slower trend in the prefrontal cortex that was more in accordance with slow improvements in behavioural performance. Also, pre-saccadic activity began progressively earlier in the striatum but not in the prefrontal cortex as learning took place. These results support the hypothesis that rewarded associations are first identified by the basal ganglia, the output of which 'trains' slower learning mechanisms in the frontal cortex.",
journal = "Nature",
volume =  433,
number =  7028,
pages = "873--876",
month =  "24~" # feb,
year =  2005,
annote = "- dlPFC (9 / 46) and caudate of striatum, Pasupathy task<div><br></div><div>- DURING CUE TIME, Population becomes selective for direction selectivity much earlier in caudate than in PFC during cue period - also very sharp transition</div><div><br></div><div>- Performance seems to track PFC selectivity much more than Caudate !</div><div><br></div><div>- Basically, during cue presentation, early in learning, the Caudate says ``Screw you, we're gonna look THAT way'' (even though it's wrong a lot), while PFC doesn't say anything (little to no selectivity). </div><div><br></div><div>- Implies that Striatum can maintain a memory of its own cue-time decision !! (Early in learning, the late-delay direction selectivity of PFC is zero, that of caudate is Low-But-Not-Zero !)</div><div><br></div><div>- However, during saccade time, Caudate response selectivity is always massive, just becomes earlier over learning (Most of PFC response selectivity is post-saccadic, but there's a little non-zero selectivity before saccade, though always after Caudate selectivity arises...)</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Histed2009-fr,
title = "Learning substrates in the primate prefrontal cortex and striatum: sustained activity related to successful actions",
author = "Histed, Mark H and Pasupathy, Anitha and Miller, Earl K",
affiliation = "The Picower Institute for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. mark\_histed@hms.harvard.edu",
abstract = "Learning from experience requires knowing whether a past action resulted in a desired outcome. The prefrontal cortex and basal ganglia are thought to play key roles in such learning of arbitrary stimulus-response associations. Previous studies have found neural activity in these areas, similar to dopaminergic neurons' signals, that transiently reflect whether a response is correct or incorrect. However, it is unclear how this transient activity, which fades in under a second, influences actions that occur much later. Here, we report that single neurons in both areas show sustained, persistent outcome-related responses. Moreover, single behavioral outcomes influence future neural activity and behavior: behavioral responses are more often correct and single neurons more accurately discriminate between the possible responses when the previous response was correct. These long-lasting signals about trial outcome provide a way to link one action to the next and may allow reward signals to be combined over time to implement successful learning.",
journal = "Neuron",
volume =  63,
number =  2,
pages = "244--253",
month =  "30~" # jul,
year =  2009,
annote = "- From monkey 'PFC' and Caudate. Must associate one of two object with saccading right or left. When performance reaches 90\%, the correct choice is reversed without warning. <div><br></div><div>- Some cells are strongly modulated by trial outcome (i.e. whether trial was correct or error / reward vs no-reward).</div><div><br></div><div>- Significant trial-outcome/reward information is maintained over seconds into the next trial (and apparently after that)</div><div><br></div><div>- Immediately after single error trials, direction selectivity is strongly reduced - i.e. cells fire more similarly for upcoming right-choice and left-choice! Even late in learning!</div><div><br></div><div>- Note that this apply throughout the trial, during cue, delay and response. So not specific to either Cue, Delay or Response cells (they show one example Cue cell with a massive effect).</div><div><br></div><div>- As a result, behavioral performance is much better just after correct trials than error trial (again, at any time in learning)</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wang2004-at,
title = "{SelectiveD2Receptor} Actionson the Functional Circuitryof Working Memory",
author = "Wang, Min and Vijayraghavan, Susheel and Goldman-Rakic, Patricia S",
journal = "Science",
volume =  303,
year =  2004,
annote = "- D2 ++ => stronger firing of RESPONSE cells, only for the preferred location, both pre/peri and post-saccadic<div><br></div><div>- Similarly, D2-- => lower firing in response cells for preferred location only.</div><div><br></div><div>- No effect on Cue or Delay cells !!</div><div><br></div><div>- D1++ = LOWER firing of DELAY cells. No effect on response cells! </div><div><br></div><div>[ Note that the Frank paper suggests D1 in basal ganglia increases contrast - low-firing fire less, high-firing fire more?... While D2 simply inhibits]</div><div><br></div><div>- So D1/D2 effect not only opposite of expected, but also strongly dissociated according to cell function</div><div><br></div><div>- D2 receptors are mostly in L5. Does it mean Response cells are L5? Arnsten thinks so. Alternatively they could be receiving input from L5, D2R-equipped cells?...</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wang2013-ba,
title = "{NMDA} receptors subserve persistent neuronal firing during working memory in dorsolateral prefrontal cortex",
author = "Wang, Min and Yang, Yang and Wang, Ching-Jung and Gamo, Nao J and Jin, Lu E and Mazer, James A and Morrison, John H and Wang, Xiao-Jing and Arnsten, Amy F T",
affiliation = "Department Neurobiology, Yale Medical School, New Haven, CT 06510, USA.",
abstract = "Neurons in the primate dorsolateral prefrontal cortex (dlPFC) generate persistent firing in the absence of sensory stimulation, the foundation of mental representation. Persistent firing arises from recurrent excitation within a network of pyramidal Delay cells. Here, we examined glutamate receptor influences underlying persistent firing in primate dlPFC during a spatial working memory task. Computational models predicted dependence on NMDA receptor (NMDAR) NR2B stimulation, and Delay cell persistent firing was abolished by local NR2B NMDAR blockade or by systemic ketamine administration. AMPA receptors (AMPARs) contributed background depolarization to sustain network firing. In contrast, many Response cells were sensitive to AMPAR blockade and increased firing after systemic ketamine, indicating that models of ketamine actions should be refined to reflect neuronal heterogeneity. The reliance of Delay cells on NMDAR may explain why insults to NMDARs in schizophrenia or Alzheimer's disease profoundly impair cognition.",
journal = "Neuron",
volume =  77,
number =  4,
pages = "736--749",
month =  "20~" # feb,
year =  2013,
annote = "<div>- Monkey, ODR (oculomotor delayed response), dlPFC.</div><div><br></div><div>- In PFC, contrarily to other areas (such as HPC), NMDA NR2B receptors are only in synapses (more precisely in Layer III glutamate synapses)</div><div><br></div>- If you block NMDA NR2B receptors, you  strongly reduce delay (memory) firing.<span style=``word-spacing: normal; line-height: 1.5em;''> Almost no effect on baseline, most effect on preferred-location firing</span><div><div><br></div><div>- AMPA blockade also has effect, but smaller, and later in the delay. NMDAR blockade inhibits throughout delay period.</div></div><div><br></div><div>- Says that Delay cells are Layer-III pyramidals.</div><div><br></div><div>- By contrast, Response cells are Layer-V deep neurons ??</div><div><br></div><div>- Some response cells are enhanced by NMDAR antagonists, strongly suppressed by AMPAR antag. These are all post-saccadic cells ! Maybe they receive feedback from oculo-motor areas </div>"
}

@ARTICLE{Kessler2015-mp,
title = "Generic Criticality in Ecological and Neuronal Networks",
author = "Kessler, David A and Levine, Herbert",
abstract = "We investigate the dynamics of two models of biological networks with purely suppressive interactions between the units; species interacting via niche competition and neurons via inhibitory synaptic coupling. In both of these cases, power-law scaling of the density of states with probability arises without any fine-tuning of the model parameters. These results argue against the increasingly popular notion that non-equilibrium living systems operate at special critical points, driven by there by evolution so as to enable adaptive processing of input data.",
month =  "10~" # aug,
year =  2015,
annote = "- A spiking network with mutual inhibition is chaotic, spikes in the 'homogenous' regime (~white noise)<div><br></div><div>- But just by adding a slightly adaptive threshold (which varies only by 10\%) you can generate slow fluctuations in firing rates / 'heterogenous' regime a la Ostojic!</div><div><br></div><div>- Also get a power-law distribution on the probability of states (i.e. firing vectors)</div><div><br></div><div>- Doesn't need precise fine-tuning!</div>",
archivePrefix = "arXiv",
primaryClass = "cond-mat.dis-nn",
eprint = "1508.02414"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Funahashi2006-ai,
title = "Prefrontal cortex and working memory processes",
author = "Funahashi, S",
affiliation = "Department of Cognitive and Behavioral Sciences, Graduate School of Human and Environmental Studies, Kyoto University, Sakyo-ku, Kyoto 606-8501, Japan. h50400@sakura.kudpc.kyoto-u.ac.jp",
abstract = "Working memory is a mechanism for short-term active maintenance of information as well as for processing maintained information. The dorsolateral prefrontal cortex has been known to participate in working memory. The analysis of task-related dorsolateral prefrontal cortex activity while monkeys performed a variety of working memory tasks revealed that delay-period activity is a neural correlate of a mechanism for temporary active maintenance of information, because this activity persisted throughout the delay period, showed selectivity to a particular visual feature, and was related to correct behavioral performances. Information processing can be considered as a change of the information represented by a population of neural activities during the progress of the trial. Using population vectors calculated by a population of task-related dorsolateral prefrontal cortex activities, we demonstrated the temporal change of information represented by a population of dorsolateral prefrontal cortex activities during performances of spatial working memory tasks. Cross-correlation analysis using spike firings of simultaneously isolated pairs of neurons reveals widespread functional interactions among neighboring neurons, especially neurons having delay-period activity, and their dynamic modulation depending on the context of the trial. Functional interactions among neurons and their dynamic modulation could be a mechanism of information processing in the dorsolateral prefrontal cortex.",
journal = "Neuroscience",
volume =  139,
number =  1,
pages = "251--261",
month =  "28~" # apr,
year =  2006,
annote = "- Delayed saccade to target, or opposite / 90deg from target.  Monkey, dlPFC.<div><br></div><div>- dlPFC neurons have clear 'memory fields' ! Lesions can produce localized deficits.</div><div><br></div><div>- Most (70 or 86\%) neurons w/ selective delay activity encode target location. Only a few encode saccade destination per se. BUT during response period, opposite - most neurons encode saccade destination!</div><div><br></div><div>- dlPFC also involved in non-spatial memory tasks, e.g. remembering faces, or the Romo task. Different neurons have different preferences.</div><div><br></div><div>- Dynamic coding: Neuron responses change over time within a delay period. Cite Quintana and Fuster 1999: cue color neurons --, response neurons ++ <span style=``word-spacing: normal; line-height: 1.5em;''> Also Rainer et al. 1999: match-to-sample task, sample-selective neurons --, neurons selective for ``anticipated'' targets (??) ++ during the delay period !</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Response-period in the opposite-direction delayed saccade: the direction encoded by the 'population vector' rotates from the cue to the saccade destination throughout the delay period!</span></div>"
}

@ARTICLE{Durstewitz2002-rd,
title = "The computational role of dopamine {D1} receptors in working memory",
author = "Durstewitz, Daniel and Seamans, Jeremy K",
affiliation = "AE Biopsychologie, Facult{\"{a}}t f{\"{u}}r Psychologie, Ruhr-Universit{\"{a}}t Bochum, Germany. Daniel.Durstewitz@ruhr-uni-bochum.de",
abstract = "The prefrontal cortex (PFC) is essential for working memory, which is the ability to transiently hold and manipulate information necessary for generating forthcoming action. PFC neurons actively encode working memory information via sustained firing patterns. Dopamine via D1 receptors potently modulates sustained activity of PFC neurons and performance in working memory tasks. In vitro patch-clamp data have revealed many different cellular actions of dopamine on PFC neurons and synapses. These effects were simulated using realistic networks of recurrently connected assemblies of PFC neurons. Simulated D1-mediated modulation led to a deepening and widening of the basins of attraction of high (working memory) activity states of the network, while at the same time background activity was depressed. As a result, self-sustained activity was more robust to distracting stimuli and noise. In this manner, D1 receptor stimulation might regulate the extent to which PFC network activity is focused on a particular goal state versus being open to new goals or information unrelated to the current goal.",
journal = "Neural Netw.",
volume =  15,
number = "4-6",
pages = "561--572",
month =  jun,
year =  2002,
annote = "- Effects of DA on PFC neurons: Increase NMDA and GABA sensitivity, but decrease (slightly) AMPA effects?..<div><br></div><div>- Increases the SNR of neurons: low-activity (idle) and high-activity (stored memory) are further apart, coherent with Cohen review<br><div><br></div><div>- A few mins of DA agonist -> Effects last stably for several hours??</div></div><div><br></div><div>- See also : Lapish et al J Neurosci 2015, The Arnsten /XJ Wang papers.</div>"
}

@ARTICLE{Deco2010-ez,
title = "Synaptic dynamics and decision making",
author = "Deco, Gustavo and Rolls, Edmund T and Romo, Ranulfo",
affiliation = "Department of Technology, Computational Neuroscience, Instituci\'{o} Catalana de Recerca i Estudis Avan\c{c}ats, Universitat Pompeu Fabra, 08018 Barcelona, Spain.",
abstract = "During decision making between sequential stimuli, the first stimulus must be held in memory and then compared with the second. Here, we show that in systems that encode the stimuli by their firing rate, neurons can use synaptic facilitation not only to remember the first stimulus during the delay but during the presentation of the second stimulus so that they respond to a combination of the first and second stimuli, as has been found for ``partial differential'' neurons recorded in the ventral premotor cortex during vibrotactile flutter frequency decision making. Moreover, we show that such partial differential neurons provide important input to a subsequent attractor decision-making network that can then compare this combination of the first and second stimuli with inputs from other neurons that respond only to the second stimulus. Thus, both synaptic facilitation and neuronal attractor dynamics can account for sequential decision making in such systems in the brain.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
volume =  107,
number =  16,
pages = "7545--7549",
month =  "20~" # apr,
year =  2010,
annote = "- You can build neurons that represent f1 + f2 in the stim2 period, simply by having synaptic facilitation within the stimulus-receiving pool: if f1 is high, there will be more facilitation and the pool will fire more strongly for a given f2 !<div><br></div><div>- Then, you just need to subtract f2-only neurons from it (i.e. sensory neurons without memory)</div><div><br></div><div>- Confusing descriptions, calls f1+f2 ``f1 > f2 - for a given f2''.</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Seung1996-ac,
title = "How the brain keeps the eyes still",
author = "Seung, H S",
affiliation = "Bell Laboratories, Lucent Technologies, Murray Hill, NJ 07974, USA.",
abstract = "The brain can hold the eyes still because it stores a memory of eye position. The brain's memory of horizontal eye position appears to be represented by persistent neural activity in a network known as the neural integrator, which is localized in the brainstem and cerebellum. Existing experimental data are reinterpreted as evidence for an ``attractor hypothesis'' that the persistent patterns of activity observed in this network form an attractive line of fixed points in its state space. Line attractor dynamics can be produced in linear or nonlinear neural networks by learning mechanisms that precisely tune positive feedback.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
volume =  93,
number =  23,
pages = "13339--13344",
month =  "12~" # nov,
year =  1996,
annote = "- Line attractor in a population of neuron can keep a constant memory of a current value.<div><br></div><div>- In the linear case, requires precise tuning to get one eigenvalue 1, and all others -1, plus a condition on the eigenvector to be orthogonal to the baseline + FF input (otherwise the latter would push the system along the eigenvector  line attractor?)</div><div><br></div><div>- In the non-linear case, can be approximated, e.g. by making the matrix rank-1 (since then any vector times the matrix is a multiple of the single-component of the matrix) + some optimization to minimize drift along this direction...</div><div><br></div><div><br></div>"
}

@ARTICLE{Janssen2005-ko,
title = "A representation of the hazard rate of elapsed time in macaque area {LIP}",
author = "Janssen, Peter and Shadlen, Michael N",
affiliation = "Howard Hughes Medical Institute, National Primate Research Center and Department of Physiology and Biophysics, University of Washington, Box 357290, Seattle, Washington 98195, USA.",
abstract = "The capacity to anticipate the timing of environmental cues allows us to allocate sensory resources at the right time and prepare actions. Such anticipation requires knowledge of elapsed time and of the probability that an event will occur. Here we show that neurons in the parietal cortex represent the probability, as a function of time, that a salient event is likely to occur. Rhesus monkeys were trained to make eye movements to peripheral targets after a light dimmed. Within a block of trials, the 'go' times were drawn from either a bimodal or unimodal distribution of random numbers. Neurons in the lateral intraparietal area showed anticipatory activity that revealed an internal representation of both elapsed time and the probability that the 'go' signal was about to occur (termed the hazard rate). The results indicate that the parietal cortex contains circuitry for representing the time structure of environmental cues over a range of seconds.",
journal = "Nat. Neurosci.",
volume =  8,
number =  2,
pages = "234--241",
month =  feb,
year =  2005,
annote = "- Time signals and hazard rate strongly modulate the activity of LIP neurons!<div><br></div><div>- Hazard rate = probability of event occurring right now, given that it didn't happen before</div><div><br></div><div>- Task: Saccade to a visible spot (in the RF) when a central fixation spot dims</div><div>- The dimming can occur within time t2, OR either at time t1 or t3 but not t2 (unimodal vs. bimodal), in alternating blocks</div><div><br></div><div>- The response of LIP neurons to the target is strongly modulated across time (~1/3) by the expected probability of dimming ! Follows the unimodal or the bimodal curve very well !</div><div><br></div><div>- Much stronger for motor destination than for attentional focus ! (If you put the dimming point, rather than the target, in the RF, you get much weaker modulation)</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Jun2010-hy,
title = "Heterogenous population coding of a short-term memory and decision task",
author = "Jun, Joseph K and Miller, Paul and Hern\'{a}ndez, Adri\'{a}n and Zainos, Antonio and Lemus, Luis and Brody, Carlos D and Romo, Ranulfo",
affiliation = "Howard Hughes Medical Institute, Princeton Neuroscience Institute and Department of Molecular Biology, Princeton University, Princeton, New Jersey 08544, USA. jkjun@princeton.edu",
abstract = "We examined neural spike recordings from prefrontal cortex (PFC) while monkeys performed a delayed somatosensory discrimination task. In general, PFC neurons displayed great heterogeneity in response to the task. That is, although individual cells spiked reliably in response to task variables from trial-to-trial, each cell had idiosyncratic combinations of response properties. Despite the great variety in response types, some general patterns held. We used linear regression analysis on the spike data to both display the full heterogeneity of the data and classify cells into categories. We compared different categories of cells and found little difference in their ability to carry information about task variables or their correlation to behavior. This suggests a distributed neural code for the task rather than a highly modularized one. Along this line, we compared the predictions of two theoretical models to the data. We found that cell types predicted by both models were not represented significantly in the population. Our study points to a different class of models that should embrace the inherent heterogeneity of the data, but should also account for the nonrandom features of the population.",
journal = "J. Neurosci.",
volume =  30,
number =  3,
pages = "916--929",
month =  "20~" # jan,
year =  2010,
annote = "- Excruciatingly detailed investigation of the data in the Romo task<div><br></div><div>- Lots of heterogeneity! Largest group: binary decision cells during the 2nd stim pres - most don't encode f1 during stim1... but the ones with the earliest decision signal seem more likely to encode f1, with the right sign for their comparison, during the late delay period??</div><div><br></div><div>-  Some sensory+memory neurons encode both f1 and f2 on either stim pres, AND keep memory of f1 during delay! Some neurons encode f1 during stim2 - many of those don't actually encode f1 during stim1 or delay (but many do too)!</div><div><br></div><div>- Also has a nice review of both the Machens 2005 model and the Miller\&Wang model. Finds that cells predicted by eitehr are not significantly found in the population</div><div><br></div><div>- NOTE: In figure 4Aii, the coloring changes ! in the first stimulus it represents f1, and in the second stimulus it represents f2 ! (notice the smooth transition)</div>"
}


@ARTICLE{Braver_undated-kt,
title = "On the control of control: The role of dopamine in regulating prefrontal function and working memory",
author = "Braver, Todd S and Cohen, Jonathan D",
abstract = "ABSTRACT An Important aspect of cognitive control is the ability to appropriately select, update, and maintain contextual information related to behavioral goals, and to me this information to coordinate processing over extended periods. In our novel, neurobiolog- ...",
journal = "ccpweb.wustl.edu"
}

@ARTICLE{Lerner2015-cf,
title = "{Intact-Brain} Analyses Reveal Distinct Information Carried by {SNc} Dopamine Subcircuits",
author = "Lerner, Talia N and Shilyansky, Carrie and Davidson, Thomas J and Evans, Kathryn E and Beier, Kevin T and Zalocusky, Kelly A and Crow, Ailey K and Malenka, Robert C and Luo, Liqun and Tomer, Raju and Deisseroth, Karl",
affiliation = "Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA. Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA. Department of Biology, Stanford University, Stanford, CA 94305, USA. Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA; Department of Biology, Stanford University, Stanford, CA 94305, USA; Nancy Pritzker Laboratory, Stanford University, Stanford, CA 94305, USA; Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA; Neuroscience Program, Stanford University, Stanford, CA 94305, USA. CNC Program, Stanford University, Stanford, CA 94305, USA. Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA; Nancy Pritzker Laboratory, Stanford University, Stanford, CA 94305, USA. Department of Biology, Stanford University, Stanford, CA 94305, USA; Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA. Department of Bioengineering, Stanford University, Stanford, CA 94305, USA; CNC Program, Stanford University, Stanford, CA 94305, USA; Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA 94305, USA; Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA. Electronic address: deissero@stanford.edu.",
abstract = "Recent progress in understanding the diversity of midbrain dopamine neurons has highlighted the importance-and the challenges-of defining mammalian neuronal cell types. Although neurons may be best categorized using inclusive criteria spanning biophysical properties, wiring of inputs, wiring of outputs, and activity during behavior, linking all of these measurements to cell types within the intact brains of living mammals has been difficult. Here, using an array of intact-brain circuit interrogation tools, including CLARITY, COLM, optogenetics, viral tracing, and fiber photometry, we explore the diversity of dopamine neurons within the substantia nigra pars compacta (SNc). We identify two parallel nigrostriatal dopamine neuron subpopulations differing in biophysical properties, input wiring, output wiring to dorsomedial striatum (DMS) versus dorsolateral striatum (DLS), and natural activity patterns during free behavior. Our results reveal independently operating nigrostriatal information streams, with implications for understanding the logic of dopaminergic feedback circuits and the diversity of mammalian neuronal cell types.",
journal = "Cell",
volume =  162,
number =  3,
pages = "635--647",
month =  "30~" # jul,
year =  2015,
annote = "201"
}

@ARTICLE{Harvey2012-qv,
title = "Choice-specific sequences in parietal cortex during a virtual-navigation decision task",
author = "Harvey, Christopher D and Coen, Philip and Tank, David W",
affiliation = "Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey 08544, USA. christopher\_harvey@hms.harvard.edu",
abstract = "The posterior parietal cortex (PPC) has an important role in many cognitive behaviours; however, the neural circuit dynamics underlying PPC function are not well understood. Here we optically imaged the spatial and temporal activity patterns of neuronal populations in mice performing a PPC-dependent task that combined a perceptual decision and memory-guided navigation in a virtual environment. Individual neurons had transient activation staggered relative to one another in time, forming a sequence of neuronal activation spanning the entire length of a task trial. Distinct sequences of neurons were triggered on trials with opposite behavioural choices and defined divergent, choice-specific trajectories through a state space of neuronal population activity. Cells participating in the different sequences and at distinct time points in the task were anatomically intermixed over microcircuit length scales (<100 micrometres). During working memory decision tasks, the PPC may therefore perform computations through sequence-based circuit dynamics, rather than long-lived stable states, implemented using anatomically intermingled microcircuits.",
journal = "Nature",
volume =  484,
number =  7392,
pages = "62--68",
month =  "5~" # apr,
year =  2012,
annote = "- T-maze, correct choice (right or left) indicated by stimuli in early part<div><br></div><div>- Vast majority of PPC cells have highly localized, choice-dependent firing locations / times (Hm, is it more space or time?)</div><div><br></div><div>- Cells fire in succession, with different trajectories for different choices. (are cells shared between choices?...)</div><div><br></div><div>- Error choices are reflected in cells following the wrong sequence !</div>"
}

@ARTICLE{Huang2011-js,
title = "Multistability properties of linear threshold discrete-time recurrent neural networks",
author = "Huang, Yujiao and Zhang, Xueyuan",
journal = "Int. J. Inf. Syst. Sci.",
volume =  7,
number =  1,
pages = "1--10",
year =  2011,
annote = "- Proves that recurrent neural networks (discrete, but essentially very much like continuous) with thresholded/rectified/ReLU units have multiple point attractor, under a certain condition on their weights!<div><br></div><div>- Thus they can serve as memory networks?...</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Raposo2014-za,
title = "A category-free neural population supports evolving demands during decision-making",
author = "Raposo, David and Kaufman, Matthew T and Churchland, Anne K",
affiliation = "1] Cold Spring Harbor Laboratory, Cold Spring Harbor, New York, USA. [2] Champalimaud Neuroscience Programme, Lisboa, Portugal. Cold Spring Harbor Laboratory, Cold Spring Harbor, New York, USA. Cold Spring Harbor Laboratory, Cold Spring Harbor, New York, USA.",
abstract = "The posterior parietal cortex (PPC) receives diverse inputs and is involved in a dizzying array of behaviors. These many behaviors could rely on distinct categories of neurons specialized to represent particular variables or could rely on a single population of PPC neurons that is leveraged in different ways. To distinguish these possibilities, we evaluated rat PPC neurons recorded during multisensory decisions. Newly designed tests revealed that task parameters and temporal response features were distributed randomly across neurons, without evidence of categories. This suggests that PPC neurons constitute a dynamic network that is decoded according to the animal's present needs. To test for an additional signature of a dynamic network, we compared moments when behavioral demands differed: decision and movement. Our new state-space analysis revealed that the network explored different dimensions during decision and movement. These observations suggest that a single network of neurons can support the evolving behavioral demands of decision-making.",
journal = "Nat. Neurosci.",
volume =  17,
number =  12,
pages = "1784--1792",
month =  dec,
year =  2014,
annote = "- Mixed, nonlinear, dynamic selectivities in Rat PPC <div><br></div><div>- Visual or auditory stimulus (or both) determines target port</div><div><br></div><div>- Some neurons selective to modality, others to choice - most to both</div><div><br></div><div>- Tunings are very dynamic, often reverting between stimulus time and movement time (though there is correlation b/w the two periods, r=.31..?)</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Brody2003-pv,
title = "Timing and neural encoding of somatosensory parametric working memory in macaque prefrontal cortex",
author = "Brody, Carlos D and Hern\'{a}ndez, Adri\'{a}n and Zainos, Antonio and Romo, Ranulfo",
affiliation = "Cold Spring Harbor Laboratory, 1 Bungtown Road, Cold Spring Harbor, NY 11724, USA.",
abstract = "We trained monkeys to compare the frequencies of two mechanical vibrations applied sequentially to the tip of a finger and to report which of the two stimuli had the higher frequency. This task requires remembering the first frequency during the delay period between the two stimuli. Recordings were made from neurons in the inferior convexity of the prefrontal cortex (PFC) while the monkeys performed the task. We report neurons that fire persistently during the delay period, with a firing rate that is a monotonic function of the frequency of the first stimulus. Separately from, and in addition to, their correlation with the first stimulus, the delay period firing rates of these neurons were correlated with the behavior of the monkey, in a manner consistent with their interpretation as the neural substrate of working memory during the task. Most neurons had firing rates that varied systematically with time during the delay period. We suggest that this time-dependent activity may encode time itself and may be an intrinsic part of active memory maintenance mechanisms.",
journal = "Cereb. Cortex",
volume =  13,
number =  11,
pages = "1196--1207",
month =  nov,
year =  2003,
annote = "- In the Romo task, many neurons change their tuning during the first delay period (as also found in the Barak paper)....<div><br></div><div>- But some remain very consistently-tuned over whole delay period ! (though their overall firing goes down then ramps back up, like the whole population)</div><div><br></div><div>- Furthermore, these 'persistent' neurons have the strongest choice probabilities ! Their firing rate predicts performance !</div><div><br></div><div>- That seems evidence that these neurons carry the actual working memory...? Barak 2010 is not convinced, for some reason (apparently because of the dip in overall firing)?.... Need to read more Barak!</div><div><br></div><div>- ALSO: Varying delay period !! </div><div>- When you extend the delay period from 3 to 6 second, the neurons ALMOST IMMEDIATELY SLOW DOWN - at least the ``late-selective neurons'' have almost perfect time-stretching! By contrast, ``early-selective'' neurons are largely unstretched/unchanged!</div>"
}

@ARTICLE{Churchland2012-hj,
title = "Neural population dynamics during reaching",
author = "Churchland, Mark M and Cunningham, John P and Kaufman, Matthew T and Foster, Justin D and Nuyujukian, Paul and Ryu, Stephen I and Shenoy, Krishna V",
affiliation = "Department of Neuroscience, Kavli Institute for Brain Science, David Mahoney Center, Columbia University Medical Center, New York, New York 10032, USA. mc3502@columbia.edu",
abstract = "Most theories of motor cortex have assumed that neural activity represents movement parameters. This view derives from what is known about primary visual cortex, where neural activity represents patterns of light. Yet it is unclear how well the analogy between motor and visual cortex holds. Single-neuron responses in motor cortex are complex, and there is marked disagreement regarding which movement parameters are represented. A better analogy might be with other motor systems, where a common principle is rhythmic neural activity. Here we find that motor cortex responses during reaching contain a brief but strong oscillatory component, something quite unexpected for a non-periodic behaviour. Oscillation amplitude and phase followed naturally from the preparatory state, suggesting a mechanistic role for preparatory neural activity. These results demonstrate an unexpected yet surprisingly simple structure in the population response. This underlying structure explains many of the confusing features of individual neural responses.",
journal = "Nature",
volume =  487,
number =  7405,
pages = "51--56",
month =  "5~" # jul,
year =  2012,
annote = "- The traces in the preparation period are extremely stable... contrasts a lot with the Romo task, in which the majority of neurons have fluctuating tuning over time during the inter-stimulus delay (as per Brody Cer Cor 2003)...."
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kaufman2014-dp,
title = "Cortical activity in the null space: permitting preparation without movement",
author = "Kaufman, Matthew T and Churchland, Mark M and Ryu, Stephen I and Shenoy, Krishna V",
affiliation = "1] Neurosciences Program, Stanford University, Stanford, California, USA. [2] Department of Electrical Engineering, Stanford University, Stanford, California, USA. [3] Cold Spring Harbor Laboratory, Cold Spring Harbor, New York, USA. 1] Department of Neuroscience, Columbia University Medical Center, New York, New York, USA. [2] Grossman Center for the Statistics of Mind, Columbia University Medical Center, New York, New York, USA. [3] David Mahoney Center for Brain and Behavior Research, Columbia University Medical Center, New York, New York, USA. [4] Kavli Institute for Brain Science, Columbia University Medical Center, New York, New York, USA. 1] Department of Electrical Engineering, Stanford University, Stanford, California, USA. [2] Department of Neurosurgery, Palo Alto Medical Foundation, Palo Alto, California, USA. 1] Neurosciences Program, Stanford University, Stanford, California, USA. [2] Department of Electrical Engineering, Stanford University, Stanford, California, USA. [3] Department of Bioengineering, Stanford University, Stanford, California, USA. [4] Department of Neurobiology, Stanford University, Stanford, California, USA.",
abstract = "Neural circuits must perform computations and then selectively output the results to other circuits. Yet synapses do not change radically at millisecond timescales. A key question then is: how is communication between neural circuits controlled? In motor control, brain areas directly involved in driving movement are active well before movement begins. Muscle activity is some readout of neural activity, yet it remains largely unchanged during preparation. Here we find that during preparation, while the monkey holds still, changes in motor cortical activity cancel out at the level of these population readouts. Motor cortex can thereby prepare the movement without prematurely causing it. Further, we found evidence that this mechanism also operates in dorsal premotor cortex, largely accounting for how preparatory activity is attenuated in primary motor cortex. Selective use of 'output-null' vs. 'output-potent' patterns of activity may thus help control communication to the muscles and between these brain areas.",
journal = "Nat. Neurosci.",
volume =  17,
number =  3,
pages = "440--448",
month =  mar,
year =  2014,
annote = "- Preparatory is strong in PMd, a bit less strong in M1, virtually absent in EMG. How?<div><br></div><div>[- The commentary by Sanger \& Kalaska suggests that it's not the  whole story - after all there is still some output-</div><div>potent activity, though this may be a result of the linear simplification...]</div><div><br></div><div>[-There really seems to be inhibition of motor responses during movement preparation! See the Greenhouse/ Ivry paper![]</div><div><br></div><div>[- Also: preparatory tuning is quite different from movement-period tuning!]<br><div><br></div><div>- One possibility: inhibitory gating? But apparently not (previous papers)</div></div><div><br></div><div>- Actually, activity in preparation time is largely in the null-space of the Motor-To-Muscle matrix - the directions in which changes don't affect the muscle output!</div><div><br></div><div>- However, motion in the null-space is very important, since it sets the 'starting point' for the 'loaded spring' that occurs due to movement.</div><div><br></div><div>- NOT caused by mere segregation of preparatory-tuned and movement-period-tuned neurons (they're not segregated)</div>"
}

@ARTICLE{Laje2013-gi,
title = "Robust timing and motor patterns by taming chaos in recurrent neural networks",
author = "Laje, Rodrigo and Buonomano, Dean V",
affiliation = "Department of Neurobiology, University of California, Los Angeles, California, USA.",
abstract = "The brain's ability to tell time and produce complex spatiotemporal motor patterns is critical for anticipating the next ring of a telephone or playing a musical instrument. One class of models proposes that these abilities emerge from dynamically changing patterns of neural activity generated in recurrent neural networks. However, the relevant dynamic regimes of recurrent networks are highly sensitive to noise; that is, chaotic. We developed a firing rate model that tells time on the order of seconds and generates complex spatiotemporal patterns in the presence of high levels of noise. This is achieved through the tuning of the recurrent connections. The network operates in a dynamic regime that exhibits coexisting chaotic and locally stable trajectories. These stable patterns function as 'dynamic attractors' and provide a feature that is characteristic of biological systems: the ability to 'return' to the pattern being generated in the face of perturbations.",
journal = "Nat. Neurosci.",
volume =  16,
number =  7,
pages = "925--933",
month =  jul,
year =  2013,
annote = "- Chaotic networks generate complex, LONG-TERM dynamics - but they're chaotic, so unpredictable<div><br></div><div>- Crucial idea: train a chaotic RNN to consistently reproduce its own trace !</div><div><br></div><div>- As a result, becomes tolerant to noise ! Can be started from many different conditions !!</div><div><br></div><div>[ - Hm, does it mean it can only do one single thing? As opposed to the Hennequin networks?]</div><div><br></div><div>- Can be used to perform cursive writing - tolerant to large perturbations! - and keep time for ~5000ms</div><div><br></div>"
}

@ARTICLE{Rajan2010-bc,
title = "Stimulus-dependent suppression of chaos in recurrent neural networks",
author = "Rajan, Kanaka and Abbott, L F and Sompolinsky, Haim",
affiliation = "Lewis-Sigler Institute for Integrative Genomics, Icahn 262, Princeton University, Princeton, New Jersey 08544, USA. krajan@princeton.edu",
abstract = "Neuronal activity arises from an interaction between ongoing firing generated spontaneously by neural circuits and responses driven by external stimuli. Using mean-field analysis, we ask how a neural network that intrinsically generates chaotic patterns of activity can remain sensitive to extrinsic input. We find that inputs not only drive network responses, but they also actively suppress ongoing activity, ultimately leading to a phase transition in which chaos is completely eliminated. The critical input intensity at the phase transition is a nonmonotonic function of stimulus frequency, revealing a ``resonant'' frequency at which the input is most effective at suppressing chaos even though the power spectrum of the spontaneous activity peaks at zero and falls exponentially. A prediction of our analysis is that the variance of neural responses should be most strongly suppressed at frequencies matching the range over which many sensory systems operate.",
journal = "Phys. Rev. E Stat. Nonlin. Soft Matter Phys.",
volume =  82,
number = "1 Pt 1",
pages = "011903",
month =  jul,
year =  2010,
annote = "- A periodic input into a chaotic RNN can suppress chaos and force oscillatory response - EVEN if it is NOT phase-locked across neurons (i.e. each neuron receives input with same frequency but different phase)<div><br></div><div>- This occurs mostly if the input frequency is ~2 the characteristic timescales of the chaotic fluctuation... ('resonant' frequency)</div><div><br></div><div>- Because nonlinear interactions between stimulus and ongoing clutuations, the ``noise'' component (what remains after you take out the common frequency?) contains info about the stimulus!</div><div><br></div>"
}

@ARTICLE{Crutchfield2011-oo,
title = "Between order and chaos",
author = "Crutchfield, James P",
abstract = "A completely ordered universe is as unexciting as an entirely disordered one. Interesting /`complex/' phenomena arise in a middle ground. This article reviews the tools that have been developed to quantify structural complexity and to automatically discover patterns hidden between order and chaos.",
journal = "Nat. Phys.",
publisher = "Nature Publishing Group",
volume =  8,
number =  1,
pages = "17--24",
month =  "22~" # dec,
year =  2011
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rubin2015-yr,
title = "The stabilized supralinear network: a unifying circuit motif underlying multi-input integration in sensory cortex",
author = "Rubin, Daniel B and Van Hooser, Stephen D and Miller, Kenneth D",
affiliation = "Center for Theoretical Neuroscience, Doctoral Program in Neurobiology and Behavior, College of Physicians and Surgeons, Columbia University, New York, NY 10032, USA. Department of Biology, Swartz Center for Theoretical Biology, Brandeis University, Waltham, MA 02454, USA. Center for Theoretical Neuroscience, Doctoral Program in Neurobiology and Behavior, College of Physicians and Surgeons, Columbia University, New York, NY 10032, USA; Department of Neuroscience, Swartz Program in Theoretical Neuroscience, Kavli Institute for Brain Science, College of Physicians and Surgeons, Columbia University, New York, NY 10032, USA. Electronic address: ken@neurotheory.columbia.edu.",
abstract = "Neurons in sensory cortex integrate multiple influences to parse objects and support perception. Across multiple cortical areas, integration is characterized by two neuronal response properties: (1) surround suppression--modulatory contextual stimuli suppress responses to driving stimuli; and (2) ``normalization''--responses to multiple driving stimuli add sublinearly. These depend on input strength: for weak driving stimuli, contextual influences facilitate or more weakly suppress and summation becomes linear or supralinear. Understanding the circuit operations underlying integration is critical to understanding cortical function and disease. We present a simple, general theory. A wealth of integrative properties, including the above, emerge robustly from four cortical circuit properties: (1) supralinear neuronal input/output functions; (2) sufficiently strong recurrent excitation; (3) feedback inhibition; and (4) simple spatial properties of intracortical connections. Integrative properties emerge dynamically as circuit properties, with excitatory and inhibitory neurons showing similar behaviors. In new recordings in visual cortex, we confirm key model predictions.",
journal = "Neuron",
volume =  85,
number =  2,
pages = "402--417",
month =  "21~" # jan,
year =  2015
}

@ARTICLE{Hennequin2014-tr,
title = "Optimal control of transient dynamics in balanced networks supports generation of complex movements",
author = "Hennequin, Guillaume and Vogels, Tim P and Gerstner, Wulfram",
affiliation = "School of Computer and Communication Sciences and Brain Mind Institute, School of Life Sciences, Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne (EPFL), 1015 Lausanne, Switzerland; Department of Engineering, University of Cambridge, Cambridge CB2 1PZ, UK. Electronic address: gjeh2@cam.ac.uk. School of Computer and Communication Sciences and Brain Mind Institute, School of Life Sciences, Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne (EPFL), 1015 Lausanne, Switzerland; Centre for Neural Circuits and Behaviour, University of Oxford, Oxford OX1 3SR, UK. School of Computer and Communication Sciences and Brain Mind Institute, School of Life Sciences, Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne (EPFL), 1015 Lausanne, Switzerland.",
abstract = "Populations of neurons in motor cortex engage in complex transient dynamics of large amplitude during the execution of limb movements. Traditional network models with stochastically assigned synapses cannot reproduce this behavior. Here we introduce a class of cortical architectures with strong and random excitatory recurrence that is stabilized by intricate, fine-tuned inhibition, optimized from a control theory perspective. Such networks transiently amplify specific activity states and can be used to reliably execute multidimensional movement patterns. Similar to the experimental observations, these transients must be preceded by a steady-state initialization phase from which the network relaxes back into the background state by way of complex internal dynamics. In our networks, excitation and inhibition are as tightly balanced as recently reported in experiments across several brain areas, suggesting inhibitory control of complex excitatory recurrence as a generic organizational principle in cortex.",
journal = "Neuron",
volume =  82,
number =  6,
pages = "1394--1406",
month =  "18~" # jun,
year =  2014
}

@TECHREPORT{Jaeger2001-ip,
title = "The ``echo state'' approach to analysing and training recurrent neural networks -- with an Erratum note1",
author = "Jaeger, Herbert",
number = "GMD 148",
institution = "German National Research Center for Information Technology",
year =  2001
}

@ARTICLE{Maass2002-wq,
title = "Real-time computing without stable states: a new framework for neural computation based on perturbations",
author = "Maass, Wolfgang and Natschl{\"{a}}ger, Thomas and Markram, Henry",
affiliation = "Institute for Theoretical Computer Science, Technische Universit{\"{a}}t Graz, A-8010 Graz, Austria. maass@igi.tu-graz.ac.at",
abstract = "A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.",
journal = "Neural Comput.",
volume =  14,
number =  11,
pages = "2531--2560",
month =  nov,
year =  2002,
annote = "- Introduces Liquid state machines<div><br></div><div>- Crucial insight: a readout neuron can learn to transform the transient, dynamic information in an RNN into a STABLE readout - because of high dimensionality!</div><div><br></div><div>- ``<span style=''word-spacing: normal; line-height: 1.5em;``>a readout neuron that receives inputs from hundreds or thousands of
neurons in a neural microcircuit can learn to extract salient information
from the high-dimensional transient states of the circuit and can transform
transient circuit states into stable readouts.''</span></div>"
}

@ARTICLE{Buonomano2009-ax,
title = "State-dependent computations: spatiotemporal processing in cortical networks",
author = "Buonomano, Dean V and Maass, Wolfgang",
affiliation = "Department of Neurobiology, Brain Research Institute, University of California, Los Angeles, California 90095, USA. dbuono@ucla.edu",
abstract = "A conspicuous ability of the brain is to seamlessly assimilate and process spatial and temporal features of sensory stimuli. This ability is indispensable for the recognition of natural stimuli. Yet, a general computational framework for processing spatiotemporal stimuli remains elusive. Recent theoretical and experimental work suggests that spatiotemporal processing emerges from the interaction between incoming stimuli and the internal dynamic state of neural networks, including not only their ongoing spiking activity but also their 'hidden' neuronal states, such as short-term synaptic plasticity.",
journal = "Nat. Rev. Neurosci.",
volume =  10,
number =  2,
pages = "113--125",
month =  feb,
year =  2009
}

@ARTICLE{Pearlmutter1995-qt,
title = "Gradient calculations for dynamic recurrent neural networks: a survey",
author = "Pearlmutter, B A",
affiliation = "Learning Syst. Dept., Siemens Corp. Res. Inc., Princeton, NJ.",
abstract = "Surveys learning algorithms for recurrent neural networks with hidden units and puts the various techniques into a common framework. The authors discuss fixed point learning algorithms, namely recurrent backpropagation and deterministic Boltzmann machines, and nonfixed point algorithms, namely backpropagation through time, Elman's history cutoff, and Jordan's output feedback architecture. Forward propagation, an on-line technique that uses adjoint equations, and variations thereof, are also discussed. In many cases, the unified presentation leads to generalizations of various sorts. The author discusses advantages and disadvantages of temporally continuous neural networks in contrast to clocked ones continues with some ``tricks of the trade'' for training, using, and simulating continuous time and recurrent neural networks. The author presents some simulations, and at the end, addresses issues of computational complexity and learning speed.",
journal = "IEEE Trans. Neural Netw.",
volume =  6,
number =  5,
pages = "1212--1228",
year =  1995
}

@ARTICLE{Florian2007-yn,
title = "Reinforcement learning through modulation of spike-timing-dependent synaptic plasticity",
author = "Florian, R\u{a}zvan V",
affiliation = "Center for Cognitive and Neural Studies (Coneural), 400504 Cluj-Napoca, Romania. florian@coneural.org",
abstract = "The persistent modification of synaptic efficacy as a function of the relative timing of pre- and postsynaptic spikes is a phenomenon known as spike-timing-dependent plasticity (STDP). Here we show that the modulation of STDP by a global reward signal leads to reinforcement learning. We first derive analytically learning rules involving reward-modulated spike-timing-dependent synaptic and intrinsic plasticity, by applying a reinforcement learning algorithm to the stochastic spike response model of spiking neurons. These rules have several features common to plasticity mechanisms experimentally found in the brain. We then demonstrate in simulations of networks of integrate-and-fire neurons the efficacy of two simple learning rules involving modulated STDP. One rule is a direct extension of the standard STDP model (modulated STDP), and the other one involves an eligibility trace stored at each synapse that keeps a decaying memory of the relationships between the recent pairs of pre- and postsynaptic spike pairs (modulated STDP with eligibility trace). This latter rule permits learning even if the reward signal is delayed. The proposed rules are able to solve the XOR problem with both rate coded and temporally coded input and to learn a target output firing-rate pattern. These learning rules are biologically plausible, may be used for training generic artificial spiking neural networks, regardless of the neural model used, and suggest the experimental investigation in animals of the existence of reward-modulated STDP.",
journal = "Neural Comput.",
volume =  19,
number =  6,
pages = "1468--1502",
month =  jun,
year =  2007
}

@ARTICLE{Churchland2012-ez,
title = "Neural population dynamics during reaching",
author = "Churchland, Mark M and Cunningham, John P and Kaufman, Matthew T and Foster, Justin D and Nuyujukian, Paul and Ryu, Stephen I and Shenoy, Krishna V",
affiliation = "Department of Neuroscience, Kavli Institute for Brain Science, David Mahoney Center, Columbia University Medical Center, New York, New York 10032, USA. mc3502@columbia.edu",
abstract = "Most theories of motor cortex have assumed that neural activity represents movement parameters. This view derives from what is known about primary visual cortex, where neural activity represents patterns of light. Yet it is unclear how well the analogy between motor and visual cortex holds. Single-neuron responses in motor cortex are complex, and there is marked disagreement regarding which movement parameters are represented. A better analogy might be with other motor systems, where a common principle is rhythmic neural activity. Here we find that motor cortex responses during reaching contain a brief but strong oscillatory component, something quite unexpected for a non-periodic behaviour. Oscillation amplitude and phase followed naturally from the preparatory state, suggesting a mechanistic role for preparatory neural activity. These results demonstrate an unexpected yet surprisingly simple structure in the population response. This underlying structure explains many of the confusing features of individual neural responses.",
journal = "Nature",
volume =  487,
number =  7405,
pages = "51--56",
month =  "5~" # jul,
year =  2012
}

@ARTICLE{Izhikevich2007-xu,
title = "Solving the distal reward problem through linkage of {STDP} and dopamine signaling",
author = "Izhikevich, Eugene M",
affiliation = "The Neurosciences Institute, 10640 John Jay Hopkins Drive, San Diego, CA 92121, USA. Eugene.Izhikevich@nsi.edu",
abstract = "In Pavlovian and instrumental conditioning, reward typically comes seconds after reward-triggering actions, creating an explanatory conundrum known as ``distal reward problem'': How does the brain know what firing patterns of what neurons are responsible for the reward if 1) the patterns are no longer there when the reward arrives and 2) all neurons and synapses are active during the waiting period to the reward? Here, we show how the conundrum is resolved by a model network of cortical spiking neurons with spike-timing-dependent plasticity (STDP) modulated by dopamine (DA). Although STDP is triggered by nearly coincident firing patterns on a millisecond timescale, slow kinetics of subsequent synaptic plasticity is sensitive to changes in the extracellular DA concentration during the critical period of a few seconds. Random firings during the waiting period to the reward do not affect STDP and hence make the network insensitive to the ongoing activity-the key feature that distinguishes our approach from previous theoretical studies, which implicitly assume that the network be quiet during the waiting period or that the patterns be preserved until the reward arrives. This study emphasizes the importance of precise firing patterns in brain dynamics and suggests how a global diffusive reinforcement signal in the form of extracellular DA can selectively influence the right synapses at the right time.",
journal = "Cereb. Cortex",
volume =  17,
number =  10,
pages = "2443--2452",
month =  oct,
year =  2007,
annote = "eligi"
}

@ARTICLE{Fremaux2010-qf,
title = "Functional requirements for reward-modulated spike-timing-dependent plasticity",
author = "Fr\'{e}maux, Nicolas and Sprekeler, Henning and Gerstner, Wulfram",
affiliation = "School of Computer and Communication Sciences and Brain-Mind Institute, Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne, CH-1015 Lausanne, Switzerland. nicolas.fremaux@epfl.ch",
abstract = "Recent experiments have shown that spike-timing-dependent plasticity is influenced by neuromodulation. We derive theoretical conditions for successful learning of reward-related behavior for a large class of learning rules where Hebbian synaptic plasticity is conditioned on a global modulatory factor signaling reward. We show that all learning rules in this class can be separated into a term that captures the covariance of neuronal firing and reward and a second term that presents the influence of unsupervised learning. The unsupervised term, which is, in general, detrimental for reward-based learning, can be suppressed if the neuromodulatory signal encodes the difference between the reward and the expected reward-but only if the expected reward is calculated for each task and stimulus separately. If several tasks are to be learned simultaneously, the nervous system needs an internal critic that is able to predict the expected reward for arbitrary stimuli. We show that, with a critic, reward-modulated spike-timing-dependent plasticity is capable of learning motor trajectories with a temporal resolution of tens of milliseconds. The relation to temporal difference learning, the relevance of block-based learning paradigms, and the limitations of learning with a critic are discussed.",
journal = "J. Neurosci.",
volume =  30,
number =  40,
pages = "13326--13337",
month =  "6~" # oct,
year =  2010
}

@ARTICLE{Hoerzer2014-zd,
title = "Emergence of complex computational structures from chaotic neural networks through reward-modulated Hebbian learning",
author = "Hoerzer, Gregor M and Legenstein, Robert and Maass, Wolfgang",
affiliation = "Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria.",
abstract = "This paper addresses the question how generic microcircuits of neurons in different parts of the cortex can attain and maintain different computational specializations. We show that if stochastic variations in the dynamics of local microcircuits are correlated with signals related to functional improvements of the brain (e.g. in the control of behavior), the computational operation of these microcircuits can become optimized for specific tasks such as the generation of specific periodic signals and task-dependent routing of information. Furthermore, we show that working memory can autonomously emerge through reward-modulated Hebbian learning, if needed for specific tasks. Altogether, our results suggest that reward-modulated synaptic plasticity can not only optimize the network parameters for specific computational tasks, but also initiate a functional rewiring that re-programs microcircuits, thereby generating diverse computational functions in different generic cortical microcircuits. On a more general level, this work provides a new perspective for a standard model for computations in generic cortical microcircuits (liquid computing model). It shows that the arguably most problematic assumption of this model, the postulate of a teacher that trains neural readouts through supervised learning, can be eliminated. We show that generic networks of neurons can learn numerous biologically relevant computations through trial and error.",
journal = "Cereb. Cortex",
volume =  24,
number =  3,
pages = "677--690",
month =  mar,
year =  2014,
keywords = "cortical microcircuit model; cortical plasticity; pattern generation; working memory"
}

@ARTICLE{Lammel2012-ds,
title = "Input-specific control of reward and aversion in the ventral tegmental area",
author = "Lammel, Stephan and Lim, Byung Kook and Ran, Chen and Huang, Kee Wui and Betley, Michael J and Tye, Kay M and Deisseroth, Karl and Malenka, Robert C",
affiliation = "Nancy Pritzker Laboratory, Department of Psychiatry and Behavioral Sciences, Stanford University School of Medicine, 265 Campus Drive, Stanford, California 94305, USA.",
abstract = "Ventral tegmental area (VTA) dopamine neurons have important roles in adaptive and pathological brain functions related to reward and motivation. However, it is unknown whether subpopulations of VTA dopamine neurons participate in distinct circuits that encode different motivational signatures, and whether inputs to the VTA differentially modulate such circuits. Here we show that, because of differences in synaptic connectivity, activation of inputs to the VTA from the laterodorsal tegmentum and the lateral habenula elicit reward and aversion in mice, respectively. Laterodorsal tegmentum neurons preferentially synapse on dopamine neurons projecting to the nucleus accumbens lateral shell, whereas lateral habenula neurons synapse primarily on dopamine neurons projecting to the medial prefrontal cortex as well as on GABAergic ($\gamma$-aminobutyric-acid-containing) neurons in the rostromedial tegmental nucleus. These results establish that distinct VTA circuits generate reward and aversion, and thereby provide a new framework for understanding the circuit basis of adaptive and pathological motivated behaviours.",
journal = "Nature",
volume =  491,
number =  7423,
pages = "212--217",
month =  "8~" # nov,
year =  2012,
annote = "pl"
}

@ARTICLE{Barak2010-mw,
title = "Neuronal population coding of parametric working memory",
author = "Barak, Omri and Tsodyks, Misha and Romo, Ranulfo",
affiliation = "Department of Neurobiology, Weizmann Institute of Science, Rehovot, Israel.",
abstract = "Comparing two sequentially presented stimuli is a widely used experimental paradigm for studying working memory. The delay activity of many single neurons in the prefrontal cortex (PFC) of monkeys was found to be stimulus-specific, however, population dynamics of stimulus representation has not been elucidated. We analyzed the population state of a large number of PFC neurons during a somatosensory discrimination task. Using the tuning curves of the neurons, we derived a compact characterization of the population state. Stimulus representation by the population was found to degrade after stimulus termination, and emerge in a different form toward the end of the delay. Specifically, the tuning properties of neurons were found to change during the task. We suggest a mechanism whereby information about the stimulus is contained in activity-dependent synaptic facilitation of recurrent connections.",
journal = "J. Neurosci.",
volume =  30,
number =  28,
pages = "9424--9430",
month =  "14~" # jul,
year =  2010,
annote = "- Population coding of stimulus value in working memory is highly dynamic.<div><br></div><div>- Initial stimulus presentation: all values lead to same state</div><div>- Late stimulus presentation: strong divergence of different values (``sensory'' representation)</div><div>- Middle delay period: low differentiation between values</div><div>- Late delay (till just before 2nd stimulus): gradual increase in differentiation of different values!</div><div><br></div><div>- Is it just an increase in firing rates of tuned neurons ? NO! Remapping of activity b/w Sensory and Delay periods.</div><div><br></div><div>- For any stimulus value, cross-correlation with stimulus state decays quickly (though slightly increases over time!) while cross-corr. with late-delay state increases strongly over time (though also non-trivial corss-corr with it during stim. pres!)</div><div><br></div><div>- Thus two (coexisting!) representations, a ``sensory'' one and a ``memory'' one.</div><div><br></div><div>- Suggests a model based on synaptic facilitation? Not sure why...</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Barak2013-hg,
title = "From fixed points to chaos: three models of delayed discrimination",
author = "Barak, Omri and Sussillo, David and Romo, Ranulfo and Tsodyks, Misha and Abbott, L F",
affiliation = "Center for Theoretical Neuroscience, Columbia University, New York, NY 10032, USA. omri.barak@gmail.com",
abstract = "Working memory is a crucial component of most cognitive tasks. Its neuronal mechanisms are still unclear despite intensive experimental and theoretical explorations. Most theoretical models of working memory assume both time-invariant neural representations and precise connectivity schemes based on the tuning properties of network neurons. A different, more recent class of models assumes randomly connected neurons that have no tuning to any particular task, and bases task performance purely on adjustment of network readout. Intermediate between these schemes are networks that start out random but are trained by a learning scheme. Experimental studies of a delayed vibrotactile discrimination task indicate that some of the neurons in prefrontal cortex are persistently tuned to the frequency of a remembered stimulus, but the majority exhibit more complex relationships to the stimulus that vary considerably across time. We compare three models, ranging from a highly organized line attractor model to a randomly connected network with chaotic activity, with data recorded during this task. The random network does a surprisingly good job of both performing the task and matching certain aspects of the data. The intermediate model, in which an initially random network is partially trained to perform the working memory task by tuning its recurrent and readout connections, provides a better description, although none of the models matches all features of the data. Our results suggest that prefrontal networks may begin in a random state relative to the task and initially rely on modified readout for task performance. With further training, however, more tuned neurons with less time-varying responses should emerge as the networks become more structured.",
journal = "Prog. Neurobiol.",
volume =  103,
pages = "214--222",
month =  apr,
year =  2013,
annote = "- Uses three types of networks to solve the Romo task (which of two successive tactiale stimuli has higher frequency)<div><br></div><div>- Model 1: 2 populations, each tuned to be a linear attrator, with mutual inhibition / subtraction (Machens 2005)</div><div>- Model 2: Chaotic RN, only readout is trained.</div><div>- Model 3: RNN + readout both trained with hessian-free optimization</div><div><br></div><div>- Line-Attractor selectivities are way too stable. Chaotic RN ones are way too variable. Trained-RNN seems pretty similar to data!</div><div><br></div><div>- Using the kind of modified-PCA of Machens 2010, you can extract a semi-constant signal for the frequency of the 1st stimulus throughout the delay period - even for the Chaotic RN !! So the presence of this component does not imply stability in coding...</div><div><br></div><div>- Note that both the Chaotic and Trained RNs start from random initialization! </div><div><br></div><div>- One aspect of data missed by all models: the gradual increase in \# of tuned neurons over the delay period (accompanied by a remapping in the population, see Barak et al. J Neurosci 2010) </div>"
}

@ARTICLE{Rigotti2013-ut,
title = "The importance of mixed selectivity in complex cognitive tasks",
author = "Rigotti, Mattia and Barak, Omri and Warden, Melissa R and Wang, Xiao-Jing and Daw, Nathaniel D and Miller, Earl K and Fusi, Stefano",
affiliation = "Center for Theoretical Neuroscience, Columbia University College of Physicians and Surgeons, New York, New York 10032, USA.",
abstract = "Single-neuron activity in the prefrontal cortex (PFC) is tuned to mixtures of multiple task-related aspects. Such mixed selectivity is highly heterogeneous, seemingly disordered and therefore difficult to interpret. We analysed the neural activity recorded in monkeys during an object sequence memory task to identify a role of mixed selectivity in subserving the cognitive functions ascribed to the PFC. We show that mixed selectivity neurons encode distributed information about all task-relevant aspects. Each aspect can be decoded from the population of neurons even when single-cell selectivity to that aspect is eliminated. Moreover, mixed selectivity offers a significant computational advantage over specialized responses in terms of the repertoire of input-output functions implementable by readout neurons. This advantage originates from the highly diverse nonlinear selectivity to mixtures of task-relevant variables, a signature of high-dimensional neural representations. Crucially, this dimensionality is predictive of animal behaviour as it collapses in error trials. Our findings recommend a shift of focus for future studies from neurons that have easily interpretable response tuning to the widely observed, but rarely analysed, mixed selectivity neurons.",
journal = "Nature",
volume =  497,
number =  7451,
pages = "585--590",
month =  "30~" # may,
year =  2013,
annote = "- Many neurons in dlPFC have non0linear mixed selectivities to various aspects of a complex task.<div><br></div><div>- As a result, y<span style=``word-spacing: normal; line-height: 1.5em;''>ou can decode all task variables (task type, 1st stimulus, 2nd stimulus...) from a population activity - even if you ensure that no neuron is selective to that particular task variable in isolation!</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- To do this, you add noise to neuron responses, such that for each neuron, average response to either condition (over all sub-conditions) is the same (so no selectivity for this condition in any neuron), but preserving the intra-condition differences between sub-conditions.</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Still excellent accurracy.</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- The population responses to all possible conditions in the delay period live in a high-dimensional space.</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- Dimensionality is evaluated by the (log of) number of binary classifications possible within these responses!</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''>- In error trials, dimensionality collapses!</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div>"
}

@ARTICLE{Sussillo2015-oi,
title = "A neural network that finds a naturalistic solution for the production of muscle activity",
author = "Sussillo, David and Churchland, Mark M and Kaufman, Matthew T and Shenoy, Krishna V",
affiliation = "Department of Electrical Engineering and Neurosciences Program, Stanford University, Stanford, California, USA. Department of Neuroscience, Grossman Center for the Statistics of Mind, David Mahoney Center for Brain and Behavior Research, Kavli Institute for Brain Science, Columbia University Medical Center, New York, New York, USA. Department of Electrical Engineering and Neurosciences Program, Stanford University, Stanford, California, USA. 1] Department of Electrical Engineering and Neurosciences Program, Stanford University, Stanford, California, USA. [2] Departments of Bioengineering and Neurobiology, Stanford Neurosciences Institute and Bio-X Program, Stanford University, Stanford, California, USA.",
abstract = "It remains an open question how neural responses in motor cortex relate to movement. We explored the hypothesis that motor cortex reflects dynamics appropriate for generating temporally patterned outgoing commands. To formalize this hypothesis, we trained recurrent neural networks to reproduce the muscle activity of reaching monkeys. Models had to infer dynamics that could transform simple inputs into temporally and spatially complex patterns of muscle activity. Analysis of trained models revealed that the natural dynamical solution was a low-dimensional oscillator that generated the necessary multiphasic commands. This solution closely resembled, at both the single-neuron and population levels, what was observed in neural recordings from the same monkeys. Notably, data and simulations agreed only when models were optimized to find simple solutions. An appealing interpretation is that the empirically observed dynamics of motor cortex may reflect a simple solution to the problem of generating temporally patterned descending commands.",
journal = "Nat. Neurosci.",
volume =  18,
number =  7,
pages = "1025--1033",
month =  jul,
year =  2015
}

@ARTICLE{Stokes2013-ib,
title = "Dynamic coding for cognitive control in prefrontal cortex",
author = "Stokes, Mark G and Kusunoki, Makoto and Sigala, Natasha and Nili, Hamed and Gaffan, David and Duncan, John",
affiliation = "Oxford Centre for Human Brain Activity, University of Oxford, Oxford OX3 7JX, UK. mark.stokes@ohba.ox.ac.uk",
abstract = "Cognitive flexibility is fundamental to adaptive intelligent behavior. Prefrontal cortex has long been associated with flexible cognitive function, but the neurophysiological principles that enable prefrontal cells to adapt their response properties according to context-dependent rules remain poorly understood. Here, we use time-resolved population-level neural pattern analyses to explore how context is encoded and maintained in primate prefrontal cortex and used in flexible decision making. We show that an instruction cue triggers a rapid series of state transitions before settling into a stable low-activity state. The postcue state is differentially tuned according to the current task-relevant rule. During decision making, the response to a choice stimulus is characterized by an initial stimulus-specific population response but evolves to different final decision-related states depending on the current rule. These results demonstrate how neural tuning profiles in prefrontal cortex adapt to accommodate changes in behavioral context. Highly flexible tuning could be mediated via short-term synaptic plasticity.",
journal = "Neuron",
volume =  78,
number =  2,
pages = "364--375",
month =  "24~" # apr,
year =  2013,
annote = "- During working memory of a cue-target association task, PFC does NOT simply preserve cue identity in a neuron-stable manner<div><br></div><div>- Coding is highly dynamic, training on cue presentation fails to decode cue identity during either delay or target presentation (even though train-test at same time period still decodes cue ID very well in both!)</div><div><br></div><div>- During target presentation, PFC pop. response shifts from initial stimulus-dependent responses to appropriate tgt-vs-distractor response, in a way that is partially independent from stimulus identity ! (you can decode targetness from training on other stimuli!)</div><div><br></div><div>[ So PFC learns to ``route'' different initial stimuli inputs to the adequate target/distractor population response, with flexible routing according to the cue/task!]</div><div><br></div><div>[ Could this be learned through reward-modulated Hebbian learning? The network might progressively separate the final response patterns...]</div>"
}

@ARTICLE{Sreenivasan2014-rs,
title = "Revisiting the role of persistent neural activity during working memory",
author = "Sreenivasan, Kartik K and Curtis, Clayton E and D'Esposito, Mark",
affiliation = "Division of Science and Mathematics, New York University Abu Dhabi, 19 Washington Square North, New York, NY 10011, USA. Electronic address: kartik.sreenivasan@nyu.edu. Department of Psychology, and Center for Neural Science, New York University, 6 Washington Place, New York, NY 10003, USA. Helen Wills Neuroscience Institute, and Department of Psychology, University of California, Berkeley, 132 Barker Hall, Berkeley, CA 94720, USA.",
abstract = "What are the neural mechanisms underlying working memory (WM)? One influential theory posits that neurons in the lateral prefrontal cortex (lPFC) store WM information via persistent activity. In this review, we critically evaluate recent findings that together indicate that this model of WM needs revision. We argue that sensory cortex, not the lPFC, maintains high-fidelity representations of WM content. By contrast, the lPFC simultaneously maintains representations of multiple goal-related variables that serve to bias stimulus-specific activity in sensory regions. This work highlights multiple neural mechanisms supporting WM, including temporally dynamic population coding in addition to persistent activity. These new insights focus the question on understanding how the mechanisms that underlie WM are related, interact, and are coordinated in the lPFC and sensory cortex.",
journal = "Trends Cogn. Sci.",
volume =  18,
number =  2,
pages = "82--89",
month =  feb,
year =  2014,
keywords = "MVPA; decoding; fMRI; forward encoding; prefrontal cortex; top down; working memory"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Stokes2015-zb,
title = "‘Activity-silent’ working memory in prefrontal cortex: a dynamic coding framework",
author = "Stokes, Mark G",
journal = "Trends Cogn. Sci.",
publisher = "Elsevier",
volume =  19,
number =  7,
pages = "394--405",
month =  "7~" # jan,
year =  2015,
annote = "- Claims that Working Memory in PFC is sometimes ``silent'', with no (specific) delay activity<div><br></div><div>- Suggests that WM is better explained by short-term synaptic plasticity, which makes the network respond differently to different outputs</div><div><br></div><div>- Not really convincing? First example is that FEF loses delay trace of a remembered location when asked to attend another one - duh! What if the remembered location is stored in another prefrontal cortex?</div><div><br></div><div>- Points out dynamicity of representations in PFC during delay - but fully compatible with dynamical system based on mutual neuronal interactions...</div><div><br></div><div>- Shows that WM can contain multiple items, with only the ``attended'' item represented in brain imaging. Also, EEG signature of WM is initially high but goes lower over trials. Claims that both suggest STSP within PFC, but might also result from involvement of Hippocampus! Could HM do these tasks?...</div><div><br></div><div><br></div>"
}

@ARTICLE{Kiani2015-in,
title = "Natural grouping of neural responses reveals spatially segregated clusters in prearcuate cortex",
author = "Kiani, Roozbeh and Cueva, Christopher J and Reppas, John B and Peixoto, Diogo and Ryu, Stephen I and Newsome, William T",
affiliation = "Department of Neurobiology and Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA; Center for Neural Science, New York University, New York, NY 10003, USA. Electronic address: roozbeh@nyu.edu. Department of Neurobiology and Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA. Department of Neurobiology and Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA. Department of Neurobiology and Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA; Champalimaud Neuroscience Programme, Champalimaud Centre for the Unknown, 1400-038 Lisbon, Portugal. Department of Neurosurgery, Palo Alto Medical Foundation, Palo Alto, CA 94301, USA. Department of Neurobiology and Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA.",
abstract = "A fundamental challenge in studying the frontal lobe is to parcellate this cortex into ``natural'' functional modules despite the absence of topographic maps, which are so helpful in primary sensory areas. Here we show that unsupervised clustering algorithms, applied to 96-channel array recordings from prearcuate gyrus, reveal spatially segregated subnetworks that remain stable across behavioral contexts. Looking for natural groupings of neurons based on response similarities, we discovered that the recorded area includes at least two spatially segregated subnetworks that differentially represent behavioral choice and reaction time. Importantly, these subnetworks are detectable during different behavioral states and, surprisingly, are defined better by ``common noise'' than task-evoked responses. Our parcellation process works well on ``spontaneous'' neural activity, and thus bears strong resemblance to the identification of ``resting-state'' networks in fMRI data sets. Our results demonstrate a powerful new tool for identifying cortical subnetworks by objective classification of simultaneously recorded electrophysiological activity.",
journal = "Neuron",
volume =  85,
number =  6,
pages = "1359--1373",
month =  "18~" # mar,
year =  2015,
annote = "- At the scale of an Utah array, you can identify clusters of correlated cells, which correspond to spatial positions<div><br></div><div>- The similarity between cells is stable across many conditions / tasks and is primarily supported by ``noise fluctuations'' (subtraction from the mean for a given condition)</div><div><br></div><div>- the clustering is pretty weak... seems to be mostly ``nearby cells are more correlated''!</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Priebe2004-xs,
title = "The contribution of spike threshold to the dichotomy of cortical simple and complex cells",
author = "Priebe, Nicholas J and Mechler, Ferenc and Carandini, Matteo and Ferster, David",
affiliation = "Department of Neurobiology and Physiology, Northwestern University, 2205 Tech Drive, Evanston, Illinois 60208, USA.",
abstract = "The existence of two classes of cells, simple and complex, discovered by Hubel and Wiesel in 1962, is one of the fundamental features of cat primary visual cortex. A quantitative measure used to distinguish simple and complex cells is the ratio between modulated and unmodulated components of spike responses to drifting gratings, an index that forms a bimodal distribution. We have found that the modulation ratio, when derived from the subthreshold membrane potential instead of from spike rate, is unimodally distributed, but highly skewed. The distribution of the modulation ratio as derived from spike rate can, in turn, be predicted quantitatively by the nonlinear properties of spike threshold applied to the skewed distribution of the subthreshold modulation ratio. Threshold also increases the spatial segregation of ON and OFF regions of the receptive field, a defining attribute of simple cells. The distinction between simple and complex cells is therefore enhanced by threshold, much like the selectivity for stimulus features such as orientation and direction. In this case, however, a continuous distribution in the spatial organization of synaptic inputs is transformed into two distinct classes of cells.",
journal = "Nat. Neurosci.",
volume =  7,
number =  10,
pages = "1113--1122",
month =  oct,
year =  2004,
annote = "- While F1/F0 of spiking is bimodal (corresponding to simple and complex cells), the V1/V0 (based on membrane potential) is actually unimodal! <div><br></div><div>- Simple cells have higher V1/V0 overall, but the distribution strongly overlap.</div><div><br></div><div>- The bimodal, dichotomous F1/F0 in spiking arises because the spiking threshold nonlinearity generates a very non-inear mapping between V1/V0 and F1/F0 (spiking ``simplifies'' faster than potential!)</div><div><br></div><div>- Basically confirm Mechler and Ringach Vis Res 2002</div>"
}

@ARTICLE{Mechler2002-bc,
title = "On the classification of simple and complex cells",
author = "Mechler, Ferenc and Ringach, Dario L",
affiliation = "Department of Neurology and Neuroscience, Weill Medical College of Cornell University, 10021, New York, NY 10021, USA.",
abstract = "In their pioneering studies of primary visual cortex, Hubel and Wiesel described the existence of two classes of cells, which they termed ``simple'' and ``complex''. The original classification scheme was based on a number of partly subjective tests of linear spatial summation. Later, investigators adopted an objective classification method based on the ratio between the amplitude of the first harmonic of the response and the mean spike rate (or the F(1)/F(0) ratio) when the neuron is stimulated with drifting sinusoidal gratings. This measure is bimodally distributed over the population and divides neurons into two classes that correspond closely to the classical definition by Hubel and Wiesel. Here we show that a simple rectification model can predict the observed bimodal distribution of F(1)/F(0) in primary visual cortex when the distributions of the intracellular response modulation and mean are unimodal. Thus, contrary to common belief, the bimodality of F(1)/F(0) does not necessarily imply the existence of two discrete cell classes. Furthermore, in reviewing the literature, we find no independent support for a simple/complex dichotomy. These results suggest that the existence of two distinct neural populations in primary visual cortex, and the associated hierarchical model of receptive field organization, need to be re-evaluated.",
journal = "Vision Res.",
volume =  42,
number =  8,
pages = "1017--1033",
month =  apr,
year =  2002,
annote = "- Even though F1/F0 classification of complex/simple cells is bimodal, this does NOT mean that the underlying circuitry/subthreshold modulation is bimodal!<div><br></div><div>- Unimodal distribution of membrane threshold fluctuation may result into strong bimodal F1/F0 in the firing rate, due to threshold !</div><div><br></div><div>- See also attached commentary by Chance and Abbott, who show that continuous distribution of lateral connectivity results in strongly bimodal distriution of F1/F0 !<br><div><br></div></div><div>- MUST see the Priebe-Carandini-Ferster Nat Neurosci 2004 paper</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kawai2015-ki,
title = "Motor cortex is required for learning but not for executing a motor skill",
author = "Kawai, Risa and Markman, Timothy and Poddar, Rajesh and Ko, Raymond and Fantana, Antoniu L and Dhawale, Ashesh K and Kampff, Adam R and {\"{O}}lveczky, Bence P",
affiliation = "Center for Brain Science, Harvard University, Cambridge, MA 02138, USA; Program in Biophysics, Harvard University, Cambridge, MA 02138, USA. Center for Brain Science, Harvard University, Cambridge, MA 02138, USA. Center for Brain Science, Harvard University, Cambridge, MA 02138, USA; Program in Neuroscience, Harvard University, Cambridge, MA 02138, USA. Center for Brain Science, Harvard University, Cambridge, MA 02138, USA; Department of Organismic and Evolutionary Biology, Harvard University, Cambridge, MA 02138, USA. Center for Brain Science, Harvard University, Cambridge, MA 02138, USA; Department of Organismic and Evolutionary Biology, Harvard University, Cambridge, MA 02138, USA. Center for Brain Science, Harvard University, Cambridge, MA 02138, USA; Department of Organismic and Evolutionary Biology, Harvard University, Cambridge, MA 02138, USA. Center for Brain Science, Harvard University, Cambridge, MA 02138, USA. Center for Brain Science, Harvard University, Cambridge, MA 02138, USA; Department of Organismic and Evolutionary Biology, Harvard University, Cambridge, MA 02138, USA. Electronic address: olveczky@fas.harvard.edu.",
abstract = "Motor cortex is widely believed to underlie the acquisition and execution of motor skills, but its contributions to these processes are not fully understood. One reason is that studies on motor skills often conflate motor cortex's established role in dexterous control with roles in learning and producing task-specific motor sequences. To dissociate these aspects, we developed a motor task for rats that trains spatiotemporally precise movement patterns without requirements for dexterity. Remarkably, motor cortex lesions had no discernible effect on the acquired skills, which were expressed in their distinct pre-lesion forms on the very first day of post-lesion training. Motor cortex lesions prior to training, however, rendered rats unable to acquire the stereotyped motor sequences required for the task. These results suggest a remarkable capacity of subcortical motor circuits to execute learned skills and a previously unappreciated role for motor cortex in ``tutoring'' these circuits during learning.",
journal = "Neuron",
volume =  86,
number =  3,
pages = "800--812",
month =  "6~" # may,
year =  2015,
annote = "- Motor CTX is required for fine, dextrous movement, but not necessarily for the performance of  relatively complex action sequences (if these individual actions require no fine skill)!<div><br></div><div>- Motor ctx still required during the learning though - seems to be ``tutoring'' the sub-cortical system until it can do it by itself, presumably through motor ctx - subcortical connections.</div><div><br></div><div>- Target task (rats): two lever presses with a long-ish delay (700 ms). Takes a lot of time to learn, several weeks! </div><div>- Rats' strategies are to perform complex sequence of movements, several of which don;t involve the lever... perhaps as a way to ``mark'' time? Or simply fortuitously ``learned'' through reinforcement?</div><div>- Rat's strategies (as assessed by paw trajectory) become very reliable for individuals with learning, but quite distinct between individuals.</div><div><br></div><div>-After motor CTX lesion, 10 days recovery: they perform the task just in the same way as they did before the lesion!</div><div><br></div><div>- If lesion of motor CTX before learning, rats become very bad at learning the task!! Can't reach criterion of performance (mean delay within 10\% of target, CV<.25), despite training 3x as long!</div><div><br></div><div>- Also: fail to learn to avoid pressing for 1.2s  after unrewarded trials, which unlesioned animals can do (and can still do if lesion occurs after learning)!!</div><div><br></div><div>- So pre-learning lesion: ``<span style=''word-spacing: normal; line-height: 1.5em;``>great difficulty reliably executing longer IPIs (Figures
7B and 7C), persevered with unrewarded motor patterns, and
were incapable of withholding lever-pressing after unrewarded
IPIs'', suggesting that motor CTX does some tutoring / inhibition of innate tendencies...</span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''><br></span></div><div><span style=``word-spacing: normal; line-height: 1.5em;''> - Also compatible with role of motor CTX in ``adaptive shaping of motor variability'', which would then be learned by other...</span></div>"
}

@ARTICLE{Lee2009-ux,
title = "A normalization model of attentional modulation of single unit responses",
author = "Lee, Joonyeol and Maunsell, John H R",
affiliation = "Department of Neuroscience, Baylor College of Medicine, Houston, Texas, United States of America.",
abstract = "Although many studies have shown that attention to a stimulus can enhance the responses of individual cortical sensory neurons, little is known about how attention accomplishes this change in response. Here, we propose that attention-based changes in neuronal responses depend on the same response normalization mechanism that adjusts sensory responses whenever multiple stimuli are present. We have implemented a model of attention that assumes that attention works only through this normalization mechanism, and show that it can replicate key effects of attention. The model successfully explains how attention changes the gain of responses to individual stimuli and also why modulation by attention is more robust and not a simple gain change when multiple stimuli are present inside a neuron's receptive field. Additionally, the model accounts well for physiological data that measure separately attentional modulation and sensory normalization of the responses of individual neurons in area MT in visual cortex. The proposal that attention works through a normalization mechanism sheds new light a broad range of observations on how attention alters the representation of sensory information in cerebral cortex.",
journal = "PLoS One",
volume =  4,
number =  2,
pages = "e4651",
month =  "27~" # feb,
year =  2009
}

@ARTICLE{Ghose2009-os,
title = "Attentional modulation of visual responses by flexible input gain",
author = "Ghose, Geoffrey M",
affiliation = "Dept. of Neuroscience and Center for Magnetic Resonance Research, University of Minnesota, 2021 6th St. SE, Minneapolis, MN 55345, USA. geoff@cmrr.umn.edu",
abstract = "Although it is clear that sensory responses in the cortex can be strongly modulated by stimuli outside of classical receptive fields as well as by extraretinal signals such as attention and anticipation, the exact rules governing the neuronal integration of sensory and behavioral signals remain unclear. For example, most experiments studying sensory interactions have not explored attention, while most studies of attention have relied on the responses to relatively limited sets of stimuli. However, a recent study of V4 responses, in which location, orientation, and spatial attention were systematically varied, suggests that attention can both facilitate and suppress specific sensory inputs to a neuron according to behavioral relevance. To explore the implications of such input gain, we modeled the effects of a center-surround organization of attentional modulation using existing receptive field models of sensory integration. The model is consistent with behavioral measurements of a suppressive effect that surrounds the facilitatory locus of spatial attention. When this center-surround modulation is incorporated into realistic models of sensory integration, it is able to explain seemingly disparate observations of attentional effects in the neurophysiological literature, including spatial shifts in receptive field position and the preferential modulation of low contrast stimuli. The model is also consistent with recent formulations of attention to features in which gain is variably applied among cells with different receptive field properties. Consistent with functional imaging results, the model predicts that spatial attention effects will vary between different visual areas and suggests that attention may act through a common mechanism of selective and flexible gain throughout the visual system.",
journal = "J. Neurophysiol.",
volume =  101,
number =  4,
pages = "2089--2106",
month =  apr,
year =  2009
}

@ARTICLE{Self2014-zt,
title = "Orientation-tuned surround suppression in mouse visual cortex",
author = "Self, Matthew W and Lorteije, Jeannette A M and Vangeneugden, Joris and van Beest, Enny H and Grigore, Mihaela E and Levelt, Christiaan N and Heimel, J Alexander and Roelfsema, Pieter R",
affiliation = "Department of Vision and Cognition, m.self@nin.knaw.nl. Department of Vision and Cognition. Department of Vision and Cognition. Department of Vision and Cognition. Department of Vision and Cognition. Department of Molecular Visual Plasticity, and. Department of Cortical Structure and Function, Netherlands Institute for Neuroscience, 1105 BA, Amsterdam, the Netherlands. Department of Vision and Cognition, Department of Integrative Neurophysiology, Center for Neurogenomics and Cognitive Research, VU University, 1081 HV Amsterdam, the Netherlands, and Psychiatry Department, Academic Medical Center, 1100 DD Amsterdam, the Netherlands.",
abstract = "The firing rates of neurons in primary visual cortex (V1) are suppressed by large stimuli, an effect known as surround suppression. In cats and monkeys, the strength of suppression is sensitive to orientation; responses to regions containing uniform orientations are more suppressed than those containing orientation contrast. This effect is thought to be important for scene segmentation, but the underlying neural mechanisms are poorly understood. We asked whether it is possible to study these mechanisms in the visual cortex of mice, because of recent advances in technology for studying the cortical circuitry in mice. It is unknown whether neurons in mouse V1 are sensitive to orientation contrast. We measured the orientation selectivity of surround suppression in the different layers of mouse V1. We found strong surround suppression in layer 4 and the superficial layers, part of which was orientation tuned: iso-oriented surrounds caused more suppression than cross-oriented surrounds. Surround suppression was delayed relative to the visual response and orientation-tuned suppression was delayed further, suggesting two separate suppressive mechanisms. Previous studies proposed that surround suppression depends on the activity of inhibitory somatostatin-positive interneurons in the superficial layers. To test the involvement of the superficial layers we topically applied lidocaine. Silencing of the superficial layers did not prevent orientation-tuned suppression in layer 4. These results show that neurons in mouse V1, which lacks orientation columns, show orientation-dependent surround suppression in layer 4 and the superficial layers and that surround suppression in layer 4 does not require contributions from neurons in the superficial layers.",
journal = "J. Neurosci.",
volume =  34,
number =  28,
pages = "9290--9304",
month =  "9~" # jul,
year =  2014,
keywords = "V1; laminar; mouse visual cortex; orientation; scene segmentation; surround suppression"
}

@ARTICLE{Ozeki2009-vu,
title = "Inhibitory stabilization of the cortical network underlies visual surround suppression",
author = "Ozeki, Hirofumi and Finn, Ian M and Schaffer, Evan S and Miller, Kenneth D and Ferster, David",
affiliation = "Department of Neurobiology and Physiology, Northwestern University, Evanston, IL 60208, USA.",
abstract = "In what regime does the cortical circuit operate? Our intracellular studies of surround suppression in cat primary visual cortex (V1) provide strong evidence on this question. Although suppression has been thought to arise from an increase in lateral inhibition, we find that the inhibition that cells receive is reduced, not increased, by a surround stimulus. Instead, suppression is mediated by a withdrawal of excitation. Thalamic recordings and previous work show that these effects cannot be explained by a withdrawal of thalamic input. We find in theoretical work that this behavior can only arise if V1 operates as an inhibition-stabilized network (ISN), in which excitatory recurrence alone is strong enough to destabilize visual responses but feedback inhibition maintains stability. We confirm two strong tests of this scenario experimentally and show through simulation that observed cell-to-cell variability in surround effects, from facilitation to suppression, can arise naturally from variability in the ISN.",
journal = "Neuron",
volume =  62,
number =  4,
pages = "578--592",
month =  "28~" # may,
year =  2009
}

@ARTICLE{Haider2010-mi,
title = "Synaptic and network mechanisms of sparse and reliable visual cortical activity during nonclassical receptive field stimulation",
author = "Haider, Bilal and Krause, Matthew R and Duque, Alvaro and Yu, Yuguo and Touryan, Jonathan and Mazer, James A and McCormick, David A",
affiliation = "Department of Neurobiology, Yale University School of Medicine, 333 Cedar Street, New Haven, CT 06510, USA.",
abstract = "During natural vision, the entire visual field is stimulated by images rich in spatiotemporal structure. Although many visual system studies restrict stimuli to the classical receptive field (CRF), it is known that costimulation of the CRF and the surrounding nonclassical receptive field (nCRF) increases neuronal response sparseness. The cellular and network mechanisms underlying increased response sparseness remain largely unexplored. Here we show that combined CRF + nCRF stimulation increases the sparseness, reliability, and precision of spiking and membrane potential responses in classical regular spiking (RS(C)) pyramidal neurons of cat primary visual cortex. Conversely, fast-spiking interneurons exhibit increased activity and decreased selectivity during CRF + nCRF stimulation. The increased sparseness and reliability of RS(C) neuron spiking is associated with increased inhibitory barrages and narrower visually evoked synaptic potentials. Our experimental observations were replicated with a simple computational model, suggesting that network interactions among neuronal subtypes ultimately sharpen recurrent excitation, producing specific and reliable visual responses.",
journal = "Neuron",
volume =  65,
number =  1,
pages = "107--121",
month =  "14~" # jan,
year =  2010
}

@ARTICLE{Compte2006-md,
title = "Tuning curve shift by attention modulation in cortical neurons: a computational study of its mechanisms",
author = "Compte, Albert and Wang, Xiao-Jing",
affiliation = "Instituto de Neurociencias de Alicante, Universidad Miguel Hern\'{a}ndez - Consejo Superior de Investigaciones Cient\'{\i}ficas, 03550 Sant Joan d'Alacant, Spain. acompte@umh.es",
abstract = "Physiological studies of visual attention have demonstrated that focusing attention near a visual cortical neuron's receptive field (RF) results in enhanced evoked activity and RF shift. In this work, we explored the mechanisms of attention induced RF shifts in cortical network models that receive an attentional 'spotlight'. Our main results are threefold. First, whereas a 'spotlight' input always produces toward-attention shift of the population activity profile, we found that toward-attention shifts in RFs of single cells requires multiplicative gain modulation. Secondly, in a feedforward two-layer model, focal attentional gain modulation in first-layer neurons induces RF shift in second-layer neurons downstream. In contrast to experimental observations, the feedforward model typically fails to produce RF shifts in second-layer neurons when attention is directed beyond RF boundaries. We then show that an additive spotlight input combined with a recurrent network mechanism can produce the observed RF shift. Inhibitory effects in a surround of the attentional focus accentuate this RF shift and induce RF shrinking. Thirdly, we considered interrelationship between visual selective attention and adaptation. Our analysis predicts that the RF size is enlarged (respectively reduced) by attentional signal directed near a cell's RF center in a recurrent network (resp. in a feedforward network); the opposite is true for visual adaptation. Therefore, a refined estimation of the RF size during attention and after adaptation would provide a probe to differentiate recurrent versus feedforward mechanisms for RF shifts.",
journal = "Cereb. Cortex",
volume =  16,
number =  6,
pages = "761--778",
month =  jun,
year =  2006
}


@ARTICLE{Deco2004-vp,
title = "A neurodynamical cortical model of visual attention and invariant object recognition",
author = "Deco, Gustavo and Rolls, Edmund T",
affiliation = "Department of Technology, Computational Neuroscience, Instituci\~{o} Catalana de Recerca i Estudis Avan\c{c}ats, Universitat Pompeu Fabra, Passeig de Circumval.laci\'{o}, 08003 Barcelona, Spain.",
abstract = "We describe a model of invariant visual object recognition in the brain that incorporates feedback biasing effects of top-down attentional mechanisms on a hierarchically organized set of visual cortical areas with convergent forward connectivity, reciprocal feedback connections, and local intra-area competition. The model displays space-based and object-based covert visual search by using attentional top-down feedback from either the posterior parietal or the inferior temporal cortex (IT) modules, and interactions between the two processing streams occurring in V1 and V2. The model explains the gradually increasing magnitude of the attentional modulation that is found in fMRI experiments from earlier visual areas (V1, V2) to higher ventral stream visual areas (V4, IT); how the effective size of the receptive fields of IT neurons becomes smaller in natural cluttered scenes; and makes predictions about interactions between stimuli in their receptive fields.",
journal = "Vision Res.",
volume =  44,
number =  6,
pages = "621--642",
month =  mar,
year =  2004
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ostlund2007-ki,
title = "Orbitofrontal cortex mediates outcome encoding in Pavlovian but not instrumental conditioning",
author = "Ostlund, Sean B and Balleine, Bernard W",
affiliation = "Department of Psychology and the Brain Research Institute, University of California, Los Angeles, California 90095-1563, USA. sostlund@ucla.edu",
abstract = "Previous studies have implicated the orbitofrontal cortex (OFC) in outcome encoding. However, it remains unknown whether the OFC is selectively involved in pavlovian stimulus-outcome learning or whether it also contributes to instrumental action-outcome learning. In experiment 1, we investigated this issue by assessing the effects of bilateral lesions of the OFC on the sensitivity of instrumental lever press performance to a reduction in the incentive value of the training outcome (a test of action-outcome encoding) and to outcome-specific pavlovian-instrumental transfer (a test of stimulus-outcome encoding). We found that post-training lesions of the OFC did not affect instrumental outcome devaluation, but abolished the transfer effect. Interestingly, lesions made before training had no effect on either task. In experiment 2, we explored the involvement of the OFC in updating stimulus-outcome associations after the underlying contingency, or predictive relationship, between these two events has been degraded. Shams displayed clear contingency learning, withholding conditioned responding to a stimulus that no longer reliably predicted its outcome while continuing to respond to a control stimulus that remained a good predictor of a different outcome. In contrast, OFC-lesioned rats stopped responding to both stimuli, regardless of their predictive status. Together, these findings suggest that the OFC supports outcome encoding in pavlovian, but not instrumental conditioning.",
journal = "J. Neurosci.",
volume =  27,
number =  18,
pages = "4819--4825",
month =  "2~" # may,
year =  2007,
annote = "- OFC lesions don't affect instrumental behavior sensitivity to devaluation (presumably because this is done by mPFC)<div><br></div><div>- However, it abolishes S-PIT... but only if lesion is post-conditioning/association of CS with US ! PRe-training lesion has no effect!!</div><div><br></div><div>- Stimulus is auditory, and long - the outcome occurs during the stimulus, not after...</div><div><br></div><div>- Also, OFC lesions eliminate stimulus-specificity of  contingency degradation - if you give the US outside the CS as well (without chaning anything else), animals will hit the magazine less often during this particular CS compared to another ``intact'' CS... but not if OFC lesion !</div><div><br></div><div>- Gallagher (Schoenbaum) 1999 showed that pre-training OFC lesion did eliminate the sensitivity of CS-prompted magazine-going to US devaluation!</div>"
}

@ARTICLE{Ragozzino1999-ro,
title = "Involvement of the {Prelimbic--Infralimbic} Areas of the Rodent Prefrontal Cortex in Behavioral Flexibility for Place and Response Learning",
author = "Ragozzino, Michael E and Detrick, Shauna and Kesner, Raymond P",
abstract = "The present experiments investigated the role of the prelimbic--infralimbic areas in behavioral flexibility using a place--response learning paradigm. All rats received a bilateral cannula implant aimed at the prelimbic--infralimbic areas. To examine the role of the prelimbic--infralimbic areas in shifting strategies, rats were tested on a place and a response discrimination in a cross-maze. Some rats were tested on the place version first followed by the response version. The procedure for the other rats was reversed. Infusions of 2\% tetracaine into the prelimbic--infralimbic areas did not impair acquisition of the place or response discriminations. Prelimbic--infralimbic inactivation did impair learning when rats were switched from one discrimination to the other (cross-modal shift). To investigate the role of the prelimbic--infralimbic areas in intramodal shifts (reversal learning), one group of rats was tested on a place reversal and another group tested on a response reversal. Prelimbic--infralimbic inactivation did not impair place or response intramodal shifts. Some rats that completed testing on a particular version in the cross-modal and intramodal experiments were tested on the same version in a new room for 3 d. The transfer tests revealed that rats use a spatial strategy on the place version and an egocentric response strategy on the response version. Overall, these results suggest that the prelimbic--infralimbic areas are important for behavioral flexibility involving cross-modal but not intramodal shifts.",
journal = "J. Neurosci.",
volume =  19,
number =  11,
pages = "4585--4594",
month =  "1~" # jun,
year =  1999,
annote = "- Inactivation of PL and IL (prelimbic and infralimbic) does not disrupt acquisition of ``place learning'' (go W or E) or ``response learning'' (turn left or right)<div><br></div><div>- It DOES damage switching to the other task after either has been learned!</div><div><br></div><div>- It does NOT damage switching the target position/direction while keeping the same ``rule type'' (place or response) !!</div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ostlund2005-yg,
title = "Lesions of medial prefrontal cortex disrupt the acquisition but not the expression of goal-directed learning",
author = "Ostlund, Sean B and Balleine, Bernard W",
affiliation = "Department of Psychology, The Brain Research Institute, University of California, Los Angeles, California 90095-1563, USA. sostlund@ucla.edu",
abstract = "Several studies have established that pretraining lesions of the medial prefrontal cortex (mPFC) render instrumental actions insensitive to devaluation of the instrumental outcome and degradation of the action-outcome contingency. Nevertheless, it remains to be assessed whether the involvement of the mPFC in goal-directed action is limited to the acquisition or to the expression of the action-outcome association in performance. The current series of experiments investigated this issue by comparing the effects of mPFC lesions made either before or after initial training using sensitivity to outcome devaluation as an assay of goal-directed performance. Whereas pretraining lesions left performance insensitive to outcome devaluation, posttraining lesions spared this effect. To determine whether the effect of mPFC lesions on outcome devaluation was the result of a more fundamental deficit in response selection, experiment 2 assessed the impact of pretraining and posttraining lesions on the ability of the instrumental outcome to selectively reinstate the performance of its associated action after a period of extinction. Although both lesions attenuated the magnitude of instrumental reinstatement generally, they left intact the ability of the instrumental outcome to influence response selection. Experiment 3 investigated the relationship between the outcome-selective devaluation and reinstatement effects and found evidence that these effects are both behaviorally and neurally dissociable at the level of the mPFC. These results indicate that the mPFC is selectively involved in the acquisition, but not the permanent storage or expression, of action-outcome associations in instrumental conditioning.",
journal = "J. Neurosci.",
volume =  25,
number =  34,
pages = "7763--7770",
month =  "24~" # aug,
year =  2005,
annote = "<div>- Effect of lesioning PL part of mPFC on ``goal-directed'' (i.e. devaluation sensitivity)</div><div> </div><div>- Rats with both pre- and post-training PL lesion show normal extinction, then normal reinstatement, so PL presumably not involved in extinction / reinstatement .</div><div><span style=``word-spacing: normal; line-height: 1.5em;''> </span></div><div>- By contrast, rats with post-training lesion show normal sensitivity to devaluation, but rats with pre-training lesion become almost insensitive to devaluation - keep pressing even after satiety!</div><div><br></div><div>- Devaluation mediated by action-outcome learning during training, but reinstatement seems to be more Pavlovian / priming of response by free outcome (like PIT?)</div><div><br></div><div>- So apparently PL involved in learning, but not expressing, R-O associations / outcomes of actions. Perhaps it simply stores them flexibly during learning, while they are learnt by something else (in the BG? BLA?) - they cite Miller \& Cohen 2001….</div><div><br></div><div>A Funny thing: When one reward is devalued, shams have initially low resp for devalued and hi resp for non-devaluedd outcome; but PL pre-training lesion have BOTH responses (associated with both the devalued and the non-devalued outcome) initially very low from the very first trial - PL lesion makes devaluation ``general''?? Yet, PL-lesion shows normal reinstatement ,although of course insensitive to devaluation! </div><div><br></div><div>- Possibility: PL is there to temporarily store the precise specific outcome of actions during learning, as opposed to merely their - overall value?</div><div><br></div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Xu2012-cs,
title = "Nonlinear dendritic integration of sensory and motor input during an active sensing task",
author = "Xu, Ning-Long and Harnett, Mark T and Williams, Stephen R and Huber, Daniel and O'Connor, Daniel H and Svoboda, Karel and Magee, Jeffrey C",
affiliation = "Howard Hughes Medical Institute, Janelia Farm Research Campus, Ashburn, Virginia 20147, USA.",
abstract = "Active dendrites provide neurons with powerful processing capabilities. However, little is known about the role of neuronal dendrites in behaviourally related circuit computations. Here we report that a novel global dendritic nonlinearity is involved in the integration of sensory and motor information within layer 5 pyramidal neurons during an active sensing behaviour. Layer 5 pyramidal neurons possess elaborate dendritic arborizations that receive functionally distinct inputs, each targeted to spatially separate regions. At the cellular level, coincident input from these segregated pathways initiates regenerative dendritic electrical events that produce bursts of action potential output and circuits featuring this powerful dendritic nonlinearity can implement computations based on input correlation. To examine this in vivo we recorded dendritic activity in layer 5 pyramidal neurons in the barrel cortex using two-photon calcium imaging in mice performing an object-localization task. Large-amplitude, global calcium signals were observed throughout the apical tuft dendrites when active touch occurred at particular object locations or whisker angles. Such global calcium signals are produced by dendritic plateau potentials that require both vibrissal sensory input and primary motor cortex activity. These data provide direct evidence of nonlinear dendritic processing of correlated sensory and motor information in the mammalian neocortex during active sensation.",
journal = "Nature",
volume =  492,
number =  7428,
pages = "247--251",
month =  "13~" # dec,
year =  2012,
annote = "- When actively whisking AND touching a target, you get strong, long plateau Ca potentials in apical tuft dendrites<div><br></div><div>- This is modulated by the position of the object!</div><div><br></div><div>-Seems to involve a non-linear combination of sensory inputs and Layer-1 M1 inputs to the apical dendrite: only when both are present together do you get the big plateau potentials</div><div><br></div><div>- From a Jeff Magee talks @ UCSD: a similar phenomenon in CA1 of HPC may create place cells! </div>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Mnih2014-hb,
title = "Recurrent Models of Visual Attention",
booktitle = "Advances in Neural Information Processing Systems 27",
author = "Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray",
editor = "Ghahramani, Z and Welling, M and Cortes, C and Lawrence, N D and Weinberger, K Q",
publisher = "Curran Associates, Inc.",
pages = "2204--2212",
year =  2014,
annote = "- Reinforcement learning used to train a complex RNN, which controls both a 'rover' / attention / location-selection network, and an action network.<div><br></div><div>- The core is the REINFORCE rule, which computes the gradient of the expected cumulative reward over the network weights (using exploration under the current policy/weights). </div><div><br></div><div>- Initially, this is simply the sum, over training episodes and time, of the gradient of the probability of taking the actually-taken action (under the current policy/weights), multiplied by the reward obtained at this particular step. (you want to make actions that have led to reward more probable!)</div><div><br></div><div>- [ More precisely: you look at all the actions that were taken in the episode, and if RPE positive/negative, you gradient-descent the weight to make them more/less likely ]</div><div><br></div><div>- This latter gradient is simply classical backprop of the outputs (action to take) over the weights!</div><div><br></div><div>- But this method has high variance (i.e. it seems that it only ever does any update on the rewarded timesteps?...)</div><div><br></div><div>- So instead you multiply by R(t) - b(t), where b(t) is the expected value (under current policy/weights) at time t! How is b computed? unclear... seems to be standard Value function of RL.</div><div><br></div><div><br></div>"
}

@ARTICLE{Li2013-qp,
title = "Linear transformation of thalamocortical input by intracortical excitation",
author = "Li, Ya-Tang and Ibrahim, Leena A and Liu, Bao-Hua and Zhang, Li I and Tao, Huizhong Whit",
affiliation = "Zilkha Neurogenetic Institute, Keck School of Medicine, University of Southern California, Los Angeles, California, USA.",
abstract = "Neurons in thalamorecipient layers of sensory cortices integrate thalamocortical and intracortical inputs. Although we know that their functional properties can arise from the convergence of thalamic inputs, intracortical circuits could also be involved in thalamocortical transformations of sensory information. We silenced intracortical excitatory circuits with optogenetic activation of parvalbumin-positive inhibitory neurons in mouse primary visual cortex and compared visually evoked thalamocortical input with total excitation in the same layer 4 pyramidal neurons. We found that intracortical excitatory circuits preserved the orientation and direction tuning of thalamocortical excitation, with a linear amplification of thalamocortical signals of about threefold. The spatial receptive field of thalamocortical input was slightly elongated and was expanded by intracortical excitation in an approximately proportional manner. Thus, intracortical excitatory circuits faithfully reinforce the representation of thalamocortical information and may influence the size of the receptive field by recruiting additional inputs.",
journal = "Nat. Neurosci.",
volume =  16,
number =  9,
pages = "1324--1330",
month =  sep,
year =  2013,
annote = "- Like Lien and Scanziani 2013, and L.Y. Li et al. (Zhang) 2013, all from the same issue, says that lateral input (in layer 4 of mouse V1 cortex) has same tuning as feedforward, thalamic feedforward input."
}

@ARTICLE{Li2013-hx,
title = "Intracortical multiplication of thalamocortical signals in mouse auditory cortex",
author = "Li, Ling-Yun and Li, Ya-Tang and Zhou, Mu and Tao, Huizhong W and Zhang, Li I",
affiliation = "Zilkha Neurogenetic Institute, Keck School of Medicine, University of Southern California, Los Angeles, California, USA.",
abstract = "Cortical processing of sensory information begins with the transformation of thalamically relayed signals. We optogenetically silenced intracortical circuits to isolate thalamic inputs to layer 4 neurons and found that intracortical excitation linearly amplified thalamocortical responses underlying frequency and direction selectivity, with spectral range and tuning preserved, and prolonged the response duration. This signal pre-amplification and prolongation enhanced the salience of thalamocortically relayed information and ensured its robust, faithful and more persistent representation.",
journal = "Nat. Neurosci.",
volume =  16,
number =  9,
pages = "1179--1181",
month =  sep,
year =  2013,
annote = "- Like Lien and Scanziani 2013, and YT Li et al. (Tao) 2013, all from the same issue, says that lateral input (in layer 4 of mouse V1 cortex) has same tuning as feedforward, thalamic feedforward input.<div><br></div><div>- Recurrent excitation also significantly prolongs the duration of responses ! Though how much of that is simply a consequence of larger responses? Is there a conflict with sompolinsky?</div><div><br></div>"
}

@ARTICLE{Fino2013-mh,
title = "The logic of inhibitory connectivity in the neocortex",
author = "Fino, Elodie and Packer, Adam M and Yuste, Rafael",
affiliation = "HHMI, Department of Biological Sciences, Columbia University, New York, NY, USA. elodie.fino@college-de-france.fr",
abstract = "Although inhibition plays a major role in the function of the mammalian neocortex, the circuit connectivity of GABAergic interneurons has remained poorly understood. The authors review recent studies of the connections made to and from interneurons, highlighting the overarching principle of a high density of unspecific connections in inhibitory connectivity. Whereas specificity remains in the subcellular targeting of excitatory neurons by interneurons, the general strategy appears to be for interneurons to provide a global ``blanket of inhibition'' to nearby neurons. In the review, the authors highlight the fact that the function of interneurons, which remains elusive, will be informed by understanding the structure of their connectivity as well as the dynamics of inhibitory synaptic connections. In a last section, the authors describe briefly the link between dense inhibitory networks and different interneuron functions described in the neocortex.",
journal = "Neuroscientist",
volume =  19,
number =  3,
pages = "228--237",
month =  jun,
year =  2013,
annote = "<div>- Inhibition by PV neurons really seems to be largely dense and all-to-all / indiscriminate.</div><div><br></div>- Largely added because a reviewer asked for it in a paper. A Packer \& Yuste J Neurosci 2011 might have been more relevant, but this is a review paper.",
keywords = "GABAergic; connectivity; inhibition; interneurons; networks"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cossell2015-ce,
title = "Functional organization of excitatory synaptic strength in primary visual cortex",
author = "Cossell, Lee and Iacaruso, Maria Florencia and Muir, Dylan R and Houlton, Rachael and Sader, Elie N and Ko, Ho and Hofer, Sonja B and Mrsic-Flogel, Thomas D",
affiliation = "1] Department of Neuroscience, Physiology and Pharmacology, University College London, 21 University Street, London WC1E 6DE, UK [2] Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH - 4056 Basel, Switzerland. 1] Department of Neuroscience, Physiology and Pharmacology, University College London, 21 University Street, London WC1E 6DE, UK [2] Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH - 4056 Basel, Switzerland. Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH - 4056 Basel, Switzerland. Department of Neuroscience, Physiology and Pharmacology, University College London, 21 University Street, London WC1E 6DE, UK. Department of Neuroscience, Physiology and Pharmacology, University College London, 21 University Street, London WC1E 6DE, UK. 1] Department of Neuroscience, Physiology and Pharmacology, University College London, 21 University Street, London WC1E 6DE, UK [2] Lui Che Woo Institute of Innovative Medicine and Chow Yuk Ho Technology Center for Innovative Medicine, Faculty of Medicine, the Chinese University of Hong Kong, Shatin, New Territories, Hong Kong. 1] Department of Neuroscience, Physiology and Pharmacology, University College London, 21 University Street, London WC1E 6DE, UK [2] Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH - 4056 Basel, Switzerland. 1] Department of Neuroscience, Physiology and Pharmacology, University College London, 21 University Street, London WC1E 6DE, UK [2] Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH - 4056 Basel, Switzerland.",
abstract = "The strength of synaptic connections fundamentally determines how neurons influence each other's firing. Excitatory connection amplitudes between pairs of cortical neurons vary over two orders of magnitude, comprising only very few strong connections among many weaker ones. Although this highly skewed distribution of connection strengths is observed in diverse cortical areas, its functional significance remains unknown: it is not clear how connection strength relates to neuronal response properties, nor how strong and weak inputs contribute to information processing in local microcircuits. Here we reveal that the strength of connections between layer 2/3 (L2/3) pyramidal neurons in mouse primary visual cortex (V1) obeys a simple rule--the few strong connections occur between neurons with most correlated responses, while only weak connections link neurons with uncorrelated responses. Moreover, we show that strong and reciprocal connections occur between cells with similar spatial receptive field structure. Although weak connections far outnumber strong connections, each neuron receives the majority of its local excitation from a small number of strong inputs provided by the few neurons with similar responses to visual features. By dominating recurrent excitation, these infrequent yet powerful inputs disproportionately contribute to feature preference and selectivity. Therefore, our results show that the apparently complex organization of excitatory connection strength reflects the similarity of neuronal responses, and suggest that rare, strong connections mediate stimulus-specific response amplification in cortical microcircuits.",
journal = "Nature",
volume =  518,
number =  7539,
pages = "399--403",
month =  "19~" # feb,
year =  2015,
annote = "<p>- How are the connection weights distributed in mouse v1 ?</p><p> </p><p>- 7\% most correlated pairs accounted for 50\% of total connection weight</p><p> </p><p>- 50\% of total synaptic weight between 12\% of pairs with the most correlated RFs</p><p> </p><p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lansner2009-al,
title = "Associative memory models: from the cell-assembly theory to biophysically detailed cortex simulations",
author = "Lansner, Anders",
affiliation = "Department of Computational Biology, School of Computer Science and Communication, Stockholm University and Royal Institute of Technology, 114 21 Stockholm, Sweden. ala@kth.se",
abstract = "The second half of the past century saw the emergence of a theory of cortical associative memory function originating in Donald Hebb's hypotheses on activity-dependent synaptic plasticity and cell-assembly formation and dynamics. This conceptual framework has today developed into a theory of attractor memory that brings together many experimental observations from different sources and levels of investigation into computational models displaying information-processing capabilities such as efficient associative memory and holistic perception. Here, we outline a development that might eventually lead to a neurobiologically grounded theory of cortical associative memory.",
journal = "Trends Neurosci.",
volume =  32,
number =  3,
pages = "178--186",
month =  mar,
year =  2009,
annote = "- A review of auto-associative memory models. <div><br></div><div>- Starts with the Hebb concept of assemblies, the Little-Hopfield model, goes through spiking networks with plasticity</div><div><br></div><div>- States that Hebb was preoccupied with both concept completion from partial stimuli AND persistent activity after stimulus removal</div><div><br></div><div>- Posits that there is a division of labor between layer 4 (build the sparse, memoryless representations as input to the auto-associative network) and layer 2/3 or 5 (be the actual auto-associative networks, using layer 4 as an input)</div><div><br></div><div>- Does explicitly state that this is associated more with ``higher order cortical areas'' - i.e. not V1, presumably.</div>"
}

@ARTICLE{Amit2003-uv,
title = "Spike-driven synaptic dynamics generating working memory states",
author = "Amit, Daniel J and Mongillo, Gianluigi",
affiliation = "Dipartimento di Fisica, Universita' di Roma, La Sapienza, 00185 Rome, Italy. daniel.amit@roma1.infn.it",
abstract = "The collective behavior of a network, modeling a cortical module of spiking neurons connected by plastic synapses is studied. A detailed spike-driven synaptic dynamics is simulated in a large network of spiking neurons, implementing the full double dynamics of neurons and synapses. The repeated presentation of a set of external stimuli is shown to structure the network to the point of sustaining working memory (selective delay activity). When the synaptic dynamics is analyzed as a function of pre- and postsynaptic spike rates in functionally defined populations, it reveals a novel variation of the Hebbian plasticity paradigm: in any functional set of synapses between pairs of neurons (e.g., stimulated-stimulated, stimulated-delay, stimulated-spontaneous), there is a finite probability of potentiation as well as of depression. This leads to a saturation of potentiation or depression at the level of the ratio of the two probabilities. When one of the two probabilities is very high relative to the other, the familiar Hebbian mechanism is recovered. But where correlated working memory is formed, it prevents overlearning. Constraints relevant to the stability of the acquired synaptic structure and the regimes of global activity allowing for structuring are expressed in terms of the parameters describing the single-synapse dynamics. The synaptic dynamics is discussed in the light of experiments observing precise spike timing effects and related issues of biological plausibility.",
journal = "Neural Comput.",
volume =  15,
number =  3,
pages = "565--596",
month =  mar,
year =  2003
}

@ARTICLE{Mongillo2005-xu,
title = "Learning in realistic networks of spiking neurons and spike-driven plastic synapses",
author = "Mongillo, Gianluigi and Curti, Emanuele and Romani, Sandro and Amit, Daniel J",
affiliation = "Dipartimento di Fisiologia Umana and Dottorato di ricerca in Neurofisiologia, Universita' di Roma La Sapienza, Rome, Italy. mongillo@surete3.roma1.infn.it",
abstract = "We have used simulations to study the learning dynamics of an autonomous, biologically realistic recurrent network of spiking neurons connected via plastic synapses, subjected to a stream of stimulus-delay trials, in which one of a set of stimuli is presented followed by a delay. Long-term plasticity, produced by the neural activity experienced during training, structures the network and endows it with active (working) memory, i.e. enhanced, selective delay activity for every stimulus in the training set. Short-term plasticity produces transient synaptic depression. Each stimulus used in training excites a selective subset of neurons in the network, and stimuli can share neurons (overlapping stimuli). Long-term plasticity dynamics are driven by presynaptic spikes and coincident postsynaptic depolarization; stability is ensured by a refresh mechanism. In the absence of stimulation, the acquired synaptic structure persists for a very long time. The dependence of long-term plasticity dynamics on the characteristics of the stimulus response (average emission rates, time course and synchronization), and on the single-cell emission statistics (coefficient of variation) is studied. The study clarifies the specific roles of short-term synaptic depression, NMDA receptors, stimulus representation overlaps, selective stimulation of inhibition, and spike asynchrony during stimulation. Patterns of network spiking activity before, during and after training reproduce most of the in vivo physiological observations in the literature.",
journal = "Eur. J. Neurosci.",
volume =  21,
number =  11,
pages = "3143--3160",
month =  jun,
year =  2005
}

@ARTICLE{Scholvinck2015-hk,
title = "Cortical state determines global variability and correlations in visual cortex",
author = "Sch{\"{o}}lvinck, Marieke L and Saleem, Aman B and Benucci, Andrea and Harris, Kenneth D and Carandini, Matteo",
affiliation = "UCL Institute of Ophthalmology, University College London, London EC1V 9EL, United Kingdom, and marieke.scholvinck@esi-frankfurt.de. UCL Institute of Ophthalmology, University College London, London EC1V 9EL, United Kingdom, and. UCL Institute of Ophthalmology, University College London, London EC1V 9EL, United Kingdom, and. UCL Institute of Ophthalmology, University College London, London EC1V 9EL, United Kingdom, and UCL Institute of Neurology and UCL Department of Neuroscience, Physiology \& Pharmacology, London WC1E 6DE, United Kingdom. UCL Institute of Ophthalmology, University College London, London EC1V 9EL, United Kingdom, and.",
abstract = "The response of neurons in sensory cortex to repeated stimulus presentations is highly variable. To investigate the nature of this variability, we compared the spike activity of neurons in the primary visual cortex (V1) of cats with that of their afferents from lateral geniculate nucleus (LGN), in response to similar stimuli. We found variability to be much higher in V1 than in LGN. To investigate the sources of the additional variability, we measured the spiking activity of large V1 populations and found that much of the variability was shared across neurons: the variable portion of the responses of one neuron could be well predicted from the summed activity of the rest of the neurons. Variability thus mostly reflected global fluctuations affecting all neurons. The size and prevalence of these fluctuations, both in responses to stimuli and in ongoing activity, depended on cortical state, being larger in synchronized states than in more desynchronized states. Contrary to previous reports, these fluctuations invested the overall population, regardless of preferred orientation. The global fluctuations substantially increased variability in single neurons and correlations among pairs of neurons. Once this effect was removed, pairwise correlations were reduced and were similar regardless of cortical state. These results highlight the importance of cortical state in controlling cortical operation and can help reconcile previous studies, which differed widely in their estimate of neuronal variability and pairwise correlations.",
journal = "J. Neurosci.",
volume =  35,
number =  1,
pages = "170--178",
month =  "7~" # jan,
year =  2015,
annote = "- Most of the (trial-to-trial?) noise in neuron responses is caused by large-scale, population-wide fluctuations",
keywords = "brain states; cerebral cortex; neural populations; thalamus; vision"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Okun2015-oq,
title = "Diverse coupling of neurons to populations in sensory cortex",
author = "Okun, Michael and Steinmetz, Nicholas A and Cossell, Lee and Iacaruso, M Florencia and Ko, Ho and Barth\'{o}, P\'{e}ter and Moore, Tirin and Hofer, Sonja B and Mrsic-Flogel, Thomas D and Carandini, Matteo and Harris, Kenneth D",
affiliation = "1] UCL Institute of Neurology, University College London, London WC1N 3BG, UK [2] Department of Neuroscience, Physiology and Pharmacology, University College London, London WC1E 6DE, UK [3] UCL Institute of Ophthalmology, University College London, London EC1V 9EL, UK. 1] UCL Institute of Neurology, University College London, London WC1N 3BG, UK [2] Department of Neuroscience, Physiology and Pharmacology, University College London, London WC1E 6DE, UK [3] UCL Institute of Ophthalmology, University College London, London EC1V 9EL, UK [4] Howard Hughes Medical Institute and Department of Neurobiology, Stanford University, Stanford, California 94305-5125, USA. 1] Department of Neuroscience, Physiology and Pharmacology, University College London, London WC1E 6DE, UK [2] Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH-4056 Basel, Switzerland. 1] Department of Neuroscience, Physiology and Pharmacology, University College London, London WC1E 6DE, UK [2] Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH-4056 Basel, Switzerland. Department of Neuroscience, Physiology and Pharmacology, University College London, London WC1E 6DE, UK. Center for Molecular and Behavioral Neuroscience, Rutgers University, 197 University Avenue, Newark, New Jersey 07102, USA. Howard Hughes Medical Institute and Department of Neurobiology, Stanford University, Stanford, California 94305-5125, USA. 1] Department of Neuroscience, Physiology and Pharmacology, University College London, London WC1E 6DE, UK [2] Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH-4056 Basel, Switzerland. 1] Department of Neuroscience, Physiology and Pharmacology, University College London, London WC1E 6DE, UK [2] Biozentrum, University of Basel, Klingelbergstrasse 50/70, CH-4056 Basel, Switzerland. UCL Institute of Ophthalmology, University College London, London EC1V 9EL, UK. 1] UCL Institute of Neurology, University College London, London WC1N 3BG, UK [2] Department of Neuroscience, Physiology and Pharmacology, University College London, London WC1E 6DE, UK [3] Center for Molecular and Behavioral Neuroscience, Rutgers University, 197 University Avenue, Newark, New Jersey 07102, USA.",
abstract = "A large population of neurons can, in principle, produce an astronomical number of distinct firing patterns. In cortex, however, these patterns lie in a space of lower dimension, as if individual neurons were ``obedient members of a huge orchestra''. Here we use recordings from the visual cortex of mouse (Mus musculus) and monkey (Macaca mulatta) to investigate the relationship between individual neurons and the population, and to establish the underlying circuit mechanisms. We show that neighbouring neurons can differ in their coupling to the overall firing of the population, ranging from strongly coupled 'choristers' to weakly coupled 'soloists'. Population coupling is largely independent of sensory preferences, and it is a fixed cellular attribute, invariant to stimulus conditions. Neurons with high population coupling are more strongly affected by non-sensory behavioural variables such as motor intention. Population coupling reflects a causal relationship, predicting the response of a neuron to optogenetically driven increases in local activity. Moreover, population coupling indicates synaptic connectivity; the population coupling of a neuron, measured in vivo, predicted subsequent in vitro estimates of the number of synapses received from its neighbours. Finally, population coupling provides a compact summary of population activity; knowledge of the population couplings of n neurons predicts a substantial portion of their n(2) pairwise correlations. Population coupling therefore represents a novel, simple measure that characterizes the relationship of each neuron to a larger population, explaining seemingly complex network firing patterns in terms of basic circuit variables.",
journal = "Nature",
volume =  521,
number =  7553,
pages = "511--515",
month =  "28~" # may,
year =  2015,
annote = "- Neurons vary in their instantaneous coupling to summed population activity, during spontaneous activity. <div><br></div><div>- ``Chorist'' neurons have their (noise?) variance tightly coupled to population summed activity, while ``soloist'' neurons are more independent.</div><div><br></div><div>- This depends on total number of connections, NOT on orientation preference</div><div><br></div><div>- This coupling explains a large part of instantaneous neuron pairwise correlations in instantaneous activity!</div><div><br></div><div>- This is separate from ``groups'' (fine-grained, individual neuron-to-neuron correlations that do depend strongly on neuron tuning): the group correlations are in addition to this overall population coupling.</div><div><br></div><div><br><div>- See also the Scholvinck et al (Harris/Carandini) paper that showed that most of the noise in neuron activity is caused by population-wide, global wide-scale fluctuations. This paper shows that neurons vary in their coupling to these overall global fluctuations, and this depends on total number of lateral connections.</div></div>"
}

@ARTICLE{Rochefort2011-aw,
title = "Development of direction selectivity in mouse cortical neurons",
author = "Rochefort, Nathalie L and Narushima, Madoka and Grienberger, Christine and Marandi, Nima and Hill, Daniel N and Konnerth, Arthur",
affiliation = "Institute of Neuroscience and Center for Integrated Protein Science, Technical University Munich, Biedersteinerstrasse 29, 80802 Munich, Germany.",
abstract = "Previous studies of the ferret visual cortex indicate that the development of direction selectivity requires visual experience. Here, we used two-photon calcium imaging to study the development of direction selectivity in layer 2/3 neurons of the mouse visual cortex in vivo. Surprisingly, just after eye opening nearly all orientation-selective neurons were also direction selective. During later development, the number of neurons responding to drifting gratings increased in parallel with the fraction of neurons that were orientation, but not direction, selective. Our experiments demonstrate that direction selectivity develops normally in dark-reared mice, indicating that the early development of direction selectivity is independent of visual experience. Furthermore, remarkable functional similarities exist between the development of direction selectivity in cortical neurons and the previously reported development of direction selectivity in the mouse retina. Together, these findings provide strong evidence that the development of orientation and direction selectivity in the mouse brain is distinctly different from that in ferrets.",
journal = "Neuron",
publisher = "research.ed.ac.uk",
volume =  71,
number =  3,
pages = "425--432",
month =  "11~" # aug,
year =  2011
}

@MISC{Center_for_History_and_New_Media_undated-vf,
title = "Zotero Quick Start Guide",
author = "{Center for History and New Media}",
howpublished = "\url{http://zotero.org/support/quick_start_guide}",
annote = "<p><strong>Welcome to Zotero!</strong></p><p>View the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research sources.</p><p>Thanks for installing Zotero.</p>"
}

@ARTICLE{Zylberberg2011-lw,
title = "A Sparse Coding Model with Synaptically Local Plasticity and Spiking Neurons Can Account for the Diverse Shapes of {V1} Simple Cell Receptive Fields",
author = "Zylberberg, Joel and Murphy, Jason Timothy and DeWeese, Michael Robert",
abstract = "Author Summary In a sparse coding model, individual input stimuli are represented by the activities of model neurons, the majority of which are inactive in response to any particular stimulus. For a given class of stimuli, the neurons are optimized so that the stimuli can be faithfully represented with the minimum number of co-active units. This has been proposed as a model for visual cortex. While it has previously been demonstrated that sparse coding model neurons, when trained on natural images, learn to represent the same features as do neurons in primate visual cortex, it remains to be demonstrated that this can be achieved with physiologically realistic plasticity rules. In particular, learning in cortex appears to occur by the modification of synaptic connections between neurons, which must depend only on information available locally, at the synapse, and not, for example, on the properties of large numbers of distant cells. We provide the first demonstration that synaptically local plasticity rules are sufficient to learn a sparse image code, and to account for the observed response properties of visual cortical neurons: visual cortex actually could learn a sparse image code.",
journal = "PLoS Comput. Biol.",
volume =  7,
number =  10,
pages = "e1002250",
month =  "27~" # oct,
year =  2011
}

@ARTICLE{Edelman2001-vd,
title = "Degeneracy and complexity in biological systems",
author = "Edelman, Gerald M and Gally, Joseph A",
abstract = "Degeneracy, the ability of elements that are structurally different to perform the same function or yield the same output, is a well known characteristic of the genetic code and immune systems. Here, we point out that degeneracy is a ubiquitous biological property and argue that it is a feature of complexity at genetic, cellular, system, and population levels. Furthermore, it is both necessary for, and an inevitable outcome of, natural selection.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
volume =  98,
number =  24,
pages = "13763--13768",
month =  "20~" # nov,
year =  2001,
language = "en"
}

@ARTICLE{Carandini1994-or,
title = "Summation and division by neurons in primate visual cortex",
author = "Carandini, M and Heeger, D J",
abstract = "Recordings from monkey primary visual cortex (V1) were used to test a model for the visually driven responses of simple cells. According to the model, simple cells compute a linear sum of the responses of lateral geniculate nucleus (LGN) neurons. In addition, each simple cell's linear response is divided by the pooled activity of a large number of other simple cells. The cell membrane performs both operations; synaptic currents are summed and then divided by the total membrane conductance. Current and conductance are decoupled (by a complementary arrangement of excitation and inhibition) so that current depends only on the LGN inputs and conductance depends only on the cortical inputs. Closed form expressions were derived for fitting and interpreting physiological data. The model accurately predicted responses to drifting grating stimuli of various contrasts, orientations, and spatiotemporal frequencies.",
journal = "Science",
volume =  264,
number =  5163,
pages = "1333--1336",
month =  "27~" # may,
year =  1994,
annote = "<p>Suggests normalization works by increasing ``shunting'' conductance (conductance with a reversal potential close to rest potential).</p>
<p>Assumes that EXC and INH conductance (but not shunting, and leak conductances) are balanced against each other: gi + ge = const. Sounds bizarre, especially if excitation and inhibition are supposed to be balanced...</p>
<p>It partly explains why normalization would lead to phase advance in neural responses: normalization increases conductance, that slashes the time constants!</p>",
language = "eng"
}

@ARTICLE{Carandini2011-jj,
title = "Normalization as a canonical neural computation",
author = "Carandini, Matteo and Heeger, David J",
journal = "Nat. Rev. Neurosci.",
month =  "23~" # nov,
year =  2011,
annote = "<p>surThey say that you can make normalization work in a feedback manner, i.e. presumably using the post-normalization responses in the normalization step and obtaining a divisive operation ``in the steady state''. Need to find out how.</p>
<p>Look in the ``Linearity and Normalization'' paper: they put the activities of normalizing cells through a complex function to produce the new conductance.... Also seems to assume gi+ge = const?</p>"
}

@ARTICLE{Carandini1997-rn,
title = "Linearity and Normalization in Simple Cells of the Macaque Primary Visual Cortex",
author = "Carandini, Matteo and Heeger, David J and Movshon, J Anthony",
abstract = "Simple cells in the primary visual cortex often appear to compute a weighted sum of the light intensity distribution of the visual stimuli that fall on their receptive fields. A linear model of these cells has the advantage of simplicity and captures a number of basic aspects of cell function. It, however, fails to account for important response nonlinearities, such as the decrease in response gain and latency observed at high contrasts and the effects of masking by stimuli that fail to elicit responses when presented alone. To account for these nonlinearities we have proposed a normalization model, which extends the linear model to include mutual shunting inhibition among a large number of cortical cells. Shunting inhibition is divisive, and its effect in the model is to normalize the linear responses by a measure of stimulus energy. To test this model we performed extracellular recordings of simple cells in the primary visual cortex of anesthetized macaques. We presented large stimulus sets consisting of (1) drifting gratings of various orientations and spatiotemporal frequencies; (2) plaids composed of two drifting gratings; and (3) gratings masked by full-screen spatiotemporal white noise. We derived expressions for the model predictions and fitted them to the physiological data. Our results support the normalization model, which accounts for both the linear and the nonlinear properties of the cells. An alternative model, in which the linear responses are subject to a compressive nonlinearity, did not perform nearly as well.",
journal = "J. Neurosci.",
volume =  17,
number =  21,
pages = "8621--8644",
month =  "1~" # nov,
year =  1997,
language = "en"
}

@ARTICLE{Purushothaman_undated-wt,
title = "Gating and control of primary visual cortex by pulvinar",
author = "Purushothaman, Gopathy and Marion, Roan and Li, Keji and Casagrande, Vivien A",
abstract = "The primary visual cortex (V1) receives its driving input from the eyes via the lateral geniculate nucleus (LGN) of the thalamus. The lateral pulvinar nucleus of the thalamus also projects to V1 but this input is little understood. We manipulated lateral pulvinar neural activity and assessed the effect on supra-granular layers of V1 that project to higher visual cortex. Reversibly inactivating lateral pulvinar prevented supra-granular V1 neurons from responding to visual stimulation. Reversible, focal excitation of lateral pulvinar receptive fields increased 4-fold the visual responses in coincident V1 receptive fields and shifted partially overlapping V1 receptive fields towards the center of excitation. V1 responses to regions surrounding the excited lateral pulvinar receptive fields were suppressed. LGN responses were unaffected by these lateral pulvinar manipulations. Excitation of lateral pulvinar after LGN lesion activated supra-granular layer V1 neurons. Thus, lateral pulvinar is able to powerfully control and gate information outflow from V1.",
journal = "Nat. Neurosci.",
volume =  15,
number =  6,
pages = "905--912"
}

@ARTICLE{Markov_undated-nz,
title = "The importance of being hierarchical",
author = "Markov, Nikola T and Kennedy, Henry",
journal = "Curr. Opin. Neurobiol.",
volume =  23,
number =  2,
pages = "187--194"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Friston2012-jb,
title = "The history of the future of the Bayesian brain",
author = "Friston, Karl",
abstract = "The slight perversion of the original title of this piece (The Future of the Bayesian Brain) reflects my attempt to write prospectively about ‘Science and Stories’ over the past 20 years. I will meet this challenge by dealing with the future and then turning to its history. The future of the Bayesian brain (in neuroimaging) is clear: it is the application of dynamic causal modeling to understand how the brain conforms to the free energy principle. In this context, the Bayesian brain is a corollary of the free energy principle, which says that any self organizing system (like a brain or neuroimaging community) must maximize the evidence for its own existence, which means it must minimize its free energy using a model of its world. Dynamic causal modeling involves finding models of the brain that have the greatest evidence or the lowest free energy. In short, the future of imaging neuroscience is to refine models of the brain to minimize free energy, where the brain refines models of the world to minimize free energy. This endeavor itself minimizes free energy because our community is itself a self organizing system. I cannot imagine an alternative future that has the same beautiful self consistency as mine. Having dispensed with the future, we can now focus on the past, which is much more interesting:",
journal = "Neuroimage",
volume =  62,
number =  2,
pages = "1230--1233",
month =  "15~" # aug,
year =  2012
}

@ARTICLE{Crick1989-hx,
title = "Neural edelmanism",
author = "Crick, F",
abstract = "The recent book Neural Darwinism (ND) by Gerald Edelman, claims to put forward 'a radically new view of the function of the brain and nervous system'. Its main focus is on the understanding of the biological basis of perception. This new view is based on what Edelman calls 'The Theory of Neuronal Group Selection', the subtitle of his book. In spite of Edelman's lengthy and spirited account of this new theory, most readers appear to have had some difficulty in grasping his ideas and many have complained that the book is not easy to read. It has been particularly difficult to relate Edelman's ideas to those already current and well-known, especially as Edelman himself says rather little on this topic. In this critique I aim to set out Edelman's central ideas, as they appear to me, in a clearer and more digestible form. I examine both his general exposition of these ideas and the simulations he has presented to support them, giving page references so that the concerned reader can check my statements against the text. I have considered also Edelman's original papers, upon which the book is based, but I have not considered more recent papers which deal with matters (such as Darwin III) that are not covered in the book.",
journal = "Trends Neurosci.",
volume =  12,
number =  7,
pages = "240--248",
month =  jul,
year =  1989,
language = "eng"
}

@ARTICLE{Miller1989-kn,
title = "Ocular dominance column development: analysis and simulation",
author = "Miller, K D and Keller, J B and Stryker, M P",
abstract = "The visual cortex of many adult mammals has patches of cells that receive inputs driven by the right eye alternating with patches that receive inputs driven by the left eye. These ocular dominance patches (or ``columns'') form during early life as a consequence of competition between the activity patterns of the two eyes. A mathematical model of several biological mechanisms that can account for this development is presented. Analysis of this model reveals the conditions under which ocular dominance segregation will occur and determines the resulting patch width. Simulations of the model also exhibit other phenomena associated with early visual development, such as topographic refinement of cortical receptive fields, the confinement of input cell connections to patches, monocular deprivation plasticity including a critical period, and the effect of artificially induced strabismus. The model can be used to predict the results of proposed experiments and to discriminate among various mechanisms of plasticity.",
journal = "Science",
volume =  245,
number =  4918,
pages = "605--615",
month =  "11~" # aug,
year =  1989,
language = "en"
}

@ARTICLE{Singer_undated-bo,
title = "Cortical dynamics revisited",
author = "Singer, Wolf",
journal = "Trends Cogn. Sci."
}

@ARTICLE{Vinje2000-aq,
title = "Sparse coding and decorrelation in primary visual cortex during natural vision",
author = "Vinje, William E and Gallant, Jack L",
journal = "Science",
volume =  287,
number =  5456,
pages = "1273--1276",
year =  2000
}

@ARTICLE{Desmurget2009-cq,
title = "Movement Intention After Parietal Cortex Stimulation in Humans",
author = "Desmurget, M and Reilly, K T and Richard, N and Szathmari, A and Mottolese, C and Sirigu, A",
journal = "Science",
volume =  324,
number =  5928,
pages = "811--813",
month =  "7~" # may,
year =  2009
}

@ARTICLE{DiCarlo_undated-es,
title = "How Does the Brain Solve Visual Object Recognition?",
author = "DiCarlo, James J and Zoccolan, Davide and Rust, Nicole C",
journal = "Neuron",
volume =  73,
number =  3,
pages = "415--434"
}

@ARTICLE{Nandy_undated-xk,
title = "The Fine Structure of Shape Tuning in Area {V4}",
author = "Nandy, Anirvan S and Sharpee, Tatyana O and Reynolds, John H and Mitchell, Jude F",
journal = "Neuron",
volume =  78,
number =  6,
pages = "1102--1115",
annote = "<p>- V4 neurons that are tuned to low-curved shapes / straight lines are relatively position-tolerant (tuning order is preserved across positions)</p>
<p>- V4 neurons that are tuned to tightly-curved shapes are NOT position-tolerant (tuning order changes across positions)</p>
<p>- If you just average the selectivity of the high-curvature-selective neurons over all positions, the tuning disappear and you would mistake these neurons as non-shape-tuned!</p>
<p>- Don't say which layer they recorded in...</p>
<p>- Seems to be mostly compatible with pooling of local edge-oriented elements, at least with low curvature</p>"
}

@ARTICLE{Rozell2008-bm,
title = "Sparse coding via thresholding and local competition in neural circuits",
author = "Rozell, Christopher J and Johnson, Don H and Baraniuk, Richard G and Olshausen, Bruno A",
journal = "Neural Comput.",
volume =  20,
number =  10,
pages = "2526--2563",
year =  2008,
annote = "<p>- In this model, they use a dynamical activation: neurons accumulate activation (dependent on both their stimulation and the inhibition they receive from other *active*=above-threshold cells multiplied by the similarity of RFs), but only really start firing when they're above threshold.</p>
<p>- The result is that, for a given set of RFs, the activity of the network essentially minimizes a cost function that is reconstruction fidelity minus some penalty based on an increasing function of cell activity</p>
<p>- The actual penalty function depends on the threshold function used. In particular, simple thresholding minimizes L1-norm.</p>
<p>- The actual numerical value of the threshold seems not to matter (you can just set it at one), only the shape of the thresholding function does.</p>
<p>- Note that they do NOT modify the dictionary elements / RF.</p>"
}

@ARTICLE{Foldiak1990-ct,
title = "Forming sparse representations by local anti-Hebbian learning",
author = "F{\"{o}}ldiak, Peter",
journal = "Biol. Cybern.",
volume =  64,
number =  2,
pages = "165--170",
year =  1990
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hyvarinen2001-lh,
title = "A two-layer sparse coding model learns simple and complex cell receptive fields and topography from natural images",
author = "Hyv{\"{a}}rinen, Aapo and Hoyer, Patrik O",
journal = "Vision Res.",
volume =  41,
number =  18,
pages = "2413--2423",
year =  2001,
annote = "<p>- An explanation of ICA for getting simple cells</p>
<p>- But also show that simply by putting a``topographically pooling'' additional layer before the to-be-sparsified response, you get complex cells! Even though connections from S to C are fixed and unchangeable!</p>
<p>- Also topographic arrangement of S cells in orientation maps, with blobs of low-frequency cells...</p>
<p>- BUT ! Already assumes phase invariance by stating that simple cells are signed and complex cells square them (i.e. strong negative activation becomes strong positive excitation)!</p>
<p> </p>"
}

@INPROCEEDINGS{Vasilkoski2011-ww,
title = "Review of stability properties of neural plasticity rules for implementation on memristive neuromorphic hardware",
booktitle = "Neural Networks ({IJCNN)}, The 2011 International Joint Conference on",
author = "Vasilkoski, Zlatko and Ames, Heather and Chandler, Ben and Gorchetchnikov, Anatoli and L\'{e}veill\'{e}, Jasmin and Livitz, Gennady and Mingolla, Ennio and Versace, Massimiliano",
pages = "2563--2569",
year =  2011
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Stevens2013-fw,
title = "Mechanisms for Stable, Robust, and Adaptive Development of Orientation Maps in the Primary Visual Cortex",
author = "Stevens, J-L R and Law, J S and Antolik, J and Bednar, J A",
journal = "Journal of Neuroscience",
volume =  33,
number =  40,
pages = "15747--15766",
month =  "2~" # oct,
year =  2013,
annote = "<p>- No learning in lateral connections! (p. 15753, second paragraph after Eq.10)</p>
<p> </p>
<p>- Hebbian learning for inhibitory weights. Cells that fire together anti-wire together?</p>
<div class=``page'' title=``Page 7''>
<div class=``layoutArea''>
<div class=``column''>
<p><span style=``font-size:8pt;font-family:MyriadMM;font-weight:bold;''> </span></p>
</div>
</div>
</div>"
}

@ARTICLE{McClelland1989-hm,
title = "Sentence comprehension: A parallel distributed processing approach",
author = "McClelland, James L and St. John, Mark and Taraban, Roman",
journal = "Lang. Cogn. Process.",
volume =  4,
number = "3-4",
pages = "SI287--SI335",
year =  1989
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yu2013-rh,
title = "Functional Coupling from Simple to Complex Cells in the Visually Driven Cortical Circuit",
author = "Yu, J and Ferster, D",
journal = "Journal of Neuroscience",
volume =  33,
number =  48,
pages = "18855--18866",
month =  "27~" # nov,
year =  2013,
annote = "<p>- BACKGROUND: People have observed strong FUNCTIONAL coupling between simple and complex cells in layers 4 and 2/3: in ~50\% of pairs, firing in the complex cell increased significantly after spikes in the simple cell. But how is it that each simple cell can trigger a high fraction of complex spikes if many simple cells connect to any complex cell?</p>
<p>- When looking at slice physiology, connection probability is actually low (~10\% of pairs)</p>
<p>- Either in vitro missed some, or in vivo overestimated due to correlated activity. Complex cells almost always fire at the top of large fluctuations in the 20-80Hz range, much larger than individual incoming EPSCs.</p>
<p>- (From the conclusion): Nearly-symmetrical Vm cross-correlations and Vm-STAs between neighbouring complex cells - possibly explained by largely common input.</p>
<p>- (From conclusion): In Monkeys, evidence of strong, fast spike synchrony between L4 cells!</p>
<p>-MAIN RESULT: during visual stimulation, strong functional connectivity (85\% of pairs). Simple spikes followed by small 1mV increases in complex cell V. But during electrical stimulation of single cells, this is not observed!</p>
<p> </p>
<p>- In simple cells, stimulation generates clusters of spikes, each cluster at ~35Hz (grating frequency 2 Hz).</p>
<p> </p>
<p>- ON AVERAGE, Simple cell spikes consistently occur just around the throughs of complex cell voltage excursions. Simple-spike-triggered average of complex V is asymmetric around t=0, rising.</p>
<p> </p>
<p>- With no stimulation, simple cell firing is very low. The simple-spike-triggered average of complex cells V becomes more symmetric. SIMPLE spikes largely occurs during slow fluctuations (UP states) of COMPLEX cells (!) - slow fluctuations are suppressed during visual stimulation, which puts the network into a high-frequency mode.</p>
<p> </p>
<p>- Electrically stimulating a single simple cell does not seem to cause any effect in the complex cell (except in a few cases with apparent small monosynaptic connections)</p>
<p> </p>
<p>- Vm cross-correlations between simple and complex cells are only asymmetric during the responsive phase of the grating for the simple cell. During the simple-cell-hyperpolarizing phase, the Vm are still corelated with the (still-firing) complex cells, but not time-shifted! (tghough still sometimes asymmetric. see pair 10)</p>
<p>- CONCLUSION: The functional coupling between simple and complex cells is caused by the CORRELATED FIRING of many simple cells.</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gross1992-ua,
title = "Representation of Visual Stimuli in Inferior Temporal Cortex [and Discussion]",
author = "Gross, Charles G and De Schonen, S",
journal = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
volume =  335,
number =  1273,
pages = "3--10",
year =  1992,
annote = "<p>A review of what is known about IT cell selectivity, in particular with regard to face processing  / face recognition, in early 1992.</p>
<p> </p>
<p>Note: ``In anaesthetized animals, the cortico-cortical input is necessary and sufficient for the visual properties of IT <br />cells. However, in the awake animal, input from the <br />tecto-pulvinar system may be important for modulation <br />of attention and receptive field size''</p>
<p> </p>
<p>From the same seminar as Rolls 1992.</p>"
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rolls1992-hx,
title = "Neurophysiological mechanisms underlying face processing within and beyond the temporal cortical visual areas [and discussion]",
author = "Rolls, Edmund T and Cowey, A and Bruce, V",
journal = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
volume =  335,
number =  1273,
pages = "11--21",
year =  1992,
annote = "<p>A description of known properties of IT neurons, in particular face selective neurons.</p>
<p>Lots of talk about modelling. The suggestions are very similar to what I do. In particular, it seems to duggest an Instar rule, within a competitive network, and (seprately) with trace.</p>
<p>From the same seminar as Gross 1992.</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Szabo2006-dq,
title = "Learning to Attend: Modeling the Shaping of Selectivity in Infero-temporal Cortex in a Categorization Task",
author = "Szabo, Miruna and Stetter, Martin and Deco, Gustavo and Fusi, Stefano and Giudice, Paolo Del and Mattia, Maurizio",
journal = "Biol. Cybern.",
volume =  94,
number =  5,
pages = "351--365",
month =  "23~" # mar,
year =  2006,
annote = "<p><strong style=``font-weight:normal;''><span style=``font-size:15px;font-family:Arial;color:\#333333;background-color:\#ffffff;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;''>IT neurons can adapt their tuning depending on task. E.g. if you ask a monkey to categorize two sets of faces, IT will increase their tuning to the diagnostic feature (even if it is actually a combination of features?), so that their firing will correlate more to the diagnostic features than the non-diagnostic ones after training. Probably dependent on feedback - perhaps from PFC.</span></strong></p>
<p> </p>
<p><span style=``font-size:15px;font-family:Arial;color:\#333333;background-color:\#ffffff;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;''>Feedback must learn to target the proper cells. </span></p>
<p><strong style=``font-weight:normal;''></strong></p>
<p><strong style=``font-weight:normal;''><span style=``font-size:15px;font-family:Arial;color:\#333333;background-color:\#ffffff;font-weight:normal;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;''>This is a model. Original result is in Sigal and Logothetis Nature 2002.</span></strong></p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Meyers2008-nf,
title = "Dynamic population coding of category information in inferior temporal and prefrontal cortex",
author = "Meyers, Ethan M and Freedman, David J and Kreiman, Gabriel and Miller, Earl K and Poggio, Tomaso",
affiliation = "Department of Brain and Cognitive Sciences, MIT, Cambridge, MA 02139, USA. emeyers@mit.edu",
abstract = "Most electrophysiology studies analyze the activity of each neuron separately. While such studies have given much insight into properties of the visual system, they have also potentially overlooked important aspects of information coded in changing patterns of activity that are distributed over larger populations of neurons. In this work, we apply a population decoding method to better estimate what information is available in neuronal ensembles and how this information is coded in dynamic patterns of neural activity in data recorded from inferior temporal cortex (ITC) and prefrontal cortex (PFC) as macaque monkeys engaged in a delayed match-to-category task. Analyses of activity patterns in ITC and PFC revealed that both areas contain ``abstract'' category information (i.e., category information that is not directly correlated with properties of the stimuli); however, in general, PFC has more task-relevant information, and ITC has more detailed visual information. Analyses examining how information coded in these areas show that almost all category information is available in a small fraction of the neurons in the population. Most remarkably, our results also show that category information is coded by a nonstationary pattern of activity that changes over the course of a trial with individual neurons containing information on much shorter time scales than the population as a whole.",
journal = "J. Neurophysiol.",
volume =  100,
number =  3,
pages = "1407--1419",
month =  sep,
year =  2008,
annote = "<p>Dog vs Cat categorization task in IT and PFC. There is strong category information in IT and PFC - even during delay and decision periods (note that there is nothing on the screen during delay period).</p>
<p> </p>
<p>Of course category information in IT during stimulus presentation is influenced by the fact that there is strong identity information about the presented stimulus in IT (but much less so in PFC!). But even if you use some ``abstract-category decoding'' method (by testing on the response to morphed stimuli, but training on the response to different prototype stimuli that were *not* used to generate the morphs) you still get ``ABSTRACT CATEGORY'' information in both PFC (much) and IT (less). Category information about the SAMPLE -STIMULUS in IT is quite strong during the DECISION-STIMULUS response phase - even in non-match trials?</p>
<p> </p>
<p>More importantly, this information depends on a small number of highly informative neurons (eg 25\% of the neurons do all the work).</p>
<p> </p>
<p>Even more importantly, the code / neural selectivities are changing all the time, and you can't decode well time t+N by training on time t (though you still can, a little bit). This suggests that neural selectivities often have time windows, that are time-locked to stimulus onset. </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Swaminathan2012-as,
title = "Preferential encoding of visual categories in parietal cortex compared with prefrontal cortex",
author = "Swaminathan, Sruthi K and Freedman, David J",
journal = "Nat. Neurosci.",
volume =  15,
number =  2,
pages = "315--320",
month =  "15~" # jan,
year =  2012,
annote = "<p>LIP cells encode category information about a visual motion direction categorization task. So does PFC. But LIP cells have stronger, earlier signal. Also predict behavior much better when the stimulus is ambiguous (just on the boundary).</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Freedman2006-jv,
title = "Experience-dependent representation of visual categories in parietal cortex",
author = "Freedman, David J and Assad, John A",
journal = "Nature",
volume =  443,
number =  7107,
pages = "85--88",
month =  "27~" # aug,
year =  2006,
annote = "<p>The original paper on categorization of visual motion by LIP neurons. Shows that neurons change their categorization after re-training.</p>
<p> </p>
<p>Says that contrarily to LIP, MT is perfect at discriminating stimulus orientation (LIP is just very good), but very bad at discriminating category.</p>
<p> </p>
<p>Category discrimination is based on ratio between Within-Category and Between-Category average difference in firing rate (controlling for angular distance) (see included supplementary material in Word format).</p>
<p> </p>"
}

@ARTICLE{Cook_undated-ao,
title = "Categorical Representation of Visual Stimuli in the Primate Prefrontal Cortex",
author = "Cook, N Duncan and Emme, M and Fanton, J and Hall, A and Hewitson, L and Jacob, D and Jacoby, E and Lewis, A and Luetjens, C M and Machida, C",
annote = "<p>The original cat vs dog categorization paper. Shows that PFC is category-selective (as opposed to just stimulus selective) for this categorization.</p>"
}

@PHDTHESIS{Leibo2013-qn,
title = "The Invariance Hypothesis and the Ventral Stream",
author = "Leibo, Joel Zaidspiner",
year =  2013,
school = "Massachusetts Institute of Technology"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Field1987-td,
title = "Relations between the statistics of natural images and the response properties of cortical cells",
author = "Field, David J",
journal = "J. Opt. Soc. Am. A",
volume =  4,
number =  12,
pages = "2379--2394",
year =  1987,
annote = "<p>The simple cells have properties (e.g. relationships b/w frequency and spatial extent and orientation/frequency bandwidth) that make them differ from local PCA/ Fourier.</p>
<p> </p>
<p>They do NOT extract the main components, in which all the energy is represented into a few components so we can discard the rest. Instead, they change the inputs into a sparse code (doesn't use the term 'sparse', but that's it): the energy *at any time* is contained in a few components, but over long time all components are equally active.</p>
<p> </p>
<p>Thus the simple cells/ Gabor functions do not reduce redundancy: they convert second-order redundancy (non-uniform correlations) into first-order (non uniform actual outputs). Images have high second-order redundancy, because of correlations between pixels; but they have very low first-order redundancy, because they have roughly uniform pixel distribution. The output of Gabor cells is the opposite: uncorrelated outputs, with a very non-uniform distribution.</p>
<p> </p>
<p>In Barlow terms (the goal of the sensory system is to reduce redundancy), simple cells don't reduce redundancy themselves, but allow for a later, higher stage to produce a low-redundancy code, by only coding the (rare) highly active components!</p>
<p> </p>
<p>Explains 1/f noise / 1/f spectrum 1/f statistics as a necessity to preserve energy ratio between scales?</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Adesnik2012-wd,
title = "A neural circuit for spatial summation in visual cortex",
author = "Adesnik, Hillel and Bruns, William and Taniguchi, Hiroki and Huang, Z Josh and Scanziani, Massimo",
journal = "Nature",
volume =  490,
number =  7419,
pages = "226--231",
month =  "10~" # oct,
year =  2012,
annote = "<p>- SOM cells in layer 2/3 of mouse visual cortex seem massively implicated in surround suppression.</p>
<p> </p>
<p>- SOM cells receive primarily LATERAL excitation, not much feedforward excitation, in contrast to PV cells, who do receive a lot of FEEDFORWARD excitation.</p>
<p> </p>
<p>-If you only excite loval Pyramidal cells, SOM receive much more additional excitation than (not-photostimulated?) Pyramidal cells (250\%); also, you see a lot of disynaptic inhibition in Pyramidals, but almost none in SOM. (slice results).</p>
<p> </p>
<p> </p>
<p>- You can do ``surround suppression'' of Pyramidals directly in cortex by optogenetics / photostimulation. Extending the size of stimulated area increases SOM cells, and depresses (non-photostimulated) Pyramidals (and also increase their inhibition).</p>
<p>- If you silence the SOMs, Pyramidals inhibition goes down by 80\% (but which percentage of *increase* in inhibition as you extend stimulation does?).</p>
<p> </p>
<p>- Anesthesia reduces surround suppression - and also reduces SOM activity tenfold.</p>
<p> </p>
<p>- Photo-hyperpolarization of (70\% of) SOM cells reduces surround suppression index of Pyramidals by 30\% (no effect on baseline firing rates). Stimuli smaller than maximum-response size not facilitated; stimuli larger than that facilitated by ~74\%.</p>
<p> </p>
<p>Still a fair amount of suppression remaining...</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kerlin2010-bp,
title = "Broadly Tuned Response Properties of Diverse Inhibitory Neuron Subtypes in Mouse Visual Cortex",
author = "Kerlin, Aaron M and Andermann, Mark L and Berezovskii, Vladimir K and Reid, R Clay",
journal = "Neuron",
volume =  67,
number =  5,
pages = "858--871",
month =  "9~" # sep,
year =  2010,
annote = "<p>- In MOUSE L2/3 visual cortex, Inhibitory neurons are very broadly tuned to orientation and frequency (excitatory neurons, by contrast, are almost always tuned, most of them strongly).</p>
<p> </p>
<p>- All inhibitory neurons subtypes are similarly broad-tuned: PV, SOM, VIP.</p>
<p> </p>
<p>- Problem for the Rudiger (Bednar lab) model that assumes strongly tuned SOM?</p>
<p> </p>
<p>- But it's mouse! There's no orientation maps! The Harris and Flogel review in Nature points out that PV interneurons are tuned for map-forming features (orientations in primates+carnivorans, space in rodents), but unselective or broadly tuned to non-mapped features such as orientation in rodents!</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Adesnik2010-sf,
title = "Lateral competition for cortical space by layer-specific horizontal circuits",
author = "Adesnik, Hillel and Scanziani, Massimo",
journal = "Nature",
volume =  464,
number =  7292,
pages = "1155--1160",
month =  "22~" # apr,
year =  2010,
annote = "<p>- Main message: exciting Pyramidal cells in layer 2/3 SUPPRESSES other layer 2/3 pyramidals, but FACILITATES layer 5 Pyramidals (mostly within the same barrel, but extending over two barrels).</p>
<p> </p>
<p>- This is despite the fact stimulating layer 2/3 cells generates inhibition and excitation over exactly the same range (laterally and vertically), in both layer 2/3 and layer 5 (but no effect in 4 or 6).</p>
<p> </p>
<p>- The cause is that, although exciting layer 2/3 pyramidals causes the SAME increase in excitation in L2/3 and L5, it causes MORE inhibition in L2/3. As a result, the ratio of excitation to inhibition is higher in L5 than in L2/3, resulting in activation rather than suppression.</p>
<p> </p>
<p>- This is not due to special properties of L5 vs L2/3 cells, since if you replay the same waveforms to both cells, you get the same effects (!)</p>"
}

@ARTICLE{Wilson2012-um,
title = "Division and subtraction by distinct cortical inhibitory networks in vivo",
author = "Wilson, Nathan R and Runyan, Caroline A and Wang, Forea L and Sur, Mriganka",
journal = "Nature",
volume =  488,
number =  7411,
pages = "343--348",
month =  "8~" # aug,
year =  2012
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Harris2013-gr,
title = "Cortical connectivity and sensory coding",
author = "Harris, Kenneth D and Mrsic-Flogel, Thomas D",
journal = "Nature",
volume =  503,
number =  7474,
pages = "51--58",
month =  "6~" # nov,
year =  2013,
annote = "<p>- Great review of cortical connectivity - circuits - coding</p>
<p> </p>
<p> -[UPDATE 31 dec 2013: The idea that local PV neurons integrate the responses of their neighbours in MICE is confirmed by Runyan and Sur J Neurosci 2013, who show also that the fraction of highly-tuned PV neurons in mice are those that have short dendritic trees - though pprobably layer 2/3 only?]</p>
<p> - [Update 5 Dec 2014: But Tan et al (Priebe) J Neurosci 2011 say that inhib inputs is just as tuned as excitatory inputs? Does this separate FF and lateral inputs though? They themeslves say that ``inhibitory neurons in mouse V1 are weakly selective for orientation compared to excitatory neurons]</p>
<p>- Connections between cells depends on cell type (great schema of cortical connectivity across layers in box 1)</p>
<p> </p>
<p>- L5 is divided in two sub-layers, one projecting to the cortex AND striatum (regular spiking) and one projecting to sub-cerebral motor centres (even in primary sensory areas), with collaterals to striatum and thalamus with large, strong 'driving' synapses, and can drive movement (bursting).</p>
<p> </p>
<p>- Also, principal cells that share common inputs are more likely to be connected with each other</p>
<p> </p>
<p>- Not the case with interneurons, with ~ 100\% connection to neighbouring principal cells (at least for PV and SOM)</p>
<p>- Also, principal cells selective for the same features are more likely to be connected with each other, even at small scale (and of course in visual cortex also at long ranges).</p>
<p>- These are probabilities, not absolute rules (not all neurons receiving common inputs / responding to same features are connected, and vice versa).</p>
<p> </p>
<p>- Principal cell's lateral excitatory input is tuned similarly to their thalamic input (at least w/ sound frequency or orientation)! So may be difficult to distinguish the two.</p>
<p> </p>
<p>- Possible causes for coherent networks: 1- response amplification / noise reduction 2- prolongation of sensory responses 3- integration of features between overlapping sub-networks, allowing whole network to respond differentially to combinations of features (but if Bathellier is right that sub-networks are in competition, not so much).</p>
<p> </p>
<p>- What explains the patterns of connectivity? Part may be development: sister cells tend to be mutually connected and share similar tuning. But much of the preferential connectivity occurs after eye opening. May be Hebbian.</p>
<p> </p>
<p>- L2/3 principal cells have sparse firing: very low(<1Hz in rodents) and highly selective. Probably caused by lots of inhibition - exciting L2/3 cells causes mostly inhibition in nearby cells. </p>
<p>- L5 principal cells fire strongly and respond in graded manner to broad ranges of stimuli (5-15Hz). L5 receive a lot of thalamic+cortical inputs and less inhibition. Exciting L5 causes self-sustaining firing!</p>
<p>- For interneurons, much modulation by behavior. PV cells, at least, receive unspecific inputs from all local PCs, and seem to be tuned to average local tuning.</p>
<p> </p>
<p>- Orientation maps in visual ctx of carnivorans and primates, but not rodents (even highly visual rodents like squirrels). Might be simply due to their small brain size!</p>
<p>- Consequence: sub-threshold input to visual cortex PCs in rodents is broadly tuned for orientation, but sharper tuning in primates or rodent auditory cortex. Also V1 sub-threshold tuning in carnivorans is broader near pinwheels.</p>
<p>- Nevertheless, PC firing can be highly tuned for non-mapped features.</p>
<p> </p>
<p>- PV interneurons are only selectively tuned to mapped features.</p>
<p>- Broad inhibition plays a role in maintaining PC selectivity near pinwheels or for unmapped features.</p>
<p> </p>
<p>- At small scales, only a small number of all possible firing patterns do actually occur - highly redundant coding (high MI between cells' firings).</p>
<p>- Correlations (though weak) seem to be consequence of wiring and likely correspond to the subnetworks discussed previously (though not proven).</p>
<p> </p>
<p>- These wasteful correlations may be thee for 1- higher robustness of the code (especially in readout due to only fractional sampling of any given area by higher neurons) and 2- preferentially encoding the most relevant features with more neurons</p>
<p> </p>
<p>- Even in primary cortex, neurons integrate behavioral signals.</p>
<p> </p>
<p>- Top-down input falls mostly on L1 interneurons and apical dendrites - the latter increasing gain / multiplicative!</p>
<p> </p>
<p>- In whisking, top-down motor cortex input excite selectively barrel VIP cells, disinhibiting PCs! By contrast, locomotion increases SOM in visual cortex. (All this in superficial).</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ko2011-ss,
title = "Functional specificity of local synaptic connections in neocortical networks",
author = "Ko, Ho and Hofer, Sonja B and Pichler, Bruno and Buchanan, Katherine A and Sj{\"{o}}str{\"{o}}m, P Jesper and Mrsic-Flogel, Thomas D",
journal = "Nature",
volume =  473,
number =  7345,
pages = "87--91",
month =  "10~" # apr,
year =  2011,
annote = "<p>- In layer 2/3 lateral connections between Pyramidals, cells that fire together really do wire together! (even at very small scales, in calcium imaging)</p>
<p> </p>
<p>- Did NOT find evidence of stronger connection for similar cells - only binary connected/non-connected </p>
<p> </p>
<p>- Cells with similar preferred orientation 2x more likely to be connected than with orthogonal orientation (10/26 to 4/24) (consistent with broad sub-threshold, narrow suprathreshold orientation tuning in mouse V1)</p>
<p> </p>
<p>- Orientation-Selective / movie-responsive neurons more likely to be connected than non-responsive/non-selective ones (25/94 vs 3/31...)</p>
<p>- Cells with similar reponse to natural stimuli were much more likely to be connected (coorelation <.05: 5/44, >.15: 13/26). But connection strength (EPSP amp, paired-pulse ratio) did not change significantly with correlation...</p>
<p> </p>
<p>- Connectivity also indicated by noise correlations in response to successive presentations of movie.</p>
<p> </p>"
}

@ARTICLE{Freiwald2010-by,
title = "Functional Compartmentalization and Viewpoint Generalization Within the Macaque {Face-Processing} System",
author = "Freiwald, W A and Tsao, D Y",
journal = "Science",
volume =  330,
number =  6005,
pages = "845--851",
month =  "4~" # nov,
year =  2010
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hubel1968-ik,
title = "Receptive fields and functional architecture of monkey striate cortex",
author = "Hubel, David H and Wiesel, Torsten N",
journal = "J. Physiol.",
volume =  195,
number =  1,
pages = "215--243",
year =  1968,
annote = "<p>- The H\&W paper on macaque monkey (came after the one on cat).</p>
<p> </p>
<p>- Most important for me: There is no strict columnar organization of retinotopy at the  microscopic scale, rather the spatial position is roughly continuous with large random ``jitter'' superimposed on slow progression of RFs. It is on this continuous spatial background that orientation and ocular dominance column, which are real and clear, are embedded (p. 229-230).</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Espinosa2012-nw,
title = "Development and plasticity of the primary visual cortex",
author = "Espinosa, J Sebastian and Stryker, Michael P",
affiliation = "Center for Integrative Neuroscience, Department of Physiology, 675 Nelson Rising Lane, University of California, San Francisco, San Francisco, CA 94143-0444, USA.",
abstract = "Hubel and Wiesel began the modern study of development and plasticity of primary visual cortex (V1), discovering response properties of cortical neurons that distinguished them from their inputs and that were arranged in a functional architecture. Their findings revealed an early innate period of development and a later critical period of dramatic experience-dependent plasticity. Recent studies have used rodents to benefit from biochemistry and genetics. The roles of spontaneous neural activity and molecular signaling in innate, experience-independent development have been clarified, as have the later roles of visual experience. Plasticity produced by monocular visual deprivation (MD) has been dissected into stages governed by distinct signaling mechanisms, some of whose molecular players are known. Many crucial questions remain, but new tools for perturbing cortical cells and measuring plasticity at the level of changes in connections among identified neurons now exist. The future for the study of V1 to illuminate cortical development and plasticity is bright.",
journal = "Neuron",
volume =  75,
number =  2,
pages = "230--249",
month =  "26~" # jul,
year =  2012,
annote = "<p>- Rodents don't have columns at all! They do have strongly selective cells, both simple and complex. They also have retinotopy, just with larger RFs.</p>
<p> </p>
<p>- [From another paper: in rodents, orientation selectivity starts in the LGN!]</p>
<p> </p>
<p>- Mice don't have ocular dominance columns either, but they do have single-neuron ocular dominance and plasticity of it in critical period.</p>
<p> </p>
<p>- The functional subnetwork of Mrsic-Flogel also exist in rodents! So they are not just columns.</p>
<p> </p>
<p>- Topographic thalamocortical (LGNd-V1) connections established prenatally. Seems to depend partly on spontaneous activity / neural/retinal waves initiated by ACh.</p>
<p> </p>
<p>- Selective RFs and orientation columns also are made prenatally, though this may simply reflect the few inputs. Responses and selectivity increase even in blind animals up to critical period onset. Dependent on cortical activity, however!</p>
<p> </p>
<p>- OTOH prolonged dark rearing after CP leads to loss of selectivity.</p>
<p> </p>
<p>- Striped goggles lead to loss of selectivity in neurons of orientation not congruent with stripes. However some neurons may also have their selectivity changed, in a study on mice.</p>
<p>- In ferret and cat, but not mice, direction maps are absent at eye opening and highly labile/dependent on experience to appear.</p>
<p> </p>
<p>- Monkey v1 is born much more mature than cats. OD columns in utero. In cats, OD columns start around day 7 and blocking retina on day 14 (after eye opening, before CP) destroys OD columns.</p>
<p> </p>
<p>- In cat, after OD columns formed, binocular deprivation has no effect on OD until CP. If you maintain deprivation during CP, responses to BOTH eyes deteriorate.</p>
<p>- In mice, before CP , neurons are already binocular (prefer contra) but commonly have different orientation selectivity for both eyes! CP ``matches'' the OS for both eyes, but only if w/ normal experience.</p>
<p> </p>
<p>- Monocular deprivation of newborn kittens for 1 month -> 83/84 cells become unresponsive to deprived eye. Almost no effect on LGN! Also occurs if you just blur one eye. This is despite 8d kittens having binocular neurons, and binocular deprivation for 4months still having >50\% binocular! Conclusion: MD effect is through *competitive* *loss* of inputs from deprived eye connections, not just disuse.</p>
<p> </p>
<p>- If forcing strabismus or alternating occlusion of both eyes, binocular cells disappear!</p>
<p> </p>
<p>- This is only if monoc depriv occurs during CP - anytime b/w w4 and w8.</p>
<p> </p>
<p>- Reflected in anatomy: contraction of deprived eye thalamocotrical projections!</p>
<p> </p>
<p>- CP is not the same for all (sub-)layers of V1, and CP for OD outlasts CP for thalamocortical projections!</p>
<p> </p>
<p>- Also occurs in mice in much the same way, except cell-by-cell.</p>
<p> </p>
<p>- Potent GABA inhibition is necessary to start CP. Deprivation / darkness delays CP.</p>
<p> </p>
<p>- Effects of MD include both immediate loss of response to deprived eye (pharmacology similar to LTD, though dependent on protein synthesis) AND both LTP and homeostatic increase of response to non-deprived (uh... how do you differentiate the two? - well, homeostatic because responses to deprived eye also occur in neurons that don't receive inputs from open eye! As for LTP, NMDAR dependence) , after a 3-day delay.</p>
<p> </p>
<p> - Homeostatic scaling of synapses / synpatic scaling seems to be widely accepted and even pharmocologically characterized (in part)!</p>
<p>- If you reopen the eye quickly enough during CP, responses go back to normal, which is caused by neurotophic growth signalling.</p>
<p> </p>
<p>- Though CP ends at adolescence, ODP tapers slowly and lingers well into maturity. In mice, becomes insignificant by d110 (adult: d60-d90). However, adult ODP is both more difficult and less permanent and also only involves increase in response to non-deprived eye (with only small and fleeting reduction of deprived eye response).</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Corey2012-dw,
title = "Cortical Selectivity through Random Connectivity",
author = "Corey, J and Scholl, B",
journal = "Journal of Neuroscience",
volume =  32,
number =  30,
pages = "10103--10104",
month =  "25~" # jul,
year =  2012,
annote = "<p>- Journal Club article for Hansel and van Vreeswijk, The mechanism of orientation selectivity in primary visual cortex without a functional map, J NEurosci 2012.</p>
<p> </p>
<p>- Even when your inputs have all possible selectivities, you can still get highly selective response!</p>
<p> </p>
<p>- That's because in the balanced excitation and inhibition state, the large untuned component of both excitation and inhibition cancel each other.</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hansel2012-yq,
title = "The Mechanism of Orientation Selectivity in Primary Visual Cortex without a Functional Map",
author = "Hansel, D and van Vreeswijk, C",
journal = "Journal of Neuroscience",
volume =  32,
number =  12,
pages = "4049--4064",
month =  "21~" # mar,
year =  2012,
annote = "<p>- See also: The mechanism of orientation selectivity in primary visual cortex without a functional map (commentary / Journal Club article in the Zotero library).</p>
<p> </p>
<p> </p>
<p>- Even when your inputs have all possible selectivities, you can still get highly selective response!</p>
<p> </p>
<p>- That's because in the balanced excitation and inhibition state, the large untuned component of both excitation and inhibition cancel each other.</p>
<p> </p>
<p> - I don't understand the model... It seems to be a spiking model with lots of stuff baked into it....</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hubel1977-ek,
title = "Ferrier lecture: Functional architecture of macaque monkey visual cortex",
author = "Hubel, David H and Wiesel, Torsten N",
journal = "Proceedings of the Royal Society of London. Series B, Biological Sciences",
pages = "1--59",
year =  1977,
annote = "<p>- In Layer 4C (but not in other layers), you DO have a (jittery, but still observable) topographic progression of RFs across successive minicolumns!</p>
<p> </p>
<p>- The drift rate is the same as for superficial layers, but in superficial layers it is obscured by the scatter of the large RFs (you need ~2 mm of cortical distance to actually obtain clearly separate RFs)</p>
<p> </p>
<p>- When crossing between ocular domains, the RF topography ``jumps back'' by half the distance covered over the previous ocular domain! Thus both eyes see the entire visual field, with 1/2 overlap between ocular bands.</p>
<p> </p>
<p>- There is cross-talk between columns for ocular source (because layer 4c is monocular, but others aren't, and possibly for position (because larger RFs in non-l4 RFs), but not for orientation?...</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Da_Costa2010-dl,
title = "Whose cortical column would that be?",
author = "da Costa, Nuno Ma\c{c}arico",
journal = "Front. Neuroanat.",
year =  2010,
annote = "<p>- Even the proximal cluster of axonal boutons of a given layer 2/3 neurons extends over nearly 1mm diameter.</p>
<p> </p>
<p>- Cortical ``daisies''/daisy: The distal clusters (where many axons converge) extend over several mm and seem to connect like with like, but are NOT seen in rodents, but in pretty much all other areas of other species...</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Paik2011-um,
title = "Retinal origin of orientation maps in visual cortex",
author = "Paik, Se-Bum and Ringach, Dario L",
journal = "Nat. Neurosci.",
volume =  14,
number =  7,
pages = "919--925",
month =  "29~" # may,
year =  2011,
annote = "<p>- Retinal ganglion cells form separate, independent hexagonal lattices for ON-center and OFF-center cells.</p>
<p> </p>
<p>- Two hexagonal lattice of slightly different orientations interact to create an orientation map with pinwheels at the vertex of a hexagonal lattice.</p>
<p> </p>
<p>- Hexagonal distribution of pinwheels apparently confirmed in multiple species.</p>
<p> </p>
<p>- If the angle between the two original lattice is right, the resulting orientation map is actually not a map at all but completely 'salt-and-pepper'!</p>
<p> </p>
<p>- (In the discussion: during development, LGN RFs show various phases, including orientation-selective ones...)</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Branco2010-oe,
title = "Dendritic Discrimination of Temporal Input Sequences in Cortical Neurons",
author = "Branco, T and Clark, B A and Hausser, M",
journal = "Science",
volume =  329,
number =  5999,
pages = "1671--1675",
month =  "12~" # aug,
year =  2010,
annote = "<p>- Dendrites are more activated if they receive a sequence of synaptic inputs going INTO the dendrite (towards soma) than OUT OF the dendrite. Raises probability of spike by ~38\% (for a single dendrite!)</p>
<p> </p>
<p>- NMDAR / voltage dependent</p>
<p> </p>
<p>- Unfortunately, optimal time course seems to be over ~2/3 ms for a single dendrite. Not good enough for direction selectivity in V1 ells (...?)</p>
<p> </p>
<p>- Can also differentiate more arbitrary patterns of inputs.</p>
<p> </p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Morita2009-cy,
title = "Computational implications of cooperative plasticity induction at nearby dendritic sites",
author = "Morita, Kenji",
journal = "Sci. Signal.",
volume =  2,
number =  52,
pages = "e2",
year =  2009,
annote = "<p>- Synaptic plasticity is *mostly* synapse-specific.</p>
<p> </p>
<p>- However, nearby synapses can influence the onset of plasticity in each other.</p>
<p> </p>
<p>- This results in still-unclear self-organizing map dynamics within the dendritic trees of single neurons!</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Jin2011-ye,
title = "Population receptive fields of {ON} and {OFF} thalamic inputs to an orientation column in visual cortex",
author = "Jin, Jianzhong and Wang, Yushi and Swadlow, Harvey A and Alonso, Jose M",
journal = "Nat. Neurosci.",
volume =  14,
number =  2,
pages = "232--238",
month =  "9~" # jan,
year =  2011,
annote = "<p>- If you reconstruct the RFs of the LGN cells that connect to a whole orientation column, and sum them *with* polarity (ON - OFF), you gett the orientation of the column.</p>
<p> </p>
<p>- Most bizarre consequence (they only say it at the very end): a whole orientation column has a single (or at least a main) phase! [Hmm, could just be a few nearby phases, e.g. phase quadrature?]</p>
<p> </p>
<p>- The most important result IMO is that you can also reconstruct orientation preference, though much less well, by looking at neighboring and NOT connected LGN cells. This is really indicative of a constraint imposed by the (mild) ON/OFF segregation in LGN.</p>
<p> </p>
<p>- I'm not sure that their main result imposes such a constraint - it might simply be that the orientation column cells choose which LGN cells they want to connect to. They explicitly exclude neurons that do send an axon to the orientation column but is not monosynaptically connected.</p>"
}

@ARTICLE{Izhikevich2008-rb,
title = "Large-scale model of mammalian thalamocortical systems",
author = "Izhikevich, Eugene M and Edelman, Gerald M",
journal = "Proceedings of the national academy of sciences",
volume =  105,
number =  9,
pages = "3593--3598",
year =  2008
}

@ARTICLE{Hirsch2003-ri,
title = "Synaptic physiology and receptive field structure in the early visual pathway of the cat",
author = "Hirsch, Judith A",
journal = "Cereb. Cortex",
volume =  13,
number =  1,
pages = "63--69",
year =  2003
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Monier2003-ui,
title = "Orientation and direction selectivity of synaptic inputs in visual cortical neurons: a diversity of combinations produces spike tuning",
author = "Monier, Cyril and Chavane, Fr\'{e}d\'{e}ric and Baudot, Pierre and Graham, Lyle J and Fr\'{e}gnac, Yves",
journal = "Neuron",
volume =  37,
number =  4,
pages = "663--680",
year =  2003,
annote = "<p>- Across cells, inhibition and excitation seem equally likely to be tuned? (Figure 5, blue/red)</p>
<p> </p>
<p>- For most cells (10/16), inhibition (inhibitory conductances) is tuned with the same orientation preference (but opposite phase) as excitation and spikes</p>
<p> </p>
<p>- For several cells, either inhibition or both inhibition and excitation are tuned to a different orientation than spiking.</p>
<p> </p>
<p>- Only cells with iso-oriented inhibition and excitation have strong direction selectivity!!</p>
<p> </p>
<p>- Distinction between ``inhibition'' and the ``hyperpolarizing component'' (shunting / divisive?...)</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kullmann_undated-pf,
title = "Plasticity of Inhibition",
author = "Kullmann, Dimitri M and Moreau, Alexandre W and Bakiri, Yamina and Nicholson, Elizabeth",
journal = "Neuron",
volume =  75,
number =  6,
pages = "951--962",
annote = "<p>- Review of the plasticity of inhibition, both in gabaergic synapses and glutamatergic synapses onto inhibitory neurons</p>
<p> </p>
<p>- Some subclasses of interneurons get transiently suppressed when their pyramidal target is depolarized - Depolarization-mediated Suppression of Inhibition (DSI) lasts < 5min (?) - endocannabinoids involved</p>
<p> </p>
<p>- In Hippocampus, inhibitory LTD (iLTD) similarly occurs when incoming inhibition coincides with firing - reducing the inhibitory synapses.</p>
<p>- In neocortex, ``Pairing 50 Hz trains of action potentials in individual fast-spiking neurons with subthreshold depolarization of postsynaptic layer 4 pyramidal neurons elicits a postsynaptically expressed LTP of GABAergic transmission''</p>
<p> </p>
<p>- ... It's complicated!</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Priebe2005-ku,
title = "Direction selectivity of excitation and inhibition in simple cells of the cat primary visual cortex",
author = "Priebe, Nicholas J and Ferster, David",
journal = "Neuron",
volume =  45,
number =  1,
pages = "133--145",
year =  2005,
annote = "<p>- Intra-cellular study of direction selectivity in simple cells of cat v1</p>
<p> </p>
<p>- Show that the feedforward  spatiotemporal RF to direction-selective cells is slanted, with inhibitory and excitatory regions, both for ON and OFF (light and dark) stimuli.</p>
<p>- Push-pull, like for orientation selectivity (they cite references for this): the inhibitory zones of the ON stimuli correspond to excitatory zones of the OFF stimuli, and vice versa.</p>
<p>- Also applies to the RF of the incoming excitation and inhibition, taken separately!</p>
<p> </p>
<p>- The RF actually look ``step-like'' rather than smoothly slanted. Margaret Livingstone's commentary ties this to a simple model of direction selectivity, based on combining the onset and offset responses of cells of opposite polarity, with a small delay.</p>
<p> </p>
<p>- NOTE: in mice, completely different stuff seems to happen - e.g. inhibition and excitation are NOT in anti-phase, but in phase! Tan et al., J Neurosci 2013</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Livingstone2005-lo,
title = "Directional Inhibition: A New Slant on an Old Question",
author = "Livingstone, Margaret S",
abstract = "In this issue of Neuron, Priebe and Ferster describe the direction selectivity and spatiotemporal organization of excitatory and inhibitory inputs to direction-selective simple cells in cat visual cortex. Their most surprising finding is that inhibition shows the same preferred direction as excitation.",
journal = "Neuron",
volume =  45,
number =  1,
pages = "5--7",
month =  "6~" # jan,
year =  2005,
annote = "<p>- Comments on Priebe and Ferster 2005</p>
<p> </p>
<p>- Suggests a model of direction selectivity proposed by Hubel and Wiesel in 1959 (!): combine the onset and offset responses of LGN cells of opposite polarity, with a small delay.</p>"
}

@ARTICLE{Vogels2013-vb,
title = "Inhibitory synaptic plasticity: spike timing-dependence and putative network function",
author = "Vogels, T P and Froemke, R C and Doyon, N and Gilson, M and Haas, J S and Liu, R and Maffei, A and Miller, P and Wierenga, C J and Woodin, M A and Zenke, F and Sprekeler, H",
journal = "Front. Neural Circuits",
volume =  7,
year =  2013
}

@ARTICLE{Mnih2013-tb,
title = "Playing Atari with Deep Reinforcement Learning",
author = "Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin",
journal = "arXiv preprint arXiv:1312.5602",
year =  2013
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hull_undated-zz,
title = "It's about time for thalamocortical circuits",
author = "Hull, Court and Scanziani, Massimo",
journal = "Nat. Neurosci.",
volume =  10,
number =  4,
pages = "400--402",
annote = "<p>- Review/comment on two articles, about thalamocortical targeting of inhibitory interneuronbs</p>
<p> </p>
<p>- In SS cortex of adult mice, TC synapses on PV are 4x stronger than on PCs</p>
<p>- In SS cortex of neonate mice:</p>
<ol><li>TC synapses on PV are weak</li>
<li>PV -> PC synapses are weak and sparse</li>
<li>GABA is depolarizing</li>
</ol><p>As a result, TC excited SS PCs, but without the strong FF inhibition typical of adults</p>
<p> </p>
<p>- This changes very quickly at P6-P7, where the FF inhibitory pathway becomes adult-like</p>
<p> </p>
<p>- Possible that the period of low inhibition allows for more plasticity, as shown by other studies and reviews (see zotero)</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Donato2013-fr,
title = "Parvalbumin-expressing basket-cell network plasticity induced by experience regulates adult learning",
author = "Donato, Flavio and Rompani, Santiago Belluco and Caroni, Pico",
journal = "Nature",
volume =  504,
number =  7479,
pages = "272--276",
month =  "11~" # dec,
year =  2013,
annote = "<p>- The PV cells network can spontaneously switch itself to a low-inhibition or a high-inhibition regime, modifying both PV expression and excitatory-to-inhibitory synapse density ratio!</p>
<p> </p>
<p>- Under environmental enrichment, or learning, switch to low-PV / low- inhibition network.</p>
<p> </p>
<p>- Learning: switch to low-PV, then back to high-PV once learning is complete!</p>
<p>- Under context-specific fear conditioning, switch to high-inhibition / high-PV network</p>
<p> </p>
<p>- Simply blocking / enhancing PV neurons pharmacologically suffices to reproduce these effects</p>
<p> </p>
<p>- Switch to low-PV involves increase of VIP boutons and connections onto PV cells (the ``disinhibition'' network?).</p>
<p> </p>
<p>- Because low-inhibition regime is a hallmark of high plasticity (e.g. in pre-critical period), this suggests the brain can spontaneously switch itself back into a plastic state!</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hasenstaub2010-kr,
title = "Paint It Black (or Red, or Green): Optical and Genetic Tools Illuminate Inhibitory Contributions to Cortical Circuit Function",
author = "Hasenstaub, Andrea R and Callaway, Edward M",
journal = "Neuron",
volume =  67,
number =  5,
pages = "681--684",
month =  "9~" # sep,
year =  2010,
annote = "<p>- UPDATE 31 dec 2013: CONTROVERSY RESOLVED? Runyan and Sur J Neurosci 2013 shows that the highly-tuned PV neurons are those with short dendritic trees. CONFIRM  that PV neurons seem to have orientation selectivity that is an AVERAGE of their neighbours!</p>
<p> </p>
<p>- Are PV interneurons broadly tuned, or just as sharply tuned as other neurons?</p>
<p> </p>
<p>- Known to have some amount of tuning in cats, but even there conflicting results.</p>
<p> </p>
<p>- (Schummers et al 2002: excitatory neurons have tuned inhibition in orientation domains, but not in pinwheels?? Actually says that subthreshold potential selectivity depends on pinwheel neighborhood, but spiking response selectivity does not and is well tuned everywhere)</p>
<p> </p>
<p>- Two studies (Runyan et al., Sur lab; Kerlin et al., Reid lab) used optical imaging IN MICE, targeting layer 2/3 PV neurons - but show apparently conflicting results</p>
<p> </p>
<p>- Runyan et al. : not just PV, but SOM and VIP are poorly tuned for orientation. Kerlin et al.: PV cells are just as tuned as other cells [NOTE: THIS IS PROBABLY SWITCHED!]</p>
<p>- Authors point out that not all PV+ cells are basket, or even inhibitory</p>
<p> </p>
<p>- Kerlin: PV, but not excitatory, seem to show tuning that is essentially an average of their neighbours</p>
<p> </p>
<p>- Unclear whether or not clacium imaging underestimates orientation tuning (by missing the low-firing, highly tuned neurons)</p>
<p> </p>
<p>- Note that the highly-tunes PV cells of Runyan had un-FS-like APs?</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lien2013-af,
title = "Tuned thalamic excitation is amplified by visual cortical circuits",
author = "Lien, Anthony D and Scanziani, Massimo",
journal = "Nat. Neurosci.",
volume =  16,
number =  9,
pages = "1315--1323",
month =  "11~" # aug,
year =  2013,
annote = "<p>- Layer 4 simple cells of mice</p>
<p> </p>
<p>- Silence cortex by activating PV population (optogenetically), then look at the EPSCs using voltage clamps, to isolate thalamic input</p>
<p> </p>
<p>- Result: thalamic incoming excitation usually consists of one ON and one OFF zone, largely overlapping, but spatially offset (~242 deg^2 each, overlap ~= 167 deg^2).</p>
<p> </p>
<p>- Discussion: subfields are 10deg wide, thalamic excitation RF is smaller than previously reported total excitation RF, suggesting that lateral input covers a wider total RF than FF input.</p>
<p> </p>
<p>- The arrangement of these ON and OFF excitatory zones predicts the orientation preference of the cell</p>
<p> </p>
<p>- Orientation and direction selectivity can be predicted from the orientation and direction selectivity of the F1 of this thalamic excitatory input</p>
<p> </p>
<p>- Total, time-averaged excitatory input  (F0) from thalamus in response to a moving grating is NOT orientation selective. However, F0 from cortical (lateral) inputs is orientation  and direction selective.</p>
<p> </p>
<p>- Thalamic F1 has almost same orientation, direction and phase preference as lateral F1 (for phase, there seems to be a small systematic effect: ~30deg / 48ms earlier).</p>
<p> </p>
<p>- Apparent conflict with Priebe and Ferster 2005, where excitatory inputs seem to be anti-correlated (peak of one is bottom of the other) ?.... But Priebe and Ferster is Cat, this is mouse. Tan et al. 2011 is in mouse, and shows that ge is actually in phase with gi !!</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tan2011-wi,
title = "Orientation Selectivity of Synaptic Input to Neurons in Mouse and Cat Primary Visual Cortex",
author = "Tan, A Y Y and Brown, B D and Scholl, B and Mohanty, D and Priebe, N J",
journal = "Journal of Neuroscience",
volume =  31,
number =  34,
pages = "12339--12350",
month =  "24~" # aug,
year =  2011,
annote = "<p>- In mouse V1 simple cells,, as opposed to cats/primates, the inhibition and excitation are IN PHASE (not push-pull)</p>
<p> </p>
<p>- Confirms the studies cited in mrsic-flogel reviewthat suggest that interneurons largely sample from their local environment, but.... only in mouse!</p>
<p> </p>
<p>- What explains the push pull pattrn in cats/primates?</p>
<p>-Disucssion: distinction between OS for membrane and for spike rate, spike rate always more selective.</p>
<p> </p>
<p>-  inputs are selective for both inhibition and excitation; less selective than spike rate.</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cardin2007-ct,
title = "Stimulus Feature Selectivity in Excitatory and Inhibitory Neurons in Primary Visual Cortex",
author = "Cardin, J A and Palmer, L A and Contreras, D",
journal = "Journal of Neuroscience",
volume =  27,
number =  39,
pages = "10333--10344",
month =  "26~" # sep,
year =  2007,
annote = "<p>- Find both simple and complex FS cells (putative interneurons) in layer 4 (and others) of cat v1.</p>
<p> </p>
<p>- All cells, RS or FS, simple or complex, across all layers, are tuned. In particular, all layer 4 complex FS cells were tuned (against Hirsch et al 2003) (n=9)</p>
<p> </p>
<p>- Only two cells out of hundreds had very broad tuning (>100deg HWHH)</p>
<p> </p>
<p>- claim 9 complex FS cells in layer 4, which indirectly should give</p>
<p> </p>
<p>- MOre generally across layers and types: FS are more broadly tuned for spiking response but not for Vm, have stronger faster Vm fluctuations</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Liu2009-cu,
title = "Intervening inhibition underlies simple-cell receptive field structure in visual cortex",
author = "Liu, Bao-Hua and Li, Pingyang and Sun, Yujiao J and Li, Ya-Tang and Zhang, Li I and Tao, Huizhong Whit",
journal = "Nat. Neurosci.",
volume =  13,
number =  1,
pages = "89--96",
month =  "29~" # nov,
year =  2009,
annote = "<p>- In mouse v1 layer 2/3, the actual excitatory and inhibitory  ON and OFF fields are all largely overlapping.</p>
<p> </p>
<p>BUT:</p>
<p> </p>
<p>Simple cells have offset excitatory fields for ON and OFF, but colocalized ON and OFF inhibitory fields, located right between the peaks of excitatory ON and OFF fields!</p>
<p> </p>
<p>Complex cells have colocated peaks for all 4 conditions.</p>
<p> </p>
<p>- As a result, inhibition sharpens the segregation between ON and OFF excitatory fields of simnple cells!</p>
<p> </p>
<p>- Without inhibition, ON and OFF spike responses are largely overlapping, but with inhibition they become segregated agin</p>
<p> </p>
<p>- Says that layer 4 cells only respond to one contrast?... Presumably some mouse specific thing?...</p>
<p> </p>
<p> </p>"
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Nassi2009-qp,
title = "Parallel processing strategies of the primate visual system",
author = "Nassi, Jonathan J and Callaway, Edward M",
journal = "Nat. Rev. Neurosci.",
volume =  10,
number =  5,
pages = "360--372",
month =  "8~" # apr,
year =  2009,
annote = "<p>- Review of the pathways through the visual system, from retina to IT and parietal!</p>
<p> </p>
<p>- Within V1, there is extensive recombination of the Magnocellular and Parvoicellular inputs; however, there is still clear distinction between the inputs to ventral system and dorsal system, through the various layers of V2</p>
<p> </p>
<p>- Layer 4Ca is M, 4Cb is P, and layer 4B is actually a projection layer that doesn't receive thalamic input (goes to V2 and MT)</p>
<p> </p>
<p>- Cell-type-specific projections: e.g. within 4B, only spiny stellates (not pyramidals) projwect to MT directly; also in layer 3B (but not 2/3A) the  pyramidals that actually project out of V1 are precisely the ones that don't receive any P input.</p>
<p> </p>
<p>- CO blobs are correlated with zones of incoming LGN inputs (despite being in layer 2/3), and  result from the higher neural activity in these zines?</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Peelen2013-ho,
title = "Nonvisual and Visual Object Shape Representations in Occipitotemporal Cortex: Evidence from Congenitally Blind and Sighted Adults",
author = "Peelen, M V and He, C and Han, Z and Caramazza, A and Bi, Y",
journal = "Journal of Neuroscience",
volume =  34,
number =  1,
pages = "163--170",
month =  "31~" # dec,
year =  2013,
annote = "<p>- Shape information in IT / Object-Selective Cortex of blind people! (though significance might be low, especially for individual-level as opposed to group-aerage comparisons)</p>
<p> </p>
<p>- First, compute ``shape similarity matrices'' between objects,  by asking people (blind and sighted) to explicitly rate the shape similarity. The matrices correlate just as highly between blind and sighted as between different sighted groups!</p>
<p> </p>
<p>- Then, tell names of objects to people and compute ``fMRI similarity matrices'' between named objects.</p>
<p> </p>
<p>- Group-average fMRI similarity matrices of both blind and sighted subjects correlate significantly with shape similarity matrices (less for blind but still pretty significant), in IT and OSC but not Occipital Cortex (Fig. 2).</p>
<p> </p>
<p>- When using individual-level matrices, becomes barely significant for the blind IT and fails significance (p=.06) for blind OSC... (Fig. 3)</p>
<p> </p>
<p>- Weird: the correlation between fMRI similarity matrices of blind and sighted participants, whether in IT, OSC or OC is much higher (~.25 for all) than correlation of any with shape similarity.... (.10-.17 for blind IT and sighted OSC resp.). Though this might just be a predictable effect of auditory-visual interactions with zero shape information...</p>
<p> </p>
<p>- Separate visual task for sighted participant in which they look at image of objects. Then there is shape similarity information in IT, but not OC, and vice-versa for pixelwise similarity information</p>
<p> </p>
<p>- The ``vision'' fMRI similarity matrix of sighted participants (with visual input) shows no correlation with the ``audio'' similarity matrix of blind participants... In contrast with the ``audio'' similarity matrix of sighted subjects, which does. Also, vision and audio matrices correlate among sighted.</p>
<p> </p>
<p>- Note that the task is to determine whether the named object is bigger or smaller than the palm of the hand...</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Li2012-cb,
title = "Broadening of Cortical Inhibition Mediates Developmental Sharpening of Orientation Selectivity",
author = "Li, Y-T and Ma, W-P and Pan, C-J and Zhang, L I and Tao, H W",
journal = "Journal of Neuroscience",
volume =  32,
number =  12,
pages = "3981--3991",
month =  "21~" # mar,
year =  2012,
annote = "<p>- In Layer 4 of the mouse v1, orientation tuning of inhibitor inputs BROADENS in early development, resulting in stronger orientation tuning of principal cells (they cite a study showing broadening of FS response in l2/3 of mouse also)</p>
<p> </p>
<p>- Both excitation and inhibition increase, but excitation increases multiplicatively while inhibition increases across the board, thus being less tuned.</p>
<p> </p>
<p>- Both FS and excitatory neurons increase firing rate, but FS also increase it for the orthogonal orientation - excitatory don't</p>
<p>- Vm tuning also sharpens; spike threshold and resting potential don't change.</p>
<p>- Preferred orientation of inhibition is largely identical to that of excitation (</p>
<p> </p>
<p>- Dark rearing gives STRANGE results: broadening of FS responses is damaged - remain sharply tuned. Also FS firing rate reduced. HOWEVER, inhibitory inputs are still broadened, b/c the inputs are less well correlated - the mean abs. difference between preferred orientation of inhib and excit goes from 20deg +/- 7 to 31deg +/- 29 !</p>
<p> </p>
<p>- The dark rearing part  CONFIRMS that FS selectivity depends on experience (se also Kuhlman et al 2011 in l2/3)</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Marino2005-lr,
title = "Invariant computations in local cortical networks with balanced excitation and inhibition",
author = "Mari\~{n}o, Jorge and Schummers, James and Lyon, David C and Schwabe, Lars and Beck, Oliver and Wiesing, Peter and Obermayer, Klaus and Sur, Mriganka",
journal = "Nat. Neurosci.",
volume =  8,
number =  2,
pages = "194--201",
month =  "23~" # jan,
year =  2005,
annote = "<p>- Cat v1, don't say layer but seems 2/3 (optical imaging involved)</p>
<p> </p>
<p>- Near pinwheels, both excitatory and inhibitory inputs have broader orientation selectivity.</p>
<p> </p>
<p>- Net result: spike selectivity remains sharp!</p>
<p> </p>
<p>- Apparently OSI of g, ge and gi depend on pinwheeel proximity but not on layer position or on simple/complex....</p>
<p> </p>
<p>- More troubling: seem to show that excitation and inhibition are fully in  phase under a drifting grating.... conflict with Priebe and Ferster?....</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Li2012-ge,
title = "Broadening of Inhibitory Tuning Underlies {Contrast-Dependent} Sharpening of Orientation Selectivity in Mouse Visual Cortex",
author = "Li, Y-T and Ma, W-P and Li, L-Y and Ibrahim, L A and Wang, S-Z and Tao, H W",
journal = "Journal of Neuroscience",
volume =  32,
number =  46,
pages = "16466--16477",
month =  "14~" # nov,
year =  2012,
annote = "<p>- MOUSE v1, layer 4 (?)</p>
<p> </p>
<p>- When contrast increases, ecxcitation scales up at all orientations, but inhibition scales up same at preferred orientation but  MORE at orthogonal orientation</p>
<p> </p>
<p>- Result: firing rate goes up at preferred but not anti-preferred - contrast invariance!</p>
<p> </p>
<p>- Seems to be caused by increased firing rate of FS at orthogonal orientation - possibly just duie to a dumb ``iceberg'' effect under increased thalamic inpuyt!</p>
<p> </p>
<p>- Argue that simple reduction in trial-to-trial variation under increased contrast, which they obsrved also and which can contribute to mintaining contrast invariance (by effectively increasing spike threshold), cannot account for their results.</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sato2013-pm,
title = "Distal connectivity causes summation and division across mouse visual cortex",
author = "Sato, Tatsuo K and H{\"{a}}usser, Michael and Carandini, Matteo",
journal = "Nat. Neurosci.",
volume =  17,
number =  1,
pages = "30--32",
month =  "17~" # nov,
year =  2013,
annote = "<p>- If you laser-stimulate a neuron in the binocular zone (by exciting its axon with a laser in the other hemisphere), you get some lateral effects in the monocular zone.</p>
<p> </p>
<p>- Effects on the monocular zone go from facilitation (if no / low contrast stimulus) to suppression (if high contrast stimulus)</p>
<p> </p>
<p>- The effect is captured by a normalization model, in which the stimulation appears a an ADDITIVE term in both numerator and denominator...</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Naito_undated-ty,
title = "Spike synchronization in cat primary visual cortex depends on similarity of surround-suppression magnitude",
author = "Naito, Tomoyuki and Kasamatsu, Takuji and Sato, Hiromichi",
journal = "Eur. J. Neurosci.",
annote = "<p>- In cat V1, looking at the relationship between spike synchrony (or more precisely phase locking) and either orientation preference or amount of surround suppression.</p>
<p> </p>
<p>- Pairs of cells with one in layer 4 and one in layer 2/3: lots of pairs with asymmetric (lagged) synchrony, dependent on both similarity of preferred orientation AND similarity of suppression index.</p>
<p> </p>
<p> </p>
<p>- Pairs of cells within layer 2/3: mostly symmetric synchrony, dependent on amount of similarity of suppression index, but NOT on similarity of orientation tuning!</p>
<p> </p>
<p>- Compatible with the idea that synchrony in layer 2/3 is largely driven by common inhibition rather than lateral excitatory  connections.</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Higuchi1996-ir,
title = "Formation of mnemonic neuronal responses to visual paired associates in inferotemporal cortex is impaired by perirhinal and entorhinal lesions",
author = "Higuchi, S-I and Miyashita, Yasushi",
journal = "Proceedings of the National Academy of Sciences",
volume =  93,
number =  2,
pages = "739--743",
year =  1996,
annote = "<p>- In IT, neurons can produce associations between pairs of stimuli (responses to two stimuli presented in pairs that must be remembered are significantly correlated).</p>
<p> </p>
<p>- This pair correlation is lost in unilateral IT, both for new and old stimulus pairs, if you unilaterally lesion perirhinal and entorhinal cortices, even though single stimulus selectivity is unaffected.</p>
<p> </p>
<p>- Previous study showed that if you bilaterally lesion PRC and EC, learning becomes impossible. Here learning is possible, but the pair representation / correlation in ipsilateral IT is lost. Also the previously learnt pairing are lost - must be relearned!!</p>
<p> </p>
<p>- The lestions may have damaged other stuff</p>
<p> </p>
<p>- Conclusion: EC and PRC inputs play a strong role in the paired-stimulus correlations in IT.</p>
<p> </p>
<p>- See also other Myiashita papers / reviews.</p>"
}

@ARTICLE{Perin2011-no,
title = "A synaptic organizing principle for cortical neuronal groups",
author = "Perin, R and Berger, T K and Markram, H",
journal = "Proceedings of the National Academy of Sciences",
volume =  108,
number =  13,
pages = "5419--5424",
month =  "7~" # mar,
year =  2011
}

@ARTICLE{Hines2011-qr,
title = "Gender Development and the Human Brain",
author = "Hines, Melissa",
journal = "Annu. Rev. Neurosci.",
volume =  34,
number =  1,
pages = "69--88",
month =  "21~" # jul,
year =  2011
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rozell2008-sw,
title = "Sparse coding via thresholding and local competition in neural circuits",
author = "Rozell, Christopher J and Johnson, Don H and Baraniuk, Richard G and Olshausen, Bruno A",
journal = "Neural Comput.",
volume =  20,
number =  10,
pages = "2526--2563",
year =  2008,
annote = "<p>- Description of LCA - Local Component Analysis</p>
<p> </p>
<p>Good introduction about Sparse Coding:</p>
<p>- You have a FIXED overcomplete dictionary, and you try to find the coefficients for this dictionary to reconstruct original signal (note- Olshausen and Field alternated between computing ``best'' coefficients for a fixed base (good reconstruction, sparse) and ``best'' basis for a given set of coefficients (good reconstruction, norm-constrained?). Here they keep basis / dictionary fixed.)</p>
<p>- This has an infinity of solutions, so you add one constraint: ``sparseness'' of the coefficients.</p>
<p>- Ideally ``sparseness'' would be hard 0-norm but this is untractable. Using 1-norm is equivalent (!) IF the coeffs are sparse relative to the similarity of the most similar dictionary elements (why?).</p>
<p>- You can solve this with various methods - Olshausen \& Field 1996 is an example of this with a neural network! Alternatively, you can use greedy algorithms such as Matching pursuit (take the best dictionary element, then iterate on the residual, etc.)</p>
<p>- Apparently these algorithms suck in terms of neural plausibility because - they can't make cells have true-zero firing unless by using ``ad hoc'' thresholding (well, duh!), and they require ``two-way'' signalling, i.e. ``zero'' cells still inhibit other cells (if true, real problem).  Also these algorithms completely change all their coefficients at each new presentation, which is not realistic for time-varying signal - cells tend to change smoothly.</p>
<p> </p>
<p>- LCA  does ``one-way'' inhibition - i.e. a cell will only inhibit others if it is above threshold!  Inhibition is proportional to similarity (correlation)  of receptive fields!!!</p>
<p> </p>
<p>Compare Foldiak / Zylberberg: inhibition also ``one-way'', but the decorrelation of weights is explicitly enforced by anti-Hebbian learning.</p>
<p> </p>
<p>- LCA is described as basically a Hopfield netowrk with NEGATIVE lateral connections equal to correlation between dictionary elements of each cell</p>
<p>tau * du/dt = I(t) - u(t) - Sum\_n!=m(G\_(m,n) * a\_n(t) )</p>
<p>a(t) = Thres\_L(u(t))</p>
<p> </p>
<p>Um is the internal ``potential'' of the cell, a is the thresholded u, G\_(M,n) is the correlation between the dictionary elements of m and n, and I(t) = PHI\_m . Stim is the FF input.</p>
<p>This is equivalent to minimizing the following Energy function (!!):</p>
<p>1/2*||stim(t) - Sum(a(t).PHI)||^2 + L * Sum(C(a(T))</p>
<p>First term is reconstruction error, second is a ``sparseness cost'', the exact form of which depends on the thresholding function. Note that L is the actual value of the threshold !!!</p>
<p> </p>
<p>- The threshold function that you use determines which energy function / sparseness cost function on the activation you are optimizing!  (plain rectifying provides the 1-norm cost).</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Kavukcuoglu2009-oy,
title = "Learning invariant features through topographic filter maps",
booktitle = "Computer Vision and Pattern Recognition, 2009. {CVPR} 2009. {IEEE} Conference on",
author = "Kavukcuoglu, Koray and Ranzato, M and Fergus, Rob and LeCun, Yann",
publisher = "IEEE",
pages = "1605--1612",
year =  2009,
annote = "<p>- Learn both features and ``pooling''</p>
<p> </p>
<p>- Arrange coefficients (and therefore dictionary elements) in a 2D map; establish overlapping Gaussian neighbourhoods on this 2D map.</p>
<p> </p>
<p>- Then just make the sparsity penalty proportional to the sum (over neighbourhoods) of sqrt(z^2 .* Gauss) for each neighbourhood.</p>
<p> </p>
<p>- Because of the z^2, the coefficients within a neighbourhood will tend to be similar (many small activations lower cost than a few large ones) - and thus so will the dictionary elements. By contrast, because of the square root, there will be sparsity across neighbourhoods</p>
<p> </p>
<p>- Advantage: the system will learn the ``proper'', pooling by associating dictionary elements that tend to have similar activations with each other, but dissimilar with the rest of all dictionary elements ! (hm, is that really what you want for e.g. phase invariance? Maybe yes, at the borders of the *overlapping* neighbourhoods...)</p>
<p>- On top of that, use a GLM to regress the optimization procedure necessary to find the components onto a set of tanh of the FF inputs! Your generative, optimizing model has just turned into a pure FF model!</p>
<p> </p>
<p>- Clever. But is it relevant?</p>
<p> </p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gavornik2014-oa,
title = "Learned spatiotemporal sequence recognition and prediction in primary visual cortex",
author = "Gavornik, Jeffrey P and Bear, Mark F",
journal = "Nat. Neurosci.",
month =  "23~" # mar,
year =  2014,
annote = "<p>- Plasticity in V1 (with a little review at the end)</p>
<p> </p>
<p>- Mouse V1, Binocular Layer 4 (+ others)</p>
<p> </p>
<p>- If you train mice on a sequence of oriented gratings, the VEP response to this specific sequence is potentiated</p>
<p> </p>
<p>- If you miss one pattern in the sequence, there is a ``predictive response'' during the missing pattern</p>
<p> </p>
<p>- Involves pretty long timescales, 150-300ms.</p>
<p> </p>
<p>- Seems to involve plasticity within V1: NMDA dependent, ACh dependent, does not transfer to other eye.</p>
<p> </p>
<p>- Seems to go against ``inhibitory predictive coding'', and the general idea that responses to familiar stimuli should be suppressed....</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ostojic2014-gx,
title = "Two types of asynchronous activity in networks of excitatory and inhibitory spiking neurons",
author = "Ostojic, Srdjan",
journal = "Nat. Neurosci.",
volume =  17,
number =  4,
pages = "594--600",
month =  "23~" # feb,
year =  2014,
annote = "<p>- You can reproduce slowly-varying rate variations in spiking LIF neurons!</p>
<p> </p>
<p>- By increasing coupling strength, you go from a ``homogeneous asynchronous'' state (Brunel-like: all neurons fire Poisson-like, with low, constant firing rates) to a ``heterogeneous asynchronous'' state in which neurons fire with time-varying rates and high autocorrelation</p>
<p> </p>
<p>- The heterogeneous state is homologous to the Sompolinsky, Van Vr, etc. chaotic firing-rate networks.</p>
<p> </p>
<p>- The trajectory of the heterogenous network is indeed quite chaotic, expands in PCA space (homogeneous doesn't), and diverges quickly for different inputs (idem)</p>"
}

@ARTICLE{David2008-ji,
title = "Attention to Stimulus Features Shifts Spectral Tuning of {V4} Neurons during Natural Vision",
author = "David, Stephen V and Hayden, Benjamin Y and Mazer, James A and Gallant, Jack L",
journal = "Neuron",
volume =  59,
number =  3,
pages = "509--521",
month =  "14~" # aug,
year =  2008,
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{EinhaEuser2002-zs,
title = "Learning the invariance properties of complex cells from their responses to natural stimuli",
author = "Einha\`{E}user, Wolfgang and Kayser, Christoph and Ko\`{E}nig, Peter and Ko\`{E}rding, Konrad P",
journal = "Eur. J. Neurosci.",
volume =  15,
number =  3,
pages = "475--486",
year =  2002,
annote = "<p>- Learns simple cells in the 1st layer and complex cells in the 2nd layer</p>
<p> </p>
<p>- Uses different algorithms in both layers! Restricts learning only to the most excited cells, divides excitation by average temporal response for each cell.</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ko2013-bq,
title = "The emergence of functional microcircuits in visual cortex",
author = "Ko, Ho and Cossell, Lee and Baragli, Chiara and Antolik, Jan and Clopath, Claudia and Hofer, Sonja B and Mrsic-Flogel, Thomas D",
journal = "Nature",
volume =  496,
number =  7443,
pages = "96--100",
month =  "3~" # apr,
year =  2013,
annote = "<p>- Layer 2-3 of mouse V1</p>
<p> </p>
<p>- Conclusions: lateral connections form preferentially between cells having similar RFs. Thus, the existence of clear RFs precede specific lateral connections!</p>
<p> </p>
<p>- They claim it does NOT work the reverse way: chemical connections don't force the development of similar RFs (but early electrical gap junctions might - no recurrent chemical connections in postnatal week1, only electrical which disappear after pw 1).claudi</p>
<p> </p>
<p>- At eye opening, V1 L2/3 cells are as likely to have a linear RF (``simple'' RF) as at later age, and same size too.</p>
<p> </p>
<p>- However, slightly but very significantly sharper orientation tuning at later age (median OSI 0.62 to 0.68).</p>
<p> </p>
<p>- Less reliable at eye opening: More variation to repeated presentations of same stimulus: Coefficient of Variation 0.93 +-36 to .71 +-30 (mean+-std). (I like the P=1.17e-304...)</p>
<p> </p>
<p>- Overall rate of connectivity between neighboring neurons similar at both ages (58/353 pairs vs 64/295 pairs).</p>
<p> </p>
<p>- Connection proba increases sharply with response correlation in mature, but not at eye opening!</p>
<p> </p>
<p>- More bidirectional among similarly-responding cells, but only for mature.</p>
<p> </p>
<p>- Non-responsive neurons (~40\% in both groups) are as likely to be connected as responsive in mature, but not at eye opening - shows selective elimination / pruning of connections b/w non-responsive neurons.</p>
<p> </p>
<p>- Total pairwise response correlation twice as high at eye opening as in mature (.044 to .021), consistent with pruning.</p>
<p> </p>
<p>- In first week postnatal, there are no recurrent chemical connections and only gap junctions provide recurrent connectivity...</p>
<p> </p>
<p>- So although not much specificity in lateral connection and already strong RFs at eye opening, these can still be influenced by recurrent (electrical) connectivity:</p>
<p> </p>
<p>- Cells with an early gap junction are more likely to develop similar RFs (in model) ! Not true with early bidirectional modifiable chemical connection - wait, what?? Maybe chemical weaker than gap?</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Niell2008-kv,
title = "Highly Selective Receptive Fields in Mouse Visual Cortex",
author = "Niell, C M and Stryker, M P",
journal = "Journal of Neuroscience",
volume =  28,
number =  30,
pages = "7520--7536",
month =  "23~" # jul,
year =  2008,
annote = "<p>- Description of mouse V1 receptive fields across cell types (putative inh and exc) and laminae / layers. Note: ANESTHESIA.</p>
<p> </p>
<p>- Layers 4, 2/3, 6: highly orientation selective exc / pyramidal, largely untuned inh / PV.</p>
<p> </p>
<p>- Layer 5: some range of orientation selectivity, but much less...</p>
<p> </p>
<p>- Some direction selectivity, not much.</p>
<p> </p>
<p>- Clear spatial frequency tuning. Layer 6, and inhibitory, prefer lower spatial frequencies - otherwise, no systematic variation across layers, or eccentricity (no fovea in mice).</p>
<p> </p>
<p>- Simple and complex cells. F1/F0 has clear bimodal distribution on both sides of 1. Inhibitory are almost all complex! So are layer-5.</p>
<p> </p>
<p>- Layer 4 and 2-3 are mostly simple ! ~70\% to 80\% in each of them! Layer 6 only a tiny bit fewer simple. Only layer 5, and inh across layers, is mostly complex (~80\%) !</p>
<p> </p>
<p>- RFs in layer 4 and 2-3 have similar size (~5-7deg)! Layer 6 are a bit larger, layer 5 almost twice as large!</p>
<p> </p>
<p>- As expected, SPONTANEOUS rate in layer 2-3 very sparse, often < .1Hz.  Layer 4 ``almost twice as active''. PV wide range, but almost an order of magnitude higher frequency. Also layer 5 exc has much higher rate (lowest selectivity -> highest spontaneous rate).</p>
<p> </p>
<p>- Evoked rate by optimal stimulus is largely similar across layers. Higher in PV. Median average firing rate over 1.5s: 6.7Hz, lower than other species (peak firing rate is quite higher).</p>
<p> </p>
<p>- Layer 4 prefers higher temporal frequency (4Hz vs 2 Hz).</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Lengyel2004-eu,
title = "Rate-and Phase-coded Autoassociative Memory",
booktitle = "{NIPS}",
author = "Lengyel, M\'{a}t\'{e} and Dayan, Peter",
year =  2004,
annote = "<p>-  A neat derivation of what the update rule should be for an auto-associative, pattern-retrieving/completing network</p>
<p> </p>
<p>- Uses bayesian derivations, by stating the objective (finding the pattern that has highest proba given the inputs and the weight matrix)</p>
<p> </p>
<p>- The hard bit to understand is Eq. 3, the derived p[W/x] - the probability that the W was learnt by including a given pattern x: this is computed by first computing the ``expected'' proba distr of W after learning M-1 patterns with the known distribution of pattern activity, then adding the specific pattern x and getting the resultant proba distr over the Ws that it induces.</p>
<p> </p>
<p>- Includes simple assumptions about the learning process; applies to both Hebbian learning for rate-based units, or STDP for phase-based units.</p>
<p> </p>
<p>- Gives a derivation of optimal parameters for update of neural activity, including decay, etc.!</p>"
}

@ARTICLE{Intrator1992-yh,
title = "Objective function formulation of the {BCM} theory of visual cortical plasticity: Statistical connections, stability conditions",
author = "Intrator, Nathan and Cooper, Leon N",
journal = "Neural Netw.",
volume =  5,
number =  1,
pages = "3--17",
year =  1992,
annote = "<p>Theoretical description of the BCM rule, including how it can be derived from a maximization of multi-modality in the response.</p>"
}

@ARTICLE{Clopath2010-xm,
title = "Connectivity reflects coding: a model of voltage-based {STDP} with homeostasis",
author = "Clopath, Claudia and B{\"{u}}sing, Lars and Vasilaki, Eleni and Gerstner, Wulfram",
affiliation = "Laboratory of Computational Neuroscience, Brain-Mind Institute and School of Computer and Communication Sciences, Ecole Polytechnique F\'{e}d\'{e}rale de Lausanne, Lausanne, Switzerland. claudia.clopath@epfl.ch",
abstract = "Electrophysiological connectivity patterns in cortex often have a few strong connections, which are sometimes bidirectional, among a lot of weak connections. To explain these connectivity patterns, we created a model of spike timing-dependent plasticity (STDP) in which synaptic changes depend on presynaptic spike arrival and the postsynaptic membrane potential, filtered with two different time constants. Our model describes several nonlinear effects that are observed in STDP experiments, as well as the voltage dependence of plasticity. We found that, in a simulated recurrent network of spiking neurons, our plasticity rule led not only to development of localized receptive fields but also to connectivity patterns that reflect the neural code. For temporal coding procedures with spatio-temporal input correlations, strong connections were predominantly unidirectional, whereas they were bidirectional under rate-coded input with spatial correlations only. Thus, variable connectivity patterns in the brain could reflect different coding principles across brain areas; moreover, our simulations suggested that plasticity is fast.",
journal = "Nat. Neurosci.",
volume =  13,
number =  3,
pages = "344--352",
month =  mar,
year =  2010
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mante2013-bq,
title = "Context-dependent computation by recurrent dynamics in prefrontal cortex",
author = "Mante, Valerio and Sussillo, David and Shenoy, Krishna V and Newsome, William T",
affiliation = "1] Howard Hughes Medical Institute and Department of Neurobiology, Stanford University, Stanford, California 94305, USA [2] Institute of Neuroinformatics, University of Zurich/ETH Zurich, CH-8057 Zurich, Switzerland. [3].",
abstract = "Prefrontal cortex is thought to have a fundamental role in flexible, context-dependent behaviour, but the exact nature of the computations underlying this role remains largely unknown. In particular, individual prefrontal neurons often generate remarkably complex responses that defy deep understanding of their contribution to behaviour. Here we study prefrontal cortex activity in macaque monkeys trained to flexibly select and integrate noisy sensory inputs towards a choice. We find that the observed complexity and functional roles of single neurons are readily understood in the framework of a dynamical process unfolding at the level of the population. The population dynamics can be reproduced by a trained recurrent neural network, which suggests a previously unknown mechanism for selection and integration of task-relevant inputs. This mechanism indicates that selection and integration are two aspects of a single dynamical process unfolding within the same prefrontal circuits, and potentially provides a novel, general framework for understanding context-dependent computations.",
journal = "Nature",
volume =  503,
number =  7474,
pages = "78--84",
month =  "7~" # nov,
year =  2013,
annote = "<p>[From a video of a talk by Bill Newsome: Swartz Mind Brain lecture, March 2014</p><p> </p><p>- Paper with Sussilo: Context-dependent computations by recurrent dynamics in PFC (really FEF)</p><p><br></p><p>- ``Detect motion'' context vs ``detect color'' context</p><p><br></p><p>- Starting hypothesis : filtering out / gating of the irrelevant information</p><p>- When detecting motion, the integrators in decision areas (LIP/FEF/SC) would only look at MT, while when detecting color, they would only look at V4/IT.</p><p><br></p><p>- WRONG!</p><p>- Actually, both signals were hitting the decision areas in both contexts.</p><p><br></p><p>- Train an RNN to produce the right answer, given sensory information + context indicator.</p><p><br></p><p><br></p><p>- Look at the dynamics in response-vector space!</p><p><br></p><p>- You get a line attractor (a series of local attractors, arranged into a line) in the direction of choice-axis!</p><p><br></p><p>- When you perturb the network by giving it color or motion info, response is displaced along the color-axis or motion-axis…</p><p><br></p><p>- If along motion-axis, then it comes back to the choice axis exactly to the same spot after end of stimulation.</p><p>- But if along color-axis, then it comes back to the choice axis a little ‘left’ or ‘right’ of its previous position !!</p><p>- Selective integration of inputs !!</p><p><br></p><p>- So the secret to perceptual ‘gating’ is in the relaxation dynamics.</p><p><br></p><p>- Both of these (line attractor, relaxation dynamics) are invisible at single-cell level! Can only be seen at population level!</p><p><br></p><p>- P.W. Anderson (``More is different'') rather than Horace Barlow (single cells)</p><p>]</p><p><br></p><p>- Monkey ``PFC'' (actually mostly, but probably not only, FEF....)</p>
<p> </p>
<p>- Task: saccade to right or left target, or to green or right target, based on either the main direction or main color of a moving dots pattern (motion vs. color context is indicated by initial cue).</p>
<p>- For each cell, ``Choice 1'' was the ``preferred direction'' for that cell.</p>
<p> </p>
<p>- Using linear regression to determine the representation of various quantities (eventual choice, color,  direction, context, etc.) from the neural population activity</p>
<p> </p>
<p>- FIRST, regress each cell's activity on the various quantities (final choice, color, motion, context). That gives a set of Betas, for each cell. THEN, group all the Betas for a given quantity, across all cells, into a single vector. That gives you the direction along which the whole population represents this quantity - the value of the projection of population vector on that axis is how the population encodes the value of said quantity</p>
<p>- (For each quantity, pick the time bin for which this vector has maximum norm; also, a PCA step is used)</p>
<p>- Finally, orthogonalize these vectors through QR transform... Note that the order counts! (p.9)</p>
<p> - Note that in the regression, the ``color'' variable doesn't mean ``red vs. green'', but ``color leading to left vs. color leading to right'', and same for motion (Suppl Mat p. 6).... not really sensory??...</p>
<p> </p>
<p>- The final choice is represented in a strictly increasing manner: the population keeps going more and more towards the direction of choice 1 or choice 2, consistent with the accumulators to bound model.</p>
<p> </p>
<p>- However, by contrast, sensory qualities (motion, color) Are represented transiently - increasingly at first, then decreasingly. By the end of the trial the population seems  to NOT represent stimulus sensory quality at all!</p>
<p> </p>
<p>- Result: population describes *arcs* away (then back to) the axis of choice, expanding (then receding) in the direction of the axis of the sensory quality being important for this particular trial!</p>
<p> - Figure 2: When color is relevant, 'dir-1' colors are only represented along the 'choice 1' axis, and 'dir-2' along 'choice 2'; but when is irrelevant, both colors are represented along both directions - as expected (he only shows correct trials!)</p>
<p> </p>
<p>- Also: more separation between the 'just-dir-1' and 'just-dir-2' ``margin'' levels in the relevant quantity vs. the irrelevant one?</p>
<p> </p>
<p>- The direction of the axes (choice, motion, color) do NOT depend on context (i.e. which sensory dimension is relevant)  However you can define a ``context'' axis, and responses show different trajectories for different contexts, again forming ``arcs'' in the direction of ``contextness'' (in the same direction, but with very different amplitude depending on which context holds).</p>
<p> </p>
<p>- There is an overall drift towards Choice 1 (the choice direction corresponding to the neuron's response field) = ``URGENCY'' signal, in both monkeys, much stronger in monkey F (in A, it only shows as a compression of the trajectories towards choice 2). Also in F, color axis acts choice-like .</p>
<p> </p>
<p>- Observation: The total expanse of trajectories along the relevant sensory axes is roughly similar, whether or not this quantity is the relevant one (i.e. the trajectories for ``most green'' and ``most red'' are almost as far as each other whether or not color is relevant). BUT, there seems to be MUCH higher separation between the two levels on each side of the decision border (``just green'' and ``just red''), when the quantity is relevant!</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lehman2011-je,
title = "Abandoning objectives: Evolution through the search for novelty alone",
author = "Lehman, Joel and Stanley, Kenneth O",
journal = "Evol. Comput.",
volume =  19,
number =  2,
pages = "189--223",
year =  2011,
annote = "<p>- By not using fitness function and only selecting for *behavioral* diversity, you can get better result than selecting for fitness!</p>
<p> </p>
<p>- That could be because it allows you to keep the ``stepping stones'' towards more complex, better systems</p>
<p> </p>
<p>- The other, unsaid reason: although they say they ``abandon objectives'', it's not completely true. The objectives are still implicitly contained in how you measure ``novelty'', because ``novelty'' is only calculated with regard to the behavior that you're trying to optimize.</p>
<p> </p>
<p>- e.g. if trying to evolve locomotion behavior, you measure novelty as ``getting to a point where few previous behaviors went''. The system might be doing plenty of other things, which might be ``novel'' in the sense that previous systems didn't do them, but you ignore those.</p>
<p> </p>
<p>- As a result you constrain the dynamics to ``hug'' a certain behavioral dimension and cover it, rather than disperse in the full search space, which is the reason why you can still obtain strong performance for a given objective despite ``abandoning objectives''</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sussillo2009-rk,
title = "Generating coherent patterns of activity from chaotic neural networks",
author = "Sussillo, David and Abbott, L F",
affiliation = "Department of Neuroscience, Department of Physiology and Cellular Biophysics, Columbia University College of Physicians and Surgeons, New York, NY 10032-2695, USA. sussillo@neurotheory.columbia.edu",
abstract = "Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.",
journal = "Neuron",
volume =  63,
number =  4,
pages = "544--557",
month =  "27~" # aug,
year =  2009,
annote = "<p>- FORCE algorithm:  a better echo-state network capable of learning with general network modification, etc.</p>
<p> </p>
<p>- As in echo-state, the output is a linear combination of the neuron's activities AND is fed back (through fixed weights) to each neuron in the reservoir.</p>
<p> </p>
<p>- Output feedback is apparently necessary to learn any useful output trajectory, at least in no-input networks.</p>
<p>- Because of errors (deviation from expected/learnt trajectory) in the output, feedback can actuall kill the learning. To prevent this, Jaeger and Maas simply fed back the actual desired output during learning. In FORCE, you just use very strong, fast synapse modification to ensure that the real output is always close to desired output.</p>
<p> </p>
<p>- Also, random NNs used here are chaotic. To eliminate this, just make the feedback strong in comparison to recurrent weights. This also requires that target function has sufficient amplitude (at least in the basic, only-output-w-modified version).</p>
<p> </p>
<p>- The FORCE choices really do help stability and learning, in comparison to the original echo-state choices which fail more often and are more unstable (perhaps because echo-state, by feeding the desired output rather than the real output, becomes fragile wrt small deviations b/w real output and desired output)</p>
<p> </p>
<p>- First modification: feed the outputs to a full separate network, rather than a single unit, with each unit in the FB network projecting back to a subset of units in the original, ``generator'' network. Removes the non-biologically plausible strong FB synapses and the fact that all neurons shared the same FB input. Still keep the single, linear-combination readout unit to produce the actual output of the whole network (this is not fed back to the system). Apply FORCE learning to all synapses from generator to FB network (but NOT recurrent synapses within the FB net), as well as all synapses from generator to readout.- Super bonus: you can get rid of the feedback altogether, and let the weights within the generator network modify (as well as the non-fed-back readout)! - For this, each neuron modifies its input weights, applying the same learning algorithm, but to its input weights, and with error based on the difference between desired target function and the READOUT's response (NOT each neuron's response, IIUC). <br />- Somehow, the change in response brought about by learning (final-response-with-learned-weights minus response-using-initial-weights-before-learning) is equal to the desired function! The system has learnt to introduce the desired output as a feedback into itself!</p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sompolinsky1988-bi,
title = "Chaos in random neural networks",
author = "Sompolinsky, Haim and Crisanti, A and Sommers, H J",
journal = "Phys. Rev. Lett.",
volume =  61,
number =  3,
pages = "259",
year =  1988,
annote = "<p>- In random, ASYMMETRIC neural networks, when N -> Inf, the behavior is chaotic when gain gJ >1, goes to 0 otherwise. (if symmetric, just plain spin glass / Hopfield)</p>
<p> </p>
<p>- J is the ``average size'' of the connections (which are 0-mean gaussian - seems to be stdev of Jij, but not sure), while g is the gain in the neural activation function tanh(gx)</p>
<p> </p>
<p>- In practice, for 1000 > N >> 1, there is an intermediate regime with non-zero fixed points and increasingly complicated cycles.</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kaufman2014-rt,
title = "Cortical activity in the null space: permitting preparation without movement",
author = "Kaufman, Matthew T and Churchland, Mark M and Ryu, Stephen I and Shenoy, Krishna V",
journal = "Nat. Neurosci.",
volume =  17,
number =  3,
pages = "440--448",
month =  "2~" # feb,
year =  2014,
annote = "<p>- Preparatory activity (tuned for movement factors) is high in PMd, lower in M1, lower still in spine and absent in muscles.</p>
<p>- Preparatory is not weaker than movement activity! Also no obvious inhibitory gating (they say).</p>
<p>- How come activity in M1 and PMd fails to generate movement?</p>
<p> </p>
<p>- Assume the effect of population neural activity on its target (muscle, downstream neuron) is linear: Muscle\_act = W * Neural\_act (M, N column vectors of muscle/neuron activities if a single timestep is considered, matrices if many timesteps))</p>
<p>- W rows are weights from all neurons to one muscle.</p>
<p>- NOTE: this precludes non-markovian temporal dynamics that depend on previous activities...</p>
<p> </p>
<p>- Note that different neurons can cancel each other's activities. E.g. if neurons remain constantly opposite in sign and equal in value, while having similar weights. Or if they have equal and opposite weights, while keeping roughly similar activities.</p>
<p>- In these 2D examples, the constant-sum direction is a line, the 'output-null' direction. Any change along this direction makes no change to output. Any change in the orthogonal, ``output-potent'' direction changes the output. (the null and potent vectors are respectively 1,1 and -1,1 for the 'same weights' example, the opposite for the 'opposite weights' example).</p>
<p> </p>
<p>- These output-potent and output-null dimensions should exist because more neurons than muscles. Does the brain use them for preparatory activity?</p>
<p> </p>
<p>- At first sight, plausible: during preparatory activity, population moves through a restricted space - only one dimensional in a 2D projection - while during motion it sweeps through the 2D space. But need indep. confirmation that the preparatory-activity dimension is indeed the output-null one!</p>
<p> </p>
<p>- To do this, look at neural activity during movement; try to find a projection of neural activity that looks like EMG (presumably the output-potent direction); and then, see if preparatory activity avoids these directions.</p>
<p> </p>
<p>- CRUCIAL: They say that if you find W / M = W* N during movement, the output-potent dimensions is the row-space of W (set of all linear combinations of rows of W, i.e. the space of which W's rows are a basis, i.e... the directions defined by the rows of W itself!), while the output-null dimensions are the null-space of W....</p>
<p> </p>
<p>- NOTE: The null-space of a matrix is always the orthogonal complement of its row space! By making sure that dim(N) is 6 and dim(M) is 3 (through PCA), you ensure that the matrix has a 3D row space (i.e. its rows are 3 6D vectors that define the basis of a 3D space) and a 3D null space (directions in the 6D neuron-pop-space that don't affect the result of the projection through W)...</p>
<p> </p>
<p>- It may help to visualize this by thinking dim(M)=2, dim(N)=1. Then W is one 2D row-vector, being the basis of a 1D space (a line). If N moves orthogonal to this line, it won't change M; any other change (i.e. change that has a component in the direction of W) will affect M.</p>
<p> </p>
<p>- MAIN RESULT: The projection of PREPARATORY neural activity on the OUTPUT-NULL SPACE has HIGHER VARIANCE (across space and conditions) than on the OUTPUT-POTENT SPACE.</p>
<p>- It follows that the reduction-of-activity from cortex to muscle is not (just) caused by some 'gating' but results (at least in part) from exploitation of output-null dimensions of the neural-to-muscle mapping connections.</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Kaiser2012-dv,
title = "Learning Games from Videos Guided by Descriptive Complexity",
booktitle = "{AAAI}",
author = "Kaiser, Lukasz",
year =  2012,
annote = "<p>- Learn to play Connect 4 ,     Gomoku, Pawns or breakthrough from just pure videos of playing, with minimal labelling (winning conditions, legal/illegal moves)!</p>
<p> </p>
<p>- Pretty much a definition of intelligence...</p>
<p>- A system called ``Progol'' can learn the rules of Chess from visual input ?!? (though highly pre-processed)</p>
<p> </p>
<p>- Present system: relies on graph / grid models (representing boards) rather than Horn clauses and recursive predicates</p>
<p> </p>
<p>- Use 4 binary relations: next-in-row, next-incol, next-first-diag, next-second-diag. Also use unary relations for presence of a piece on a square. Also introduce one element per board square and define all the relations between all board squares/elements.</p>
<p> </p>
<p>- First order logic (statement of relations, equality, for any, there exists, not, or, and) cannot express certain patterns. E.g. with the above relations, you can't express ``there are two elements in the same row, not necessarily next to each other'' in a way that is independent of the size of the board.</p>
<p> </p>
<p>- So you add ``transitive closure'' - e.g. TC x,y R(x,y) says there is a path of R(x,i), R(i,j)... R(n, y). (TC x, y next-in-row(x,y) = ``y is somewhere to the right of x''). Also use TC^m to specify the exact number of steps.</p>
<p>- ``Descriptive complexity'' studies the computational complexity of computing all relationships defined by a certain logic.</p>
<p> </p>
<p>- If you restrict the maximum number of variables in your expression to k, under some conditions (fulfilled by board games) you can find a relationship distinguishing any two sets of structures in polynomial time (?)</p>
<p> </p>
<p>- You can learn which conditions are winning or not.</p>
<p>- You can represent moves, and learn expressions for which moves are legal (you need examples of illegal moves).</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>"
}

@ARTICLE{Ramirez2013-yh,
title = "Creating a false memory in the hippocampus",
author = "Ramirez, Steve and Liu, Xu and Lin, Pei-Ann and Suh, Junghyup and Pignatelli, Michele and Redondo, Roger L and Ryan, Tom\'{a}s J and Tonegawa, Susumu",
abstract = "Memories can be unreliable. We created a false memory in mice by optogenetically manipulating memory engram-bearing cells in the hippocampus. Dentate gyrus (DG) or CA1 neurons activated by exposure to a particular context were labeled with channelrhodopsin-2. These neurons were later optically reactivated during fear conditioning in a different context. The DG experimental group showed increased freezing in the original context, in which a foot shock was never delivered. The recall of this false memory was context-specific, activated similar downstream regions engaged during natural fear memory recall, and was also capable of driving an active fear response. Our data demonstrate that it is possible to generate an internally represented and behaviorally expressed fear memory via artificial means.",
journal = "Science",
volume =  341,
number =  6144,
pages = "387--391",
month =  "26~" # jul,
year =  2013,
language = "eng"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Olshausen2013-oj,
title = "Highly overcomplete sparse coding",
author = "Olshausen, Bruno A",
editor = "Rogowitz, Bernice E and Pappas, Thrasyvoulos N and de Ridder, Huib",
pages = "86510S",
month =  "14~" # mar,
year =  2013,
annote = "<p>- If you use a massively overcomplete sparse coding, you get very very diverse receptive fields</p>
<p> </p>
<p>- Note that overcompleteness here is not so much in terms of cell number ratio, but number of cells vs total number of independent dimensions in the patches: because of low-pass filtering, only about 200 dimensions in the 16x16 patches, thus 256 cells is ~1.25x overcomplete.</p>
<p>- Not just gabors/gaussians, but also curves, disks, gratings, etc.</p>
<p> </p>
<p>- Also describes the (rather complex) preprocessing applied. It's not just difference of gaussians!</p>"
}

@ARTICLE{Salinas1997-fu,
title = "Invariant Visual Responses From Attentional Gain Fields",
author = "Salinas, Emilio and Abbott, L F",
journal = "J. Neurophysiol.",
volume =  77,
number =  6,
pages = "3267--3272",
month =  "1~" # jun,
year =  1997,
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Munz2014-ib,
title = "Rapid Hebbian axonal remodeling mediated by visual stimulation",
author = "Munz, M and Gobert, D and Schohl, A and Poquerusse, J and Podgorski, K and Spratt, P and Ruthazer, E S",
journal = "Science",
volume =  344,
number =  6186,
pages = "904--909",
month =  "23~" # may,
year =  2014,
annote = "<p>- Hebb is real (at least in developing tadpoles)!</p>
<p> </p>
<p>- Most retinal ganglion cells (RGCs) target contralateral tectum. But occasionally one will target ipsilateral tectum.</p>
<p> </p>
<p>- You can identify the tectal cells contacted by this 'stray', same-side-eye RGC. They are largely driven by contra-lateral stimuli, but also a little bit by ipsi-lateral stimuli (because of the stray axon!)</p>
<p> </p>
<p>- If you stimulate both eyes *alternatively*, the ipsilateral axon *loses* synaptic strength to the tectal cell. But if you stimulate simultaneously, the ipsilateral axon maintains or gains synaptic strength relative to contralateral.</p>
<p> </p>
<p>- A 2-day asynchronous vs. synchronous stimulation (using large-scale stimuli, either stroboscopic or independent dots), led to larger, more diffuse axons of the ipsilateral RGC cell onto the tectal cells for the asynchronous case.</p>
<p> </p>
<p>- In a 2-hour comparison of asynch-then-synch vs. synch-then-asynch :  asynch first increased new branch formation AND elimination within 20min! Tips are also longer.</p>
<p> </p>
<p>- Branch formation, elimination, elongation of tips slows down after switching to synchronous stimulation of eyes.</p>
<p> </p>
<p>- Branches formed during synchronous are more stable, significantly more likely to survive more than 30min.</p>
<p> </p>
<p>- Difference between sycnh and asynch regime is NMDAR-dependent.</p>
<p> </p>
<p>- Conclusion: during development, cells that can't find a ``suitable'' target keep looking for one (branching out), whereas cells that do find a suitable target stabilize their connection. The Hebbian process is highly specific.</p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Baldauf2014-vn,
title = "Neural Mechanisms of {Object-Based} Attention",
author = "Baldauf, D and Desimone, R",
journal = "Science",
volume =  344,
number =  6182,
pages = "424--427",
month =  "25~" # apr,
year =  2014,
annote = "<p>- IFJ directs object-based attention to different portions of IT (FFA and PPA), just life FEF directs spatial attention to different portion of V4 !</p>
<p> </p>
<p>- Frequency-tag face and house stimuli. As expected, PPA and FFA light up in the MEG at the adequate frequencies.</p>
<p> </p>
<p>- Direct attention to either face or houses. In contrast to a non-attention but demanding task, the IFJ lighted up in fMRI.</p>
<p> </p>
<p>- Attention modulates PPA and FFA responses.</p>
<p> </p>
<p>- IFJ responses to the tags lag IFA/PPA responses by ~25ms, presumably because of synaptic delays.</p>
<p> </p>
<p>- During attention to either, the IFJ gamma-synchronizes to the appropriate area with a phase advance of ~20ms (though lots of variation among subjects in peak synch frequency)</p>
<p> </p>
<p>- In 9 of 12 subjects, and clearly in the aggregate, angular phase lag increases linearly around the peak synch freq, suggesting a constant phase lag in ms (20 ms)</p>
<p> </p>
<p>- Connectivity analysis suggests that among frontal areas, IFJ is the most strongly connected to both PPA and FFA...</p>
<p> </p>
<p>- Would this be used for visual search? You would expect the 'target' to be represented (fMRI-MVPA or adaptation detectable) in IFJ.. and also in LIP during delay.. And IFJ->LIP/FEF gamma coherence...</p>
<p> </p>
<p> </p>",
language = "en"
}

@ARTICLE{Zhou_undated-oo,
title = "{Feature-Based} Attention in the Frontal Eye Field and Area {V4} during Visual Search",
author = "Zhou, Huihui and Desimone, Robert",
journal = "Neuron",
volume =  70,
number =  6,
pages = "1205--1217",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sheinberg2001-dt,
title = "Noticing familiar objects in real world scenes: the role of temporal cortical neurons in natural vision",
author = "Sheinberg, David L and Logothetis, Nikos K",
journal = "J. Neurosci.",
volume =  21,
number =  4,
pages = "1340--1350",
year =  2001,
annote = "<p>- During visual search in complex scenes, IT responds to targets just as much as when they are isolated - but only after the target is found!</p>
<p> </p>
<p>- Target-selective IT cell bursts occurs either at the last fixation or at the fixation just before that.</p>
<p> </p>
<p>- Strict linear relationship (y=ax+b) between burst time and manual response time (b~=300ms), strongly suggesting that the burst is an indication of ``finding''.</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Saiepour2014-bn,
title = "Competition and Homeostasis of Excitatory and Inhibitory Connectivity in the Adult Mouse Visual Cortex",
author = "Saiepour, M H and Chakravarthy, S and Min, R and Levelt, C N",
journal = "Cereb. Cortex",
month =  "14~" # oct,
year =  2014,
annote = "<p> - Synaptic competition and synaptic scaling (?) continue in the adult brain!</p>
<p> </p>
<p>- If you express a plasticity-damaging (?) gene in adult mice in  A FEW pyramids, they lose a lot of input synapses.</p>
<p> </p>
<p>- If you express the same in A LOT of pyramids, they are unaffected!</p>
<p> </p>
<p>- several references on synaptic scaling in development</p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ernst2001-hk,
title = "Intracortical origin of visual maps",
author = "Ernst, U A and Pawelzik, K R and Sahar-Pikielny, C and Tsodyks, M V",
journal = "Nat. Neurosci.",
volume =  4,
number =  4,
pages = "431--436",
year =  2001,
annote = "<p>- If you have mexican hat connectivity within cortex, with inhomogeneities, then YOU GET ORIENTATION SELECTIVITY AND ORIENTATION MAPS FOR FREE, even if thalamic afferents are pure gaussian blobs.</p>
<p> </p>
<p>- No need for Hebbian learning or any selectivity in inputs.</p>
<p> </p>
<p>- The stable states are those that maximize local excitatory feedback; the inhibition ensures that only some of the cells, arranged in patches with a certain distance between them, are active for any given stimulus (e.g. uniform intensity generates a neatly regular set of active patches).</p>
<p> </p>
<p>- Also explains direction selectivity !</p>
<p> </p>
<p>- Claim that orientation maps don't really depend on experience - but this is hotly debated, and Miller Erwin and Kayser J Neurobiol 1999 review evidence to the opposite, including some of the eferences they cite. See also the Stevens - Bednar paper in zotero.</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{White_undated-ky,
title = "Vision and Cortical Map Development",
author = "White, Leonard E and Fitzpatrick, David",
journal = "Neuron",
volume =  56,
number =  2,
pages = "327--338",
annote = "<p>- Big review of the formation of cortical maps development</p>
<p> </p>
<p>- Much is innate, much is experience dependent.</p>
<p> </p>
<p>- ``our purpose here is to review recent evidence suggesting that visual experience plays a more substantial role in the earlier, formative stages of ORIENTATION and DIRECTION preference map development than would have been predicted based on studies of TOPOLOGICAL maps''</p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Miller2014-yg,
title = "Visual stimuli recruit intrinsically generated cortical ensembles",
author = "Miller, J-E K and Ayzenshtat, I and Carrillo-Reid, L and Yuste, R",
journal = "Proceedings of the National Academy of Sciences",
volume =  111,
number =  38,
pages = "E4053--E4061",
month =  "23~" # sep,
year =  2014,
annote = "<p>- In both spontaneous and evoked activity, local rodent V1 layer 2/3 local activity ``is dominated by coactive groups of neurons, forming ensembles whose activation cannot be explained by the independent firing properties of their contributing neurons, considered in isolation''</p>
<p> </p>
<p>- Note: ``coactive'' means ``coactive within a frame'', where a ``frame'' covers ~250ms!</p>
<p> </p>
<p>- i.e. cells tend to fire in pre-established groups.</p>
<p> </p>
<p>- About half of cells are orientation selectiv; agrees with previous estimates.</p>
<p> </p>
<p>- Analyzes ``high activity frames'' - 13\% of all frames, but >50\% of all spikes.</p>
<p> </p>
<p>- The rate of  active ensembles per second, and number of active neurons per ensemble, is similar in spontaneous and evoked activity!</p>
<p> </p>
<p>- However, the total firing rate in ensembles is higher for gratings than spontaneous - but  natural movie is same as spontaneous!</p>
<p> </p>
<p>- Correlated ensembles occur more frequently than by chance</p>
<p> </p>
<p>- This is not just caused by individual cell's response properties: frequency of ``core ensemble'' (group of cells that are always active when a given ensemble is) occurrence  was much higher than expected if you just look at individual cell's firing properties.</p>
<p> </p>
<p>- MANY single neurons participate in more than one ensemble, yet are just as selective as the others. 8\% of cells shared by core ensembles to different gratings (>45deg diff), with similar orientation tuning. </p>
<p> </p>
<p>- 40\% shared by different core ensembles in movies, 13\% shared by 5 or more distinct core ensembles!!</p>
<p> </p>
<p>- Evoked and spontaneous ensembles are similar.</p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Zhang2014-rs,
title = "Long-range and local circuits for top-down modulation of visual cortex processing",
author = "Zhang, S and Xu, M and Kamigaki, T and Hoang Do, J P and Chang, W-C and Jenvay, S and Miyamichi, K and Luo, L and Dan, Y",
journal = "Science",
volume =  345,
number =  6197,
pages = "660--665",
month =  "8~" # aug,
year =  2014,
annote = "<p>- Top-down attention DOES target inhibitory interneurons, maybe in a complex way!</p>
<p> </p>
<p>- (At least in mouse, where ``top'' is Cingular (Cg) / apparently similar to FEF , and ``Bottom'' is V1)</p>
<p> </p>
<p>- Laser-stimulate axons from Cg in V1, record from l2/3 pyramidals; look at firing rate, but also IPSCs / EPSCs.</p>
<p> </p>
<p>- Some monosynaptic EPSCs , but also disynaptic IPSCs - even after you prevent firing in V1 with TTX! So Top-down Cg axons do target inhib. interneurons directly!</p>
<p> </p>
<p>- Activating a single CG axon causes INCREASE in Pyr firing at 0micom, DECREASE at 200 microm, dies out at ~400microm. - Surround suppression!</p>
<p> </p>
<p>- EPSCs decrease monotonically with distance, but IPSCs first increase then decrease!</p>
<p> </p>
<p>- Inactivating solely PV interneurons just increases firing / decreases IPSCs overall, shifts the whole curves (firing/IPSCs vs. distance from axon) up - even if you don't activate the axon. So it seems to be just general disinhibition.</p>
<p> </p>
<p>- Inactivating VIP causes DECREASE in firing and INCREASE in IPSCs at 0microm only - no effect at longer distances. Local disinhibition!</p>
<p> </p>
<p>- Inactivating SOM causes INCREASE in firing, mostly at 200microm - the firing is not increased by Cg axon stim. at all distances, with modulation decreasing monotonically with distance - the ``surround suppression'' by Cg axon stim. has disappeared!</p>
<p> </p>
<p>- See also: the Kepecs lab paper about the disinhibitory PIV->SOM circuit, recruited in fear-conditioning in auditory cortex.</p>
<p> </p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Pi2013-ii,
title = "Cortical interneurons that specialize in disinhibitory control",
author = "Pi, Hyun-Jae and Hangya, Bal\'{a}zs and Kvitsiani, Duda and Sanders, Joshua I and Huang, Z Josh and Kepecs, Adam",
journal = "Nature",
volume =  503,
number =  7477,
pages = "521--524",
month =  "6~" # oct,
year =  2013,
annote = "<p>- The PIV -> SOM disinhibition system in mouse A1 is engaged by associative fear conditioning.</p>
<p> </p>
<p>- They cite a previous paper which showed that disinhibition by cholinergic (nicotinic) inputs into L1 of A1 was also engage AND necessary, wonder if these two circuits overlap.</p>"
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Okamura2014-xd,
title = "Neural Substrates of {View-Invariant} Object Recognition Developed without Experiencing Rotations of the Objects",
author = "Okamura, J-Y and Yamaguchi, R and Honda, K and Wang, G and Tanaka, K",
journal = "Journal of Neuroscience",
volume =  34,
number =  45,
pages = "15047--15059",
month =  "5~" # nov,
year =  2014,
annote = "<p>- 3D view tolerance builds (in both IT cells and behavior) through experience.</p>
<p> </p>
<p>- One possible model is ``trace'' - slowly turning stimuli are associated with the same object, building view tolerance.</p>
<p> </p>
<p>- But here they show that if you learn to discriminate two slightly different objects at the same angle (where angle can take several values), you can also discriminate same/different after a 30deg or even 60deg jump!</p>
<p> </p>
<p>- IOW, you can ``transfer'' the fine object ID across reasonable jumps in orientation, if you have seen the discriminands at each of the separate orientations</p>
<p> </p>
<p>- This is also observed in the cells, which build viewpoint tolerance (i.e. preserve firing order of objects across nearby angles 0- 30deg and a bit 60deg from preferred view).</p>
<p> </p>
<p>- Only if you learn to discriminate slightly different objects. Not if you learn to discriminate totally different objects - both for behaviour and IT cell responses.</p>
<p> </p>
<p>- Note that the response selectivity is viewpoint-tolerant, but not invariant: unpref object at pref angle may give higher response than pref object at unpref angle (but at the same angle, pref obj > unpref obj - at least at 30 and 60deg rotation from pref angle)</p>
<p> </p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hyvarinen2000-uu,
title = "Emergence of phase-and shift-invariant features by decomposition of natural images into independent feature subspaces",
author = "Hyv{\"{a}}rinen, Aapo and Hoyer, Patrik",
journal = "Neural Comput.",
volume =  12,
number =  7,
pages = "1705--1720",
year =  2000,
annote = "<p>- Yet another way to get omplex cells, from Hyvarinen.</p>
<p> </p>
<p>- Main insight (from Kohonen): invariant (complex) features can be represented as a linear subspace in (simple) feature space. You then get the value of the invariant feature for a stimulus by computing the (squared) norm of its projection onto the subspace, that is, the sum of its squared dot-products with each of the individual simple feature.</p>
<p> </p>
<p>- Notes that in sparse coding, Img = Sum (dict\_i * coeff\_i), in general, the dict\_i are not RFs. RFs are obtained by inverting dict\_is, getting coeff\_i = <inv\_dict\_i, Img> HOWEVER, if the data is whitened, AND if the coeff\_i are all uncorrelated and unit-variance, then 1- the dict\_i are orthonormal, and 2- you can use inv\_dict\_i = dict\_i.</p>
<p> </p>
<p>- If you use a special ICA that groups together groups of features (allowing within-group redundancy, but forcing between-group independence), you can use it to generate the linear subspace that generate invariant features</p>
<p> </p>
<p>- You get complex cells with phase and a bit of spatial invariance!</p>
<p> </p>
<p>= Not sure how much is baked in by the use of squared responses; still cool that precisely the right simple features (in phase quadrature?) are grouped together by the algorithm?</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tchumatchenko2011-iy,
title = "Ultrafast Population Encoding by Cortical Neurons",
author = "Tchumatchenko, T and Malyshev, A and Wolf, F and Volgushev, M",
journal = "Journal of Neuroscience",
volume =  31,
number =  34,
pages = "12171--12179",
month =  "24~" # aug,
year =  2011,
annote = "<p>- If you inject a very small step current into 1 neuron (much smaller than what is needed to make it fire from rest), you can get a FAST increase of firing rate (as computed by summing over many repetitions).</p>
<p> </p>
<p>- Detectable within 1-2ms !!  (if you have enough repetitions, or equivalently, if you inject the small current into enough cells at the same time - on the order of ~2000)!</p>
<p> </p>
<p>- Much faster than the time-scale of membrane voltage dynamics!</p>
<p> </p>
<p> -     Also works if you don't inject noise, as long as you have enough background input that the cells do fire at low rate. Note that previous studies with non-realistic ``white'' Gaussian noise had found much slower responses, apparently Gaussian noise is associated with slow, membrane-time-constant dynamics even by theoretical derivations.</p>
<p> </p>
<p>- Population firing rate can track stimuli varying at ~200-300 Hz!</p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Toyoizumi_undated-zc,
title = "Modeling the Dynamic Interaction of Hebbian and Homeostatic Plasticity",
author = "Toyoizumi, Taro and Kaneko, Megumi and Stryker, Michael P and Miller, Kenneth D",
journal = "Neuron",
volume =  84,
number =  2,
pages = "497--510",
annote = "<p>- Briefly: a plasticity rule in which the total weight is a *product* of independent Hebbian and homeostatic rules eliminates instabilities while ensuring low homeostatic and fast Hebb, as in observations!</p>
<p> </p>
<p>- Massive review of monocular deprivation / ocular dominance plasticity.</p>
<p> </p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lee2003-tz,
title = "Hierarchical Bayesian inference in the visual cortex",
author = "Lee, Tai Sing and Mumford, David",
journal = "JOSA A",
volume =  20,
number =  7,
pages = "1434--1448",
year =  2003,
annote = "<p>- Feedback and Feedforward connections between areas might be Bayesian message passing similar to ``deep belief nets''</p>
<p> </p>
<p>- Allows higher areas to provide global context to lower areas, and then the refined lower areas can refine the higher areas (IT face selectivity going from basic - just gender, orientation - to detailed - identity).</p>
<p> </p>
<p>- [Also explains the final 'spike' in identity-selectivity in the Tsao papers]</p>
<p>- ``Particle filtering'' - lower areas may need to keep several hypothesis (neuron groups) alive at the same time during further processing in the higher areas!</p>
<p> </p>
<p>- V1 responds to illusory contours a la Kanisza... But later than V2!! (note that the rate to illusory is much less than in V2 though..)</p>
<p> </p>
<p>- When looking at 'shaded circles' that indicate relief (``shape from shading''), oddballs ('creux' in a field of 'bosses') elicit stronger responses in V2 immediately (pop-out). In V1, stronger responses only if oddballs are task-relevant. Not higher responses in either for saturated B\&W stimuli.</p>
<p> </p>
<p>- Lamme: V1 responds more strongly  within-figure than on background.</p>
<p>- Bullier lab: FB apparent only with stimuli weak, low aliency and high ambiguity.</p>
<p> </p>
<p>- [However, isn't FB from V2 largely inhibitory? Well, only for large-scale, surround suppression... May be quite different for the selective activity of a single V2 neuron!]</p>
<p>- Generally, feedback is observed in V1 only if the stimuli are ambiguous with several possible interpretations!</p>
<p> </p>
<p>- Some fMRI studies suggest that more ``globally coherent'' patterns generate less activity in V1, even if higher activity in V2. this may be related to particle filtering / the necessity of keeping several hypotheses 'alive', unless one completely dominates.</p>
<p> </p>
<p>- [Lower activity in fMRI may result from fewer neurons active, but each having more activity - i.e. more certainty in the hypotheses??]</p>
<p> </p>
<p>-[Also compatible with the supposedly suppressive V2 FB - when a few V2 neurons are really active they may increase their preferred V1 neuron at the expense of other V1 neurons!]</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Murphy2009-yz,
title = "Balanced Amplification: A New Mechanism of Selective Amplification of Neural Activity Patterns",
author = "Murphy, Brendan K and Miller, Kenneth D",
journal = "Neuron",
volume =  61,
number =  4,
pages = "635--648",
year =  2009,
annote = "<p>- Balanced amplification: because the Inh is separated from the Exc, networks can have dynamics very different from those of pure symmetric networks.</p>
<p> </p>
<p>- In particular, you can expect large transient increases, even if the network is bound to eventually go to zero.</p>
<p> </p>
<p>- If connection matrix is normal, eigenvector basis is orthogonal, and the matrix in this basis is diagonal. So the diagonalized matrix defines 'modes' or 'patterns' that activate coherently within themselves and independently of each other.</p>
<p> </p>
<p>- BUT if connection matrix is NOT normal (as is the case for separate exc and inh), them the eigenvector basis is NOT orthogonal. Looking at Re(eigenvalues) < 1 ensures long-term stability, but you can still get high transient increases.</p>
<p> </p>
<p>- The matrix can be Schaur-decomposed, giving an orthogonal basis of modes, in which the matrix is actually triangular. This means that each 'mode' receives input from the previous mode. The 'modes' define a virtual 'feedforward' network on the recurrent connectivity!</p>
<p> </p>
<p>- The balanced amplification allows for amplification of ``connectivity-preferred'' patterns without slowing dynamics!</p>
<p> </p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yamawaki2015-eb,
title = "A genuine layer 4 in motor cortex with prototypical synaptic circuit connectivity",
author = "Yamawaki, Naoki and Borges, Katharine and Suter, Benjamin A and Harris, Kenneth D and Shepherd, Gordon M G",
journal = "Elife",
volume =  3,
pages = "e05422",
year =  2015,
annote = "<p>- M1 / Primary motor cortex, usually called ``agranular cortex'', DOES have a (small) layer 4!</p>
<p> </p>
<p>- Thalamic inputs, unidirectional output to layer 2/3, lack of input from other cortico-cortical areas, and few long-range cortical outputs.</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Gershman2013-sk,
title = "dopamine.pdf",
author = "Gershman, Sam",
year =  2013,
annote = "<p>- Excellent review of dopamine function in the brain!</p>
<p> </p>
<p>- Explains TD, but also tonic dopamine as average reward level, etc.</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Redish_undated-tv,
title = "Memory and decision making",
author = "Redish, A David and Mizumori, Sheri J Y",
journal = "Neurobiol. Learn. Mem.",
volume =  117,
pages = "1--3",
annote = "<p>- Quick review and introduction to a special issue on Memory and Decision Making</p>
<p> </p>
<p>- Contains an interesting, short summary of model based vs model free:</p>
<p> </p>
<p>``An algorithm that searched through models of the world to construct hypothetical states, which could then be evaluated in the context of the animal’s current situation, depended on knowing the structure of the world, was flexible, but computationally slow ...</p>
<p>In contrast, an algorithm that categorized the situation and recalled a single generalized action that had been learned to be optimal within that situation would be inflexible, but computationally fast to execute...</p>
<p>More recently, it has become clear that a full description of memory and decision-making will require additional components including affective memory systems, Pavlovian action-selection systems, reflexive systems, as well as cognitive and cue-recognition components''</p>
<p> </p>
<p>- Contains many references!</p>
<p> </p>",
language = "en"
}

@ARTICLE{Fernandez-Delgado2014-ae,
title = "Do we need hundreds of classifiers to solve real world classification problems?",
author = "Fern\'{a}ndez-Delgado, Manuel and Cernadas, Eva and Barro, Sen\'{e}n and Amorim, Dinani",
journal = "J. Mach. Learn. Res.",
volume =  15,
number =  1,
pages = "3133--3181",
year =  2014,
annote = "<p>- A review of many different learning / classifier algorithms based on NOT-LARGE-SCALE problems!!</p>
<p>- Apparently, random forests and Gaussian kernel SVMs are best</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{noauthor_undated-rt,
title = "neighborhood\_burdickwill.pdf",
annote = "<p>- Changing neighbourhood DOES improve the testing scores of disadvantaged children (a bit)... But only in Chicago and Baltimore - not so much in Boston, LA...</p>
<p> </p>
<p>- Note that the samples in Chicago and Baltimore were from a much more disadvantaged background and had much more gang violence!</p>
<p> </p>
<p> </p>"
}

@ARTICLE{Reynolds2009-gx,
title = "The Normalization Model of Attention",
author = "Reynolds, John H and Heeger, David J",
journal = "Neuron",
volume =  61,
number =  2,
pages = "168--185",
year =  2009
}

@ARTICLE{Buffalo2010-rx,
title = "A backward progression of attentional effects in the ventral stream",
author = "Buffalo, E A and Fries, P and Landman, R and Liang, H and Desimone, R",
journal = "Proceedings of the National Academy of Sciences",
volume =  107,
number =  1,
pages = "361--365",
month =  "5~" # jan,
year =  2010,
language = "en"
}

@ARTICLE{Baluch_undated-hk,
title = "Mechanisms of top-down attention",
author = "Baluch, Farhan and Itti, Laurent",
journal = "Trends Neurosci.",
volume =  34,
number =  4,
pages = "210--224",
language = "en"
}

@ARTICLE{Noudoost_undated-fb,
title = "Top-down control of visual attention",
author = "Noudoost, Behrad and Chang, Mindy H and Steinmetz, Nicholas A and Moore, Tirin",
journal = "Curr. Opin. Neurobiol.",
volume =  20,
number =  2,
pages = "183--190",
language = "en"
}

@ARTICLE{Barone2000-pz,
title = "Laminar distribution of neurons in extrastriate areas projecting to visual areas {V1} and {V4} correlates with the hierarchical rank and indicates the operation of a distance rule",
author = "Barone, Pascal and Batardiere, Alexandre and Knoblauch, Kenneth and Kennedy, Henry",
journal = "J. Neurosci.",
volume =  20,
number =  9,
pages = "3263--3281",
year =  2000
}

@ARTICLE{Moore2003-xe,
title = "Selective gating of visual signals by microstimulation of frontal cortex",
author = "Moore, Tirin and Armstrong, Katherine M",
abstract = "Several decades of psychophysical and neurophysiological studies have established that visual signals are enhanced at the locus of attention. What remains a mystery is the mechanism that initiates biases in the strength of visual representations. Recent evidence argues that, during spatial attention, these biases reflect nascent saccadic eye movement commands. We examined the functional interaction of saccade preparation and visual coding by electrically stimulating sites within the frontal eye fields (FEF) and measuring its effect on the activity of neurons in extrastriate visual cortex. Here we show that visual responses in area V4 could be enhanced after brief stimulation of retinotopically corresponding sites within the FEF using currents below that needed to evoke saccades. The magnitude of the enhancement depended on the effectiveness of receptive field stimuli as well as on the presence of competing stimuli outside the receptive field. Stimulation of non-corresponding FEF representations could suppress V4 responses. The results suggest that the gain of visual signals is modified according to the strength of spatially corresponding eye movement commands.",
journal = "Nature",
volume =  421,
number =  6921,
pages = "370--373",
month =  "23~" # jan,
year =  2003,
language = "en"
}

@ARTICLE{Gregoriou2009-cz,
title = "High-frequency, long-range coupling between prefrontal and visual cortex during attention",
author = "Gregoriou, Georgia G and Gotts, Stephen J and Zhou, Huihui and Desimone, Robert",
journal = "Science",
volume =  324,
number =  5931,
pages = "1207--1210",
year =  2009
}

@ARTICLE{Saalmann2007-vx,
title = "Neural Mechanisms of Visual Attention: How {Top-Down} Feedback Highlights Relevant Locations",
author = "Saalmann, Yuri B and Pigarev, Ivan N and Vidyasagar, Trichur R",
abstract = "Attention helps us process potentially important objects by selectively increasing the activity of sensory neurons that represent the relevant locations and features of our environment. This selection process requires top-down feedback about what is important in our environment. We investigated how parietal cortical output influences neural activity in early sensory areas. Neural recordings were made simultaneously from the posterior parietal cortex and an earlier area in the visual pathway, the medial temporal area, of macaques performing a visual matching task. When the monkey selectively attended to a location, the timing of activities in the two regions became synchronized, with the parietal cortex leading the medial temporal area. Parietal neurons may thus selectively increase activity in earlier sensory areas to enable focused spatial attention.",
journal = "Science",
volume =  316,
number =  5831,
pages = "1612--1615",
month =  "15~" # jun,
year =  2007,
language = "en"
}

@ARTICLE{Lauritzen2009-ao,
title = "Top--down flow of visual spatial attention signals from parietal to occipital cortex",
author = "Lauritzen, Thomas Z and D'Esposito, Mark and Heeger, David J and Silver, Michael A",
abstract = "Given the complexity of our visual environment, the ability to selectively attend to certain locations, while ignoring others, is crucial for reducing the amount of visual information to manageable levels and for optimizing behavioral performance. Sustained allocation of spatial attention causes persistent increases in functional magnetic resonance imaging (fMRI) signals in portions of early visual cortex that retinotopically represent the attended location, even in the absence of a visual stimulus. Here we test the hypothesis that topographically organized posterior parietal cortical areas IPS1 and IPS2 transmit top--down spatial attention signals to early visual cortex. We employed fMRI and coherency analysis to measure functional connectivity among cortical areas V1, V2, V3, V3A, V3B, V7, IPS1, and IPS2 during sustained visual spatial attention. Attention increased the magnitude of coherency for many pairs of areas in occipital and parietal cortex. Additionally, attention-related activity in IPS1 and IPS2 led activity in several visual cortical areas by a few hundred milliseconds. These results are consistent with transmission of top--down spatial attention signals from IPS1 and IPS2 to early visual cortex.",
journal = "J. Vis.",
volume =  9,
number =  13,
pages = "18",
month =  "16~" # dec,
year =  2009,
language = "en"
}

@ARTICLE{Gawne2002-ou,
title = "Responses of Primate Visual Cortical {V4} Neurons to Simultaneously Presented Stimuli",
author = "Gawne, Timothy J and Martin, Julie M",
abstract = "We report here results from 45 primate V4 visual cortical neurons to the preattentive presentations of seven different patterns located in two separate areas of the same receptive field and to combinations of the patterns in the two locations. For many neurons, we could not determine any clear relationship for the responses to two simultaneous stimuli. However, for a substantial fraction of the neurons we found that the firing rate was well modeled as the maximum firing rate of each stimulus presented separately. It has previously been proposed that taking the maximum of the inputs (``MAX'' operator) could be a useful operation for neurons in visual cortex, although there has until now been little direct physiological evidence for this hypothesis. Our results here provide direct support for the hypothesis that the MAX operator plays a significant (although certainly not exclusive) role in generating the receptive field properties of visual cortical neurons.",
journal = "J. Neurophysiol.",
volume =  88,
number =  3,
pages = "1128--1135",
month =  "1~" # sep,
year =  2002,
language = "en"
}

@ARTICLE{Carrasco_undated-hf,
title = "Visual attention: The past 25 years",
author = "Carrasco, Marisa",
journal = "Vision Res.",
volume =  51,
number =  13,
pages = "1484--1525",
language = "en"
}

@ARTICLE{Reynolds2004-jl,
title = "Attentional modulation of visual processing",
author = "Reynolds, John H and Chelazzi, Leonardo",
journal = "Annu. Rev. Neurosci.",
volume =  27,
number =  1,
pages = "611--647",
month =  "21~" # jul,
year =  2004,
language = "en"
}

@ARTICLE{Kastner2001-ur,
title = "The neural basis of biased competition in human visual cortex",
author = "Kastner, Sabine and Ungerleider, Leslie G",
abstract = "A typical scene contains many different objects that compete for neural representation due to the limited processing capacity of the visual system. At the neural level, competition among multiple stimuli is evidenced by the mutual suppression of their visually evoked responses and occurs most strongly at the level of the receptive field. The competition among multiple objects can be biased by both bottom--up sensory-driven mechanisms and top--down influences, such as selective attention. Functional brain imaging studies reveal that biasing signals due to selective attention can modulate neural activity in visual cortex not only in the presence, but also in the absence of visual stimulation. Although the competition among stimuli for representation is ultimately resolved within visual cortex, the source of top--down biasing signals likely derives from a distributed network of areas in frontal and parietal cortex. Attention-related activity in frontal and parietal areas does not reflect attentional modulation of visually evoked responses, but rather the attentional operations themselves.",
journal = "Neuropsychologia",
volume =  39,
number =  12,
pages = "1263--1276",
year =  2001
}

@ARTICLE{Womelsdorf2006-rr,
title = "Dynamic shifts of visual receptive fields in cortical area {MT} by spatial attention",
author = "Womelsdorf, Thilo and Anton-Erxleben, Katharina and Pieper, Florian and Treue, Stefan",
journal = "Nat. Neurosci.",
volume =  9,
number =  9,
pages = "1156--1160",
year =  2006
}

@ARTICLE{Womelsdorf2008-ry,
title = "Receptive Field Shift and Shrinkage in Macaque Middle Temporal Area through Attentional Gain Modulation",
author = "Womelsdorf, Thilo and Anton-Erxleben, Katharina and Treue, Stefan",
abstract = "Selective attention is the top-down mechanism to allocate neuronal processing resources to the most relevant subset of the information provided by an organism's sensors. Attentional selection of a spatial location modulates the spatial-tuning characteristics (i.e., the receptive fields of neurons in macaque visual cortex). These tuning changes include a shift of receptive field centers toward the focus of attention and a narrowing of the receptive field when the attentional focus is directed into the receptive field. Here, we report that when attention is directed into versus of receptive fields of neurons in the middle temporal visual area (area MT), the magnitude of the shift of the spatial-tuning functions is positively correlated with a narrowing of spatial tuning around the attentional focus. By developing and applying a general attentional gain model, we show that these nonmultiplicative attentional modulations of basic neuronal-tuning characteristics could be a direct consequence of a spatially distributed multiplicative interaction of a bell-shaped attentional spotlight with the spatially fined-grained sensory inputs of MT neurons. Additionally, the model lets us estimate the spatial spread of the attentional top-down signal impinging on visual cortex. Consistent with psychophysical reports, the estimated size of the ``spotlight of attention'' indicates a coarse spatial resolution of attention. These results illustrate how spatially specific nonmultiplicative attentional changes of neuronal-tuning functions can be the result of multiplicative gain modulation affecting sensory neurons in a widely distributed region in cortical space.",
journal = "J. Neurosci.",
volume =  28,
number =  36,
pages = "8934--8944",
month =  "3~" # sep,
year =  2008,
language = "en"
}

@ARTICLE{Connor1997-io,
title = "Spatial Attention Effects in Macaque Area {V4}",
author = "Connor, Charles E and Preddie, Dean C and Gallant, Jack L and Essen, David C Van",
abstract = "Focal visual attention typically produces enhanced perceptual processing at the psychological level and relatively stronger neural responses at the physiological level. A longstanding mechanistic question is whether these attentional effects pertain specifically to the attended (target) object or to the region of space it occupies. We show here that attentional response enhancement in macaque area V4 extends to behaviorally irrelevant objects in the vicinity of the target object, indicating that focal attention has a strong spatial component at the physiological level. In addition, we find that spatial attention effects typically show a striking directional asymmetry. The direction of the asymmetry varies between cells, so that some cells respond best when attention is directed to the left of the stimulus, some when attention is directed to the right, etc. Thus, attention involves not only enhanced responses to behavioral targets but also a complex modulation of responses to other stimuli in the surrounding visual space.",
journal = "J. Neurosci.",
volume =  17,
number =  9,
pages = "3201--3214",
month =  "1~" # may,
year =  1997,
language = "en"
}

@ARTICLE{Anton-Erxleben2009-mq,
title = "Attention Reshapes {Center-Surround} Receptive Field Structure in Macaque Cortical Area {MT}",
author = "Anton-Erxleben, Katharina and Stephan, Valeska M and Treue, Stefan",
abstract = "Directing spatial attention to a location inside the classical receptive field (cRF) of a neuron in macaque medial temporal area (MT) shifts the center of the cRF toward the attended location. Here we investigate the influence of spatial attention on the profile of the inhibitory surround present in many MT neurons. Two monkeys attended to the fixation point or to 1 of 2 random dot patterns (RDPs) placed inside or next to the cRF, whereas a third RDP (the probe) was briefly presented in quick succession across the cRF and surround. The probe presentation responses were used to compute a map of the excitatory receptive field and its inhibitory surround. Attention systematically reshapes the receptive field profile, independently shifting both center and surround toward the attended location. Furthermore, cRF size is changed as a function of relative distance to the attentional focus: attention inside the cRF shrinks it, whereas directing attention next to the cRF expands it. In addition, we find systematic changes in surround inhibition and cRF amplitude. This nonmultiplicative push--pull modulation of the receptive field's center-surround structure optimizes processing at and near the attentional focus to strengthen the representation of the attended stimulus while reducing influences from distractors.",
journal = "Cereb. Cortex",
volume =  19,
number =  10,
pages = "2466--2478",
month =  "1~" # oct,
year =  2009,
language = "en"
}

@ARTICLE{Martinez-Trujillo2004-mq,
title = "{Feature-Based} Attention Increases the Selectivity of Population Responses in Primate Visual Cortex",
author = "Martinez-Trujillo, Julio C and Treue, Stefan",
abstract = "Background: Attending to the spatial location or to nonspatial features of visual stimuli can modulate neuronal responses in primate visual cortex. The modulation by spatial attention changes the gain of sensory neurons and strengthens the representation of attended locations without changing neuronal selectivities such as directionality, i.e., the ratio of responses to preferred and anti-preferred directions of motion. Whether feature-based attention acts in a similar manner is unknown. Results: To clarify this issue, we recorded the responses of 135 direction-selective neurons in the middle temporal area (MT) of two macaques to an unattended moving random dot pattern (the distractor) positioned inside a neuron's receptive field while the animals attended to a second moving pattern positioned in the opposite hemifield. Responses to different directions of the distractor were modulated by the same factor (approximately 12\%) as long as the attended direction remained unchanged. On the other hand, systematically changing the attended direction from a neuron's preferred to its anti-preferred direction caused a systematic change of the attentional modulation from an enhancement to a suppression, increasing directionality by about 20\%. Conclusions: The results show that (1) feature-based attention exerts a multiplicative modulation upon neuronal responses and that the strength of this modulation depends on the similarity between the attended feature and the cell's preferred feature, in line with the feature-similarity gain model, and (2) at the level of the neuronal population, feature-based attention increases the selectivity for attended features by increasing the responses of neurons preferring this feature value while decreasing responses of neurons tuned to the opposite feature value.",
journal = "Curr. Biol.",
volume =  14,
number =  9,
pages = "744--751",
month =  "4~" # may,
year =  2004
}

@ARTICLE{Motter1994-fa,
title = "Neural correlates of attentive selection for color or luminance in extrastriate area {V4}",
author = "Motter, B C",
abstract = "Rhesus monkeys were trained on a conditional orientation discrimination task in order to assess whether attentive selection for a color or luminance stimulus feature would affect visual processing in extrastriate area V4. The task required monkeys to select a bar stimulus based on its color or luminance and then to discriminate the angular tilt of the selected stimulus. The majority of neurons (74\%) were selectively activated when the color or luminance of the stimulus in the receptive field matched the color or luminance of the cue. The activity was attenuated when there was not a match between the stimulus and the cue. The differential activation was based on the presence or absence of the stimulus feature and was independent of spatial location. Across the population of V4 neurons, optimal stimuli that matched the selected color or luminance elicited about twice the activity as stimuli that did not match the selected feature. The feature-selective changes in activity were observed to develop beginning about 200 msec after the stimulus onset and were maintained over the remainder of the behavioral trial. In this task the activity of V4 neurons reflected a selection based on the cued feature and not simply the physical color or luminance of the receptive field stimulus. Under these conditions, the topographic representation of the neural activity in area V4 highlights the potential targets in the visual scene at the expense of background objects. These observations offer a physiological counterpart to psychophysical studies suggesting that stimuli can be preferentially selected in parallel across the visual field on the basis of a unique color or luminance feature",
journal = "J. Neurosci.",
volume =  14,
number =  4,
pages = "2178--2189",
month =  "1~" # apr,
year =  1994,
language = "en"
}

@ARTICLE{Luck1997-gs,
title = "Neural Mechanisms of Spatial Selective Attention in Areas V1, V2, and {V4} of Macaque Visual Cortex",
author = "Luck, Steven J and Chelazzi, Leonardo and Hillyard, Steven A and Desimone, Robert",
abstract = "Luck, Steven J., Leonardo Chelazzi, Steven A. Hillyard, and Robert Desimone. Neural mechanisms of spatial selective attention in areas V1, V2, and V4 of macaque visual cortex. J. Neurophysiol. 77: 24--42, 1997. Many neurons in extrastriate visual cortex have large receptive fields, and this may lead to significant computational problems whenever multiple stimuli fall within a single field. Previous studies have suggested that when multiple stimuli fall within a cell's receptive field, they compete for the cell's response in a manner that can be biased in favor of attended stimuli. In the present study we examined this role of attention in areas V1, V2, and V4 of macaque monkeys with the use of a behavioral paradigm in which attention was directed to one of two stimulus locations. When two stimuli were presented simultaneously inside the cell's receptive field (which could be accomplished only in areas V2 and V4), we found that the cell's response was strongly influenced by which of the two stimuli was attended. The size of this attention effect was reduced when the attended and ignored stimuli were presented sequentially rather than simultaneously. In addition, the effects became very weak and inconsistent in these areas when only one of the two stimuli was located inside the receptive field. Attention thus modulated sensory responses primarily when two or more simultaneous stimuli competed for access to a neuron's receptive field. As in areas V2 and V4, attention did not modulate sensory responses in area V1 when only a single stimulus was inside the receptive field. In addition, the small receptive fields in this area precluded the simultaneous presentation of attended and ignored stimuli inside the receptive field, making it impossible to determine whether attention effects would be observed under the conditions that led to consistent attention effects in areas V2 and V4. Spontaneous firing rates in areas V2 and V4 were found to be 30--40\% higher when attention was directed inside rather than outside the receptive field, even when no stimulus was present in the receptive field. Spontaneous firing rates also varied according to the particular location within the receptive field that was attended. These shifts in spontaneous activity may reflect a top-down signal that biases responses in favor of stimuli at the attended location.",
journal = "J. Neurophysiol.",
volume =  77,
number =  1,
pages = "24--42",
month =  "1~" # jan,
year =  1997,
language = "en"
}

@ARTICLE{Reynolds2000-yx,
title = "Attention Increases Sensitivity of {V4} Neurons",
author = "Reynolds, John H and Pasternak, Tatiana and Desimone, Robert",
abstract = "When attention is directed to a location in the visual field, sensitivity to stimuli at that location is increased. At the neuronal level, this could arise either through a multiplicative increase in firing rate or through an increase in the effective strength of the stimulus. To test conflicting predictions of these alternative models, we recorded responses of V4 neurons to stimuli across a range of luminance contrasts and measured the change in response when monkeys attended to them in order to discriminate a target stimulus from nontargets. Attention caused greater increases in response at low contrast than at high contrast, consistent with an increase in effective stimulus strength. On average, attention increased the effective contrast of the attended stimulus by a factor of 1.51, an increase of 51\% of its physical contrast.",
journal = "Neuron",
volume =  26,
number =  3,
pages = "703--714",
month =  "6~" # jan,
year =  2000,
language = "English"
}

@ARTICLE{Maunsell2002-bh,
title = "The role of attention in visual processing",
author = "Maunsell, John H R and Cook, Erik P",
abstract = "Attention to a visual stimulus typically increases the responses of cortical neurons to that stimulus. Because many studies have shown a close relationship between the performance of individual neurons and behavioural performance of animal subjects, it is important to consider how attention affects this relationship. Measurements of behavioural and neuronal performance taken from rhesus monkeys while they performed a motion detection task with two attentional states show that attention alters the relationship between behaviour and neuronal response. Notably, attention affects the relationship differently in different cortical visual areas. This indicates that a close relationship between neuronal and behavioural performance on a given task persists over changes in attentional state only within limited regions of visual cortex.",
journal = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
volume =  357,
number =  1424,
pages = "1063--1072",
month =  "29~" # aug,
year =  2002,
language = "en"
}

@ARTICLE{Kastner1998-dy,
title = "Mechanisms of Directed Attention in the Human Extrastriate Cortex as Revealed by Functional {MRI}",
author = "Kastner, Sabine and Weerd, Peter De and Desimone, Robert and Ungerleider, Leslie G",
abstract = "A typical scene contains many different objects, but the capacity of the visual system to process multiple stimuli at a given time is limited. Thus, attentional mechanisms are required to select relevant objects from among the many objects competing for visual processing. Evidence from functional magnetic resonance imaging (MRI) in humans showed that when multiple stimuli are present simultaneously in the visual field, their cortical representations within the object recognition pathway interact in a competitive, suppressive fashion. Directing attention to one of the stimuli counteracts the suppressive influence of nearby stimuli. This mechanism may serve to filter out irrelevant information in cluttered visual scenes.",
journal = "Science",
volume =  282,
number =  5386,
pages = "108--111",
month =  "2~" # oct,
year =  1998,
language = "en"
}

@ARTICLE{Lauritzen2009-sc,
title = "Top-down flow of visual spatial attention signals from parietal to occipital cortex",
author = "Lauritzen, Thomas Z and D'Esposito, Mark and Heeger, David J and Silver, Michael A",
affiliation = "Redwood Center for Theoretical Neuroscience, Helen Wills Neuroscience Institute, Henry H. Wheeler Jr. Brain Imaging Center, School of Optometry, University of California, Berkeley, CA 94720-3220, USA. tzl@berkeley.edu",
abstract = "Given the complexity of our visual environment, the ability to selectively attend to certain locations, while ignoring others, is crucial for reducing the amount of visual information to manageable levels and for optimizing behavioral performance. Sustained allocation of spatial attention causes persistent increases in functional magnetic resonance imaging (fMRI) signals in portions of early visual cortex that retinotopically represent the attended location, even in the absence of a visual stimulus. Here we test the hypothesis that topographically organized posterior parietal cortical areas IPS1 and IPS2 transmit top-down spatial attention signals to early visual cortex. We employed fMRI and coherency analysis to measure functional connectivity among cortical areas V1, V2, V3, V3A, V3B, V7, IPS1, and IPS2 during sustained visual spatial attention. Attention increased the magnitude of coherency for many pairs of areas in occipital and parietal cortex. Additionally, attention-related activity in IPS1 and IPS2 led activity in several visual cortical areas by a few hundred milliseconds. These results are consistent with transmission of top-down spatial attention signals from IPS1 and IPS2 to early visual cortex.",
journal = "J. Vis.",
volume =  9,
number =  13,
pages = "18.1--14",
month =  "16~" # dec,
year =  2009,
language = "en"
}

@ARTICLE{Heeger1993-uo,
title = "Modeling simple-cell direction selectivity with normalized, half-squared, linear operators",
author = "Heeger, David J",
journal = "J. Neurophysiol.",
volume =  70,
number =  5,
pages = "1885--1898",
year =  1993
}

@ARTICLE{Miller2002-vu,
title = "Neural Noise Can Explain Expansive, {Power-Law} Nonlinearities in Neural Response Functions",
author = "Miller, Kenneth D and Troyer, Todd W",
abstract = "Many phenomenological models of the responses of simple cells in primary visual cortex have concluded that a cell's firing rate should be given by its input raised to a power greater than one. This is known as an expansive power-law nonlinearity. However, intracellular recordings have shown that a different nonlinearity, a linear-threshold function, appears to give a good prediction of firing rate from a cell's low-pass-filtered voltage response. Using a model based on a linear-threshold function, Anderson et al. showed that voltage noise was critical to converting voltage responses with contrast-invariant orientation tuning into spiking responses with contrast-invariant tuning. We present two separate results clarifying the connection between noise-smoothed linear-threshold functions and power-law nonlinearities. First, we prove analytically that a power-law nonlinearity is the only input-output function that converts contrast-invariant input tuning into contrast-invariant spike tuning. Second, we examine simulations of a simple model that assumes instantaneous spike rate is given by a linear-threshold function of voltage and voltage responses include significant noise. We show that the resulting average spike rate is well described by an expansive power law of the average voltage (averaged over multiple trials), provided that average voltage remains less than about 1.5 SDs of the noise above threshold. Finally, we use this model to show that the noise levels recorded by Anderson et al. are consistent with the degree to which the orientation tuning of spiking responses is more sharply tuned relative to the orientation tuning of voltage responses. Thus neuronal noise can robustly generate power-law input-output functions of the form frequently postulated for simple cells.",
journal = "J. Neurophysiol.",
volume =  87,
number =  2,
pages = "653--659",
month =  "1~" # feb,
year =  2002,
language = "en"
}

@ARTICLE{Desimone1998-xb,
title = "Visual attention mediated by biased competition in extrastriate visual cortex",
author = "Desimone, Robert",
journal = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
volume =  353,
number =  1373,
pages = "1245--1255",
year =  1998
}

@ARTICLE{Herrmann_undated-il,
title = "When size matters: attention affects performance by contrast or response gain",
author = "Herrmann, Katrin and Montaser-Kouhsari, Leila and Carrasco, Marisa and Heeger, David J",
journal = "Nat. Neurosci.",
volume =  13,
number =  12,
pages = "1554--1559"
}

@ARTICLE{Cohen_undated-ja,
title = "Attention improves performance primarily by reducing interneuronal correlations",
author = "Cohen, Marlene R and Maunsell, John H R",
journal = "Nat. Neurosci.",
volume =  12,
number =  12,
pages = "1594--1600"
}


@ARTICLE{Fries2008-ay,
title = "The Effects of Visual Stimulation and Selective Visual Attention on Rhythmic Neuronal Synchronization in Macaque Area {V4}",
author = "Fries, Pascal and Womelsdorf, Thilo and Oostenveld, Robert and Desimone, Robert",
abstract = "Selective attention lends relevant sensory input priority access to higher-level brain areas and ultimately to behavior. Recent studies have suggested that those neurons in visual areas that are activated by an attended stimulus engage in enhanced gamma-band (30--70 Hz) synchronization compared with neurons activated by a distracter. Such precise synchronization could enhance the postsynaptic impact of cells carrying behaviorally relevant information. Previous studies have used the local field potential (LFP) power spectrum or spike-LFP coherence (SFC) to indirectly estimate spike synchronization. Here, we directly demonstrate zero-phase gamma-band coherence among spike trains of V4 neurons. This synchronization was particularly evident during visual stimulation and enhanced by selective attention, thus confirming the pattern inferred from LFP power and SFC. We therefore investigated the time course of LFP gamma-band power and found rapid dynamics consistent with interactions of top-down spatial and feature attention with bottom-up saliency. In addition to the modulation of synchronization during visual stimulation, selective attention significantly changed the prestimulus pattern of synchronization. Attention inside the receptive field of the recorded neuronal population enhanced gamma-band synchronization and strongly reduced $\alpha$-band (9--11 Hz) synchronization in the prestimulus period. These results lend further support for a functional role of rhythmic neuronal synchronization in attentional stimulus selection.",
journal = "J. Neurosci.",
volume =  28,
number =  18,
pages = "4823--4835",
month =  "30~" # apr,
year =  2008,
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bosman_undated-fw,
title = "Attentional Stimulus Selection through Selective Synchronization between Monkey Visual Areas",
author = "Bosman, Conrado A and Schoffelen, Jan-Mathijs and Brunet, Nicolas and Oostenveld, Robert and Bastos, Andre M and Womelsdorf, Thilo and Rubehn, Birthe and Stieglitz, Thomas and De Weerd, Peter and Fries, Pascal",
journal = "Neuron",
volume =  75,
number =  5,
pages = "875--888",
language = "en"
}

@ARTICLE{Itti2001-zb,
title = "Computational modelling of visual attention",
author = "Itti, Laurent and Koch, Christof",
abstract = "Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.",
journal = "Nat. Rev. Neurosci.",
volume =  2,
number =  3,
pages = "194--203",
month =  mar,
year =  2001,
language = "en"
}

@ARTICLE{Shenoy1993-ay,
title = "Learning by selection in the trion model of cortical organization",
author = "Shenoy, Krishna V and Kaufman, Jeffrey and McGrann, John V and Shaw, Gordon L",
journal = "Cereb. Cortex",
volume =  3,
number =  3,
pages = "239--248",
year =  1993
}

@ARTICLE{Berkes2011-lt,
title = "Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment",
author = "Berkes, Pietro and Orb\'{a}n, Gerg\H{o} and Lengyel, M\'{a}t\'{e} and Fiser, J\'{o}zsef",
abstract = "The brain maintains internal models of its environment to interpret sensory inputs and to prepare actions. Although behavioral studies have demonstrated that these internal models are optimally adapted to the statistics of the environment, the neural underpinning of this adaptation is unknown. Using a Bayesian model of sensory cortical processing, we related stimulus-evoked and spontaneous neural activities to inferences and prior expectations in an internal model and predicted that they should match if the model is statistically optimal. To test this prediction, we analyzed visual cortical activity of awake ferrets during development. Similarity between spontaneous and evoked activities increased with age and was specific to responses evoked by natural scenes. This demonstrates the progressive adaptation of internal models to the statistics of natural stimuli at the neural level.",
journal = "Science",
volume =  331,
number =  6013,
pages = "83--87",
month =  "7~" # jan,
year =  2011,
language = "en"
}

@ARTICLE{Goldberg2004-ih,
title = "Patterns of ongoing activity and the functional architecture of the primary visual cortex",
author = "Goldberg, Joshua A and Rokni, Uri and Sompolinsky, Haim",
journal = "Neuron",
volume =  42,
number =  3,
pages = "489--500",
year =  2004,
annote = "tim"
}

@ARTICLE{Perin2011-xi,
title = "A synaptic organizing principle for cortical neuronal groups",
author = "Perin, Rodrigo and Berger, Thomas K and Markram, Henry",
abstract = "Neuronal circuitry is often considered a clean slate that can be dynamically and arbitrarily molded by experience. However, when we investigated synaptic connectivity in groups of pyramidal neurons in the neocortex, we found that both connectivity and synaptic weights were surprisingly predictable. Synaptic weights follow very closely the number of connections in a group of neurons, saturating after only 20\% of possible connections are formed between neurons in a group. When we examined the network topology of connectivity between neurons, we found that the neurons cluster into small world networks that are not scale-free, with less than 2 degrees of separation. We found a simple clustering rule where connectivity is directly proportional to the number of common neighbors, which accounts for these small world networks and accurately predicts the connection probability between any two neurons. This pyramidal neuron network clusters into multiple groups of a few dozen neurons each. The neurons composing each group are surprisingly distributed, typically more than 100 $\mu$m apart, allowing for multiple groups to be interlaced in the same space. In summary, we discovered a synaptic organizing principle that groups neurons in a manner that is common across animals and hence, independent of individual experiences. We speculate that these elementary neuronal groups are prescribed Lego-like building blocks of perception and that acquired memory relies more on combining these elementary assemblies into higher-order constructs.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
volume =  108,
number =  13,
pages = "5419--5424",
month =  "29~" # mar,
year =  2011,
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Brette2005-ef,
title = "Adaptive Exponential {Integrate-and-Fire} Model as an Effective Description of Neuronal Activity",
author = "Brette, Romain and Gerstner, Wulfram",
abstract = "We introduce a two-dimensional integrate-and-fire model that combines an exponential spike mechanism with an adaptation equation, based on recent theoretical findings. We describe a systematic method to estimate its parameters with simple electrophysiological protocols (current-clamp injection of pulses and ramps) and apply it to a detailed conductance-based model of a regular spiking neuron. Our simple model predicts correctly the timing of 96\% of the spikes (±2 ms) of the detailed model in response to injection of noisy synaptic conductances. The model is especially reliable in high-conductance states, typical of cortical activity in vivo, in which intrinsic conductances were found to have a reduced role in shaping spike trains. These results are promising because this simple model has enough expressive power to reproduce qualitatively several electrophysiological classes described in vitro.",
journal = "J. Neurophysiol.",
volume =  94,
number =  5,
pages = "3637--3642",
month =  "1~" # nov,
year =  2005,
language = "en"
}

@ARTICLE{Van_Hateren1998-gq,
title = "Independent component filters of natural images compared with simple cells in primary visual cortex",
author = "van Hateren, J Hans and van der Schaaf, Arjen",
journal = "Proceedings of the Royal Society of London. Series B: Biological Sciences",
volume =  265,
number =  1394,
pages = "359--366",
year =  1998
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sompolinsky1986-sd,
title = "Temporal Association in Asymmetric Neural Networks",
author = "Sompolinsky, H and Kanter, I",
abstract = "A neural network model which is capable of recalling time sequences and cycles of patterns is introduced. In this model, some of the synaptic connections, Jij, between pairs of neurons are asymmetric (Jij≠Jji) and have slow dynamic response. The effects of thermal noise on the generated sequences are discussed. Simulation results demonstrating the performance of the network are presented. The model may be also useful in understanding the generation of rhythmic patterns in biological motor systems.",
journal = "Phys. Rev. Lett.",
volume =  57,
number =  22,
pages = "2861--2864",
month =  "1~" # dec,
year =  1986,
annote = "<p>- A simple (non-spiking?) Hopfield-like neural network that stores sequences of patterns, not just patterns</p>
<p> </p>
<p>- Use both symmetric Hopfield-Hebb synapses, and also pattern-to-pattern non-symmetric synapses.</p>
<p> </p>
<p>- Crucially: the second, non-symmetric synapses are *slower*, allowing for sequences of well-defined patterns</p>
<p> </p>
<p> </p>"
}

@ARTICLE{Olshausen1996-vz,
title = "Emergence of simple-cell receptive field properties by learning a sparse code for natural images",
author = "Olshausen, Bruno A and Field, David J",
journal = "Nature",
volume =  381,
number =  6583,
pages = "607--609",
month =  "13~" # jun,
year =  1996,
language = "en"
}

@ARTICLE{Kenet2003-ns,
title = "Spontaneously emerging cortical representations of visual attributes",
author = "Kenet, Tal and Bibitchkov, Dmitri and Tsodyks, Misha and Grinvald, Amiram and Arieli, Amos",
journal = "Nature",
volume =  425,
number =  6961,
pages = "954--956",
year =  2003
}

@ARTICLE{Hopfield1982-pw,
title = "Neural networks and physical systems with emergent collective computational abilities",
author = "Hopfield, John J",
journal = "Proceedings of the national academy of sciences",
volume =  79,
number =  8,
pages = "2554--2558",
year =  1982
}

@BOOK{Edelman1978-nm,
title = "The mindful brain: Cortical organization and the group-selective theory of higher brain function",
author = "Edelman, Gerald M and Mountcastle, Vernon B",
abstract = "Examines in 2 papers the relationships that connect the higher brain functions---memory, learning, perception, and thinking---with basic levels of neural activity, emphasizing the role of local neuronal circuits. The 1st paper reviews the structure of the neocortex, and the 2nd discusses the hypothesis that consciousness results from phasic reentrant signaling occurring in parallel processes involving associations between stored patterns and current sensory input. (14 p ref)",
publisher = "Massachusetts Inst of Technology Pr",
year =  1978,
address = "Oxford, England"
}

@BOOK{Hebb1949-ph,
title = "The organization of behavior: a neuropsychological theory",
author = "Hebb, Donald Olding",
publisher = "Wiley",
year =  1949,
language = "en"
}

@ARTICLE{Bathellier2012-ub,
title = "Discrete Neocortical Dynamics Predict Behavioral Categorization of Sounds",
author = "Bathellier, Brice and Ushakova, Lyubov and Rumpel, Simon",
journal = "Neuron",
volume =  76,
number =  2,
pages = "435--449",
year =  2012,
annote = "<p>At small scales (200 microns, 46-99 neurons), the smooth tonotopic map of A1 breaks down into functionally discrete, but partially overlapping neural groups, such that different subgroups will respond to different stimuli - in a mutually exclusive fashion: if subgroup 1 is firing, subgroup 2 is not, and vice versa.</p>
<p>Each subgroup responds to only a few stimuli. However, using the whole population of subgroup (where each subgroup is reduced to just one activation value) produces very good discrimination not just of stimuli, but of actual behavioural report.</p>"
}

@ARTICLE{Barlow1972-tg,
title = "Single units and sensation: a neuron doctrine for perceptual psychology?",
author = "Barlow, Horace B",
journal = "Perception",
volume =  1,
pages = "371--394",
year =  1972
}

@ARTICLE{Edelman1993-ip,
title = "Neural Darwinism: Selection and reentrant signaling in higher brain function",
author = "Edelman, Gerald M",
abstract = "Variation and selection within neural populations play key roles in the development and function of the brain. In this article, I review a population theory of the nervous system aimed at understanding the significance of these processes. Since its original formulation in 1978, considerable evidence has accumulated to support this theory of neuronal group selection. Extensive neural modeling based on the theory has provided useful insights into several outstanding neurobiological problems including those concerned with integration of cortical function, sensorimotor control, and perceptually based behavior.",
journal = "Neuron",
volume =  10,
number =  2,
pages = "115--125",
month =  "2~" # jan,
year =  1993,
language = "English"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yamins2014-us,
title = "Performance-optimized hierarchical models predict neural responses in higher visual cortex",
author = "Yamins, Daniel L K and Hong, Ha and Cadieu, Charles F and Solomon, Ethan A and Seibert, Darren and DiCarlo, James J",
abstract = "The ventral visual stream underlies key human visual object recognition abilities. However, neural encoding in the higher areas of the ventral stream remains poorly understood. Here, we describe a modeling approach that yields a quantitatively accurate model of inferior temporal (IT) cortex, the highest ventral cortical area. Using high-throughput computational techniques, we discovered that, within a class of biologically plausible hierarchical neural network models, there is a strong correlation between a model’s categorization performance and its ability to predict individual IT neural unit response data. To pursue this idea, we then identified a high-performing neural network that matches human performance on a range of recognition tasks. Critically, even though we did not constrain this model to match neural data, its top output layer turns out to be highly predictive of IT spiking responses to complex naturalistic images at both the single site and population levels. Moreover, the model’s intermediate layers are highly predictive of neural responses in the V4 cortex, a midlevel visual area that provides the dominant cortical input to IT. These results show that performance optimization---applied in a biologically appropriate model class---can be used to build quantitative predictive models of neural processing.",
journal = "Proc. Natl. Acad. Sci. U. S. A.",
volume =  111,
number =  23,
pages = "8619--8624",
month =  "10~" # jun,
year =  2014,
language = "en"
}

@INCOLLECTION{Gerald_M_Edelman1978-bz,
title = "Group selection and phasic reentrant signaling: A theory of higher brain function",
booktitle = "The Mindful Brain: Cortical Organization and the {Group-Selective} Theory of Higher Brain Function",
author = "{Gerald M. Edelman} and {Gerald M. Edelman} and {Vernon B. Mountcastle}",
publisher = "MIT Press",
pages = "51--100",
year =  1978,
address = "Cambridge"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tal_Kenet2005-sl,
title = "Are single cortical neurons soloists or are they obedient members of a huge orchestra?",
author = "Tal Kenet, Amos Arieli",
pages = "160--181",
year =  2005,
annote = "<p>- Observe cortical activity with Voltage Sensitive Die Imaging (VSDI) - see real-time voltage of local cortical populations (averaged over many local neurons).</p>
<p> </p>
<p>- The coherent (assembly) spontaneous activity fluctuations are very strong, on the ``same order of magnitude'' as stimulus-evoked activity!</p>
<p> </p>
<p>- Record electrophys from one neuron, then image all the local neurons every time this neuron fires. Over time, the assembly of synchronously-firing neurons emerges from the spike-triggered voltage !</p>
<p> </p>
<p>- Spike-triggered voltage fluctuation amplitude during spontaneous is 54\% of stimulus-evoked, onset-locked fluctuation amplitude !</p>
<p> </p>
<p>- 88\% neurons are in an assembly. Neurons in the same column can belong to different assemblies! (STV reveal different patterns for adjacent, same-electrode neurons)</p>
<p> </p>
<p>- single trial responses can be predicted by taking into account pre-stimulus spontaneous activity; thus the sponeantous fluctuations have a strong impact on sensory response!</p>
<p> </p>
<p>- Pre-stimulus spontaneous activity affects the motor behavior of monkeys! (Arieli et al 1996b)</p>
<p> </p>
<p>- The preferred cortical state (PCS) of a neuron is the map associated with this neuron's preferred input</p>
<p> </p>
<p>- Even when the input is non-preferred, the neuron fires more when the population is in its own PCS</p>
<p> </p>
<p>- During spontaneous activity, activities do not necessarily correlate with the PCS (overall, the correlation coefficient is centred on zero)... but  the spike-trigerred average does!</p>
<p> </p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Scholvinck2015-gi,
title = "Cortical State Determines Global Variability and Correlations in Visual Cortex",
author = "Sch{\"{o}}lvinck, Marieke L and Saleem, Aman B and Benucci, Andrea and Harris, Kenneth D and Carandini, Matteo",
abstract = "The response of neurons in sensory cortex to repeated stimulus presentations is highly variable. To investigate the nature of this variability, we compared the spike activity of neurons in the primary visual cortex (V1) of cats with that of their afferents from lateral geniculate nucleus (LGN), in response to similar stimuli. We found variability to be much higher in V1 than in LGN. To investigate the sources of the additional variability, we measured the spiking activity of large V1 populations and found that much of the variability was shared across neurons: the variable portion of the responses of one neuron could be well predicted from the summed activity of the rest of the neurons. Variability thus mostly reflected global fluctuations affecting all neurons. The size and prevalence of these fluctuations, both in responses to stimuli and in ongoing activity, depended on cortical state, being larger in synchronized states than in more desynchronized states. Contrary to previous reports, these fluctuations invested the overall population, regardless of preferred orientation. The global fluctuations substantially increased variability in single neurons and correlations among pairs of neurons. Once this effect was removed, pairwise correlations were reduced and were similar regardless of cortical state. These results highlight the importance of cortical state in controlling cortical operation and can help reconcile previous studies, which differed widely in their estimate of neuronal variability and pairwise correlations.",
journal = "J. Neurosci.",
volume =  35,
number =  1,
pages = "170--178",
month =  "7~" # jan,
year =  2015,
annote = "<p>- Anesthetized cat (like Kenet et al.), arrays, over 1 to 4 days (!)</p>
<p> </p>
<p>- Single-neuron response show massive trial-to-trial variations which are largely explained by the local overall cortical state, pairwise correlation not much dependent on shared orientation, contrarily to Kenet et al.</p>
<p>[</p>
<p>- Seems to explain something different than groups / clusters a la Bathellier. Clusters are what you see when you REMOVE all this trial-to-trial noise. Kenet et al. also had to do a lot of noise removal. The revelation here is just how massive this ongoing noise can be, and that it depends on ``cortical state'' that varies slowly (over hours and between sessions)</p>
<p>]</p>
<p> </p>
<p>- Stimulus explains 27\% of the variance in neuron responses; but stimulus + a multiple of global average noise explains 84\% !! (for 500ms trials)</p>
<p> </p>
<p>- Noise differs across sessions! In some sessions, single-trial response matches the multi-trial average, whereas in others, massive trial-to-trial variability</p>
<p> </p>
<p>- The large trial-to-trial variability in some sessions seems to be caused by MASSIVE excursions in certain trials</p>
<p> </p>
<p>- These massive excursions are also seen in spontaneous, ingoing, gray-screen activity . But only in the ``noisy'' sessions (i.e. when they also occur in evoked responses)!</p>
<p> </p>
<p>- ~50ms events of up to 150 spikes/sec !</p>
<p> </p>
<p> - So two states: ``synchronized'' (with presence of large overall fluctuations) and ``desynchronized'' . Fluctuation index = SD of population total firing divided y its mean. There is actually a continuum b/w desynch and synch, though there seems to be some trend towards bimodality?</p>
<p> </p>
<p>- Pairwise correlations between sites are largely explained by overall population noise, very little dependence on common orientation preference!!   </p>
<p> </p>
<p>- Global noise on a 8ms timescale largely predicts total noise (i.e. response - expected from stimulus / averaged across trials ?..) so large global fluctuations are the culprit.</p>
<p> </p>
<p>- Correlations in ongoing activity not measurably higher between sites of similar preferred orientation</p>
<p> </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Saalmann2012-yw,
title = "The Pulvinar Regulates Information Transmission Between Cortical Areas Based on Attention Demands",
author = "Saalmann, Y B and Pinsk, M A and Wang, L and Li, X and Kastner, S",
journal = "Science",
volume =  337,
number =  6095,
pages = "753--756",
month =  "10~" # aug,
year =  2012,
annote = "<p>- Pulvinar synchronizes with V4 and TEO under attention, even in the delay (blank-screen period). TEO and V4 also synch.</p>
<p> </p>
<p>- Granger causality suggests that, during delay period, Pulvinar really drives TEO and V4, with high GC b/w pulvinar and both TEO/V4, but no GC between TEO and V4 once Pulvinar is accounted.</p>
<p> </p>
<p>-[Problem: they don't show TEO->P or V4->P, only the reverse...]</p>
<p>- During stimulation, by contrast, there is high granger causality between TEO and V4</p>
<p> </p>
<p>- So Pulvinar really seems to gate attention-mediated synchrony between TEO and V4 during delay period?...</p>
<p> </p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Meehl1990-zk,
title = "Why summaries of research on psychological theories are often uninterpretable",
author = "Meehl, Paul E",
journal = "Psychol. Rep.",
volume =  66,
number =  1,
pages = "195--244",
year =  1990,
annote = "<p>- A list of potential massive pitfalls in statistical null-hypothesis testing in correlational (non-experimental/manipulative) studies.</p>
<p> </p>
<p>- ``Null hypothesis testing of correlational predictions from weak substantive theories in soft psychology is subject to the influence of ten obfuscating factors whose effects are usually (1) sizeable, (2) opposed, (3) variable, and (4) unknown The net epistemic effect of these ten obfuscating influences is that the usual research literature review is well nigh uninterpretable Major changes in graduate education, conduct of research, and editorial policy are proposed''</p>
<p> </p>
<p> </p>
<p>- The Crud Factor: Everything correlates with everything else! In a large enough volume of data, you will always find some statistically-significant relationships between ALL (or 90\%) variable pairs.</p>
<p>- This is NOT a false-positive error or a multiple-comparison problem, that's just the way the world is, due to complex networks of genetic / environmental effects!</p>
<p> </p>
<p>- (Note: as a result, you should be able to predict any variable from all the other ones with enormous precision?....)</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hartley2013-xz,
title = "Space in the brain: how the hippocampal formation supports spatial cognition",
author = "Hartley, T and Lever, C and Burgess, N and O'Keefe, J",
journal = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
volume =  369,
number =  1635,
pages = "20120510--20120510",
month =  "23~" # dec,
year =  2013,
annote = "<p>- Mega review of spatial cells in hippocampus / hippocampal formation</p>
<p> </p>
<p>- Usually in the brain, space is represented ``egocentric'' or ``body-centered'', but spatial cells in HPC are ``allocentric'' or ``world-centered''</p>
<p> </p>
<p>- Hippocampal formation = HPC proper (CA1/2/3), plus the Medial and Lateral EC, DG, Subiculum (Sb),. pre- and para-subiculum. Projections are ``largely unidirectional''.</p>
<p> </p>
<p>- Superficial layers of EC are major *cortical* input into HPC. Deep layers of EC and Subiculum are major outputs of HPC. CA1 is also an output - e.g. to PFC</p>
<p> </p>
<p>- But, much re-entry! See Ref. 20</p>
<p> </p>
<p>- CA3 has massive recurrence, and projects to CA1 through Schafer collaterals. CA3 recurrence thought by Marr to underlie pattern completion / association.</p>
<p> </p>
<p>- HPC also has major sub-cortical inputs, e.g. anterior thalamus (which has Head-Direction cells!) through dorsal PreSb; also subcortical outputs( mamillary, ventral striatum, and to lateral septum).</p>
<p> </p>
<p>- Also an indirect CA3-lateral septum - VTA pathway, involved in associating place and rewards?</p>
<p> </p>
<p>- All pf HPC receives input from Medial Septum, inolved in theta generation</p>
<p> </p>
<p>- Theta frequency depends on running speed!</p>
<p>- Theta phase AND Acetylcholine may differentiate encoding vs. retrieval ??</p>
<p> </p>
<p>- Place cells are in HPC proper and DG.</p>
<p>- Dorsal place cells have smaller fields than ventral. (says later that this might be related to difference in membrane properties / ion channels)</p>
<p> </p>
<p>- Place cells are tolerant to cue changes, but removing boundary walls reliably elicit remapping!</p>
<p> </p>
<p>- Phase precession: the place field that you are *entering* fires *last* (leaving / first).</p>
<p> </p>
<p> </p>
<p>- Place cells are not directional, in open fields (says later that they are more directional in linear tracks)</p>
<p> </p>
<p>- HD cells are in dorsal PreSB, mEC, and outside the hippocampal formation (anterior dorsal Thalamus and retrosplenial CTX).</p>
<p> </p>
<p>- If you rotate cues, all  HD cells have their direction rotated equally -relative angles are stable!</p>
<p> </p>
<p>- If you rotate/remap pHD cells, place cells are also rotated.</p>
<p> </p>
<p>- Lesioning HD cells messes with place cells, makes them *more* directionally-sensitive??.</p>
<p> </p>
<p>- Grid cells are in medial EC and Pre- and Para-subiculum.</p>
<p> - Defined by oreitnation (of the triangular axes), scale, and phase. Grid cells at a given site may have widely different phases  - Dorsale mEC grid cells have smaller, denser scales;ventral have larger.</p>
<p> </p>
<p>- Scale seems to jump abruptly and discretely b/w nearby locations``?</p>
<p> </p>
<p> - Grids form overlapping modules with different orientation and scale! (though still tendency of dorsal = smaller)</p>
<p> </p>
<p> - Orientation varies b/w modules (and also a bit within modules??) but not all orientations ae equally represented !</p>
<p> </p>
<p>- Grid cells seem involved in path integration</p>
<p> </p>
<p>- Grid cells may not be crucial to place cells! At least not when path integration is not important!</p>
<p> </p>
<p>- Boundary cells: cells in mEC, Sb, pre- and para-Sb, active near certain boundaries of the environment (from a certain direction!)</p>
<p> </p>
<p> - Predicted from the fact that place cells seemed to track boundary changes...</p>
<p> </p>
<p>- There are also ''boundary-off`` cells - fire whenever you're not near a certain boundary...</p>
<p> </p>
<p>- Hippocampal formation seems important for boundary-based rather than cue-based spatial learning in humans!!</p>
<p> </p>
<p>- Many cells in mEC and para-Sb are ''periodic`` in some sense (including Grid ells, but also ''band-like`` cells) - though the whole population has a small number of preferred orientations and scales!</p>
<p> </p>
<p>- Many cells in EC combine spatial and HD  properties.</p>
<p> </p>
<p>- Also some ''time cells`` in HPC when  delays are behaviorally relevant ??</p>
<p> </p>
<p>- LAteral EC apparently not invovled in spatial stuff - does not receive inputs from the HD -selective Dorsal Pre-Sb</p>
<p> </p>
<p> - ''<span style=``font-size:9pt;font-family:AdvTTc999d02f;''>The HD signal arriving via the dorsal presubiculum appears to underpin the spatial processing of the entire hippocampal formation</span>`` !!</p>
<p> </p>
<p>- mEC is strongly mutually coinnected with para-HPC cortex and post-rhinal cortex (''visuospatial`` processing), but lEC is connected with object-selective Perirhinal Cortex.</p>
<p> </p>
<p>- mEC and lEC projections to DG, CA and subiculum, and from these on, form roughly parallel pathways...</p>
<p> </p>
<p>- Replay: place-cells ''trajectories`` are  observed in short bursts when stationary or asleep. Occurs during EEG events (''sharp waves`` / ''ripples``)</p>
<p> </p>
<p>- Can be forward or reverse.</p>
<p>- Can also occur in theta cycles during locomotion, but these tend to be shorter and rat-centered?</p>
<p>- May support consolidation</p>
<p> </p>
<p>- Can predict future trajectories towards a certain goal!</p>
<p> </p>
<p>- Preplay: constrained sequences can be observed before experience!</p>
<p> </p>
<p> </p>
<p>- All non-HPC spatial cell types provide inputs to the (place-cells) HPC</p>
<p> </p>
<p>- Place cells may be established before grid cells! Inactivating medial septum damages grid cells, but leaves place / HD cells largely untouched!</p>
<p> </p>
<p> - Grid cells: attractor networks formed by excitation-inhibition, or oscillatory interference b/w theta and local cell oscillations? Maybe both !</p>
<p> </p>
<p>- Place cells and grid cells found in human single-cell electrophys?</p>
<p> </p>
<p>- fMRI of human EC shows that activity is higher when humans walk along one of three 60deg orientations, suggesting grid cells !! (But wait, would it not imply that all grid cells have the same orientation?.. Well they say it's ''clustered`` also in rats EC...)</p>
<p> </p>
<p>- Same effect seen in a larger, non-HPC netowkr involved in ''autobiographical memory`` retrieval......</p>
<p> </p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Pfeiffer2013-of,
title = "Hippocampal place-cell sequences depict future paths to remembered goals",
author = "Pfeiffer, Brad E and Foster, David J",
abstract = "Effective navigation requires planning extended routes to remembered goal locations. Hippocampal place cells have been proposed to have a role in navigational planning, but direct evidence has been lacking. Here we show that before goal-directed navigation in an open arena, the rat hippocampus generates brief sequences encoding spatial trajectories strongly biased to progress from the subject’s current location to a known goal location. These sequences predict immediate future behaviour, even in cases in which the specific combination of start and goal locations is novel. These results indicate that hippocampal sequence events characterized previously in linearly constrained environments as ‘replay’ are also capable of supporting a goal-directed, trajectory-finding mechanism, which identifies important places and relevant behavioural paths, at specific times when memory retrieval is required, and in a manner that could be used to control subsequent navigational behaviour. View full text",
journal = "Nature",
volume =  497,
number =  7447,
pages = "74--79",
month =  "2~" # may,
year =  2013,
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mnih2015-wc,
title = "Human-level control through deep reinforcement learning",
author = "Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis",
abstract = "The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.",
journal = "Nature",
volume =  518,
number =  7540,
pages = "529--533",
month =  "26~" # feb,
year =  2015,
annote = "<p>- Train a massive convolutional neural network to determine Q(s,a) - the ``quality'' of all possible actions in a given state</p>
<p> </p>
<p>- Inputs to the network: pixels (essentially the state s); outputs: 1 value per possible action - essentially the Q(s,a).</p>
<p> </p>
<p>- The network is trained through backprop. The reinforcement learning bit is the *Error function* provided to the backprop, over a batch of stored experiences.</p>
<p> </p>
<p><span style=``word-spacing: normal; line-height: 1.5em;''>- More precisely: each stored experience is an initial state s, a taken action a, and a resulting state s' with reward r. </span></p><p><br></p><p>- The Error function being gradient-descented over the weights is simply [r + gamma * max\_a'(Q(a',s')) - Q(a,s)] - a reward prediction error</p>
<p> </p>
<p>- Awesome.</p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Van_der_Meer2010-hw,
title = "Triple Dissociation of Information Processing in Dorsal Striatum, Ventral Striatum, and Hippocampus on a Learned Spatial Decision Task",
author = "van der Meer, Matthijs A A and Johnson, Adam and Schmitzer-Torbert, Neil C and Redish, A David",
abstract = "Summary Decision-making studies across different domains suggest that decisions can arise from multiple, parallel systems in the brain: a flexible system utilizing action-outcome expectancies and a more rigid system based on situation-action associations. The hippocampus, ventral striatum, and dorsal striatum make unique contributions to each system, but how information processing in each of these structures supports these systems is unknown. Recent work has shown covert representations of future paths in hippocampus and of future rewards in ventral striatum. We developed analyses in order to use a comparative methodology and apply the same analyses to all three structures. Covert representations of future paths and reward were both absent from the dorsal striatum. In contrast, dorsal striatum slowly developed situation representations that selectively represented action-rich parts of the task. This triple dissociation suggests that the different roles these structures play are due to differences in information-processing mechanisms.",
journal = "Neuron",
volume =  67,
number =  1,
pages = "25--32",
month =  "15~" # jul,
year =  2010,
annote = "<p>- Dorsal striatum seems to represent specific choice situations, i.e. ``situation-action associator''; hippocampus represents place, including (in difficult choice situations) ``forward'' places; and ventral represents...``value expectation / critic'', etc</p>
<p> </p>
<p>- From the synthesis: ``While hippocampal neural ensembles encoded future paths during pauses at the choice point, dorsal striatal ensembles did not. While ventral striatal reward-related cells showed activity during pauses at the choice point, dorsal striatal reward-related cells did not. In contrast, dorsal striatal ensembles slowly developed a more accurate spatial representation than hippocampal ensembles on the action-rich navigation sequence of the task, and dorsal striatal non-reward-related cells slowly developed responses to high-value cues.''</p>
<p> </p>
<p>- Multiple T-maze: several ``small'' choices (not much cost if you go wrong way), and at the end, one ``big'' choice (boig cost if choose wrong way)</p>
<p> </p>
<p>- In early lapos, animals hesitate / look both ways at the bog choice point - Vicarious Trial and Error - HPC dependent; total time continues to decrease after performance reaches asymptote.</p>
<p> </p>
<p>- Dorsal fires more at choice point, least on the ``Return'' track.</p>
<p>-Ventral simply ramps up, then drops down massively at first reward!</p>
<p>-HPC fires all the time.</p>
<p> </p>
<p>- However, VS and DS have big peaks of cells with field centers located at the reward sites (HPC place fields are roughly uniformly distributed)</p>
<p>- Also, DS (but not VS) has more fields in the navigation sequence than in the long-track section</p>
<p> </p>
<p>- For equal number of cells, DS is BETTER than HPC At decoding position!! (VS sucks)</p>
<p>- Spatial decoding performance increases over early laps within a session, more and longer than HPC (VS decoding is flat). So DS is reorganizing.</p>
<p> </p>
<p>- At the big choice point, all 3 structures have time-stable higher probability of decoding ahead than behind</p>
<p>- However, HPC and VS have much higher probability of decoding ahead in the early laps, in comparison to later laps (DS is stable all the time)</p>
<p>- So both HPC and VS ``look ahead more'' in early laps at the big choice point. NOT at the ``small choice'' points before !</p>
<p>- Later he says that this is ``look-ahead'' during the VTE-like pauses at the choice points (but he doesn't show data to support this)</p>
<p> </p>
<p>- VS reward-sensitive cells ``Fire up'' a bit at the ``big choice'' point, but only in early laps - not in late laps!</p>
<p>- So early on, reward is represented at the choice point in VS , but NOT in DS, and it goes away after learning.</p>
<p> </p>
<p>- Conclusions:</p>
<p>- HPC is a map that can do look-aheads, in a voluntary, dynamic way (only at big choice point and for early laps).</p>
<p>- DS is a situation-action associatior (it learns to encode situations-that-requires-actions); doesn't do look-ahead</p>
<p>- VS ramps up throughout, and also represents reward at choice point, in early trials. Bad position decoding though.  Might be the ``critic'' in actor-critic, ramping being apparently useful as a value signal for model-free learning (??), in addition to helping model-based learning through covert representation of reward at choice points...</p>
<p> </p>
<p>The most interesting part is perhaps the difference between early and late phase: early on, HPC and VS do look-aheads (much more than later), and VS represents reward at the big choice point. </p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Atallah2007-md,
title = "Separate neural substrates for skill learning and performance in the ventral and dorsal striatum",
author = "Atallah, Hisham E and Lopez-Paniagua, Dan and Rudy, Jerry W and O'Reilly, Randall C",
abstract = "It is widely accepted that the striatum of the basal ganglia is a primary substrate for the learning and performance of skills. We provide evidence that two regions of the rat striatum, ventral and dorsal, play distinct roles in instrumental conditioning (skill learning), with the ventral striatum being critical for learning and the dorsal striatum being important for performance but, notably, not for learning. This implies an actor (dorsal) versus director (ventral) division of labor, which is a new variant of the widely discussed actor-critic architecture. Our results also imply that the successful performance of a skill can ultimately result in its establishment as a habit outside the basal ganglia.",
journal = "Nat. Neurosci.",
volume =  10,
number =  1,
pages = "126--131",
month =  jan,
year =  2007,
annote = "<p>(-This is a very strange task; no matter what the rat does, it will get the reward!!)</p>
<p> </p>
<p>- Dorsal striatum necessary for performance of actions, but not for learning (!). VS necessary for learning and performance.</p>
<p> </p>
<p>-VS and DS are distinct cortico-striatal loops!</p>
<p>-VS: ventral PFC (e.g. OFC); DS: dorsal PFC+Motor areas.</p>
<p>- However, both involved in instrumental learning (fMRI, lesions -> deficit)</p>
<p> </p>
<p>- Use either muscimol, or NMDA-blocker AP-5 (Which prevents plasticity), in Ventral and Dorsal striatum.</p>
<p> </p>
<p>- Both Musc and AP-5 in VS during learning phase, kill performance. AP-5 in test phase only has no effect; muscimol in test phase only causes  small deficit.</p>
<p>- So VS activity and plasticity are required during learning; activity helps during performance.</p>
<p> </p>
<p>-Musc in DS kills performance (for this session)  too. However, Musc during learning and no-Musc during testing has excellent performance !! Even though the rat sucked at doing the task during the learning phase, it still learnt very well - almost (not quite) as good as saline!!</p>
<p> </p>
<p>- AP-5 has no effect at all !! Plasticity in DS unneeded ???</p>
<p> </p>
<p>- Conclusion: DS is involved in performance, but not learning of task. At all !</p>
<p> </p>
<p>- Another result is that injecting muscimol on either VS or DS, after normal learning, has relatively small effect on performance. Suggests that learning of the habit also occurs outside the basal ganglia!</p>
<p> </p>
<p> </p>",
language = "eng"
}

@ARTICLE{Xia2011-zm,
title = "Nucleus Accumbens Medium Spiny Neurons Target {Non-Dopaminergic} Neurons in the Ventral Tegmental Area",
author = "Xia, Yanfang and Driscoll, Joseph R and Wilbrecht, Linda and Margolis, Elyssa B and Fields, Howard L and Hjelmstad, Gregory O",
abstract = "The midbrain ventral tegmental area (VTA) projection to the nucleus accumbens (NAc) is implicated in motivation and reinforcement. A significant number of NAc medium spiny neurons (MSNs) project back to the VTA, although the nature of this projection is essentially unknown. For example, do NAc MSNs directly target accumbens-projecting dopamine neurons and do they act via the GABAA or GABAB receptor? To address these issues, we expressed the light-sensitive channel rhodopsin-2 in the rat NAc and made electrophysiological recordings from VTA neurons ex vivo. We found that the NAc directly targets non-dopaminergic VTA neurons, including some that project back to the NAc. These MSN GABAergic terminals are opioid sensitive and act via GABAA receptors.",
journal = "J. Neurosci.",
volume =  31,
number =  21,
pages = "7811--7816",
month =  "25~" # may,
year =  2011,
language = "en"
}

@ARTICLE{Gurney2015-tm,
title = "A new framework for cortico-striatal plasticity: behavioural theory meets in vitro data at the reinforcement-action interface",
author = "Gurney, Kevin N and Humphries, Mark D and Redgrave, Peter",
affiliation = "Department of Psychology, Adaptive Behaviour Research Group, University of Sheffield, United Kingdom; INSIGNEO Institute for In Silico Medicine, University of Sheffield, United Kingdom. Faculty of Life Sciences, University of Manchester, United Kingdom. Department of Psychology, Adaptive Behaviour Research Group, University of Sheffield, United Kingdom.",
abstract = "Operant learning requires that reinforcement signals interact with action representations at a suitable neural interface. Much evidence suggests that this occurs when phasic dopamine, acting as a reinforcement prediction error, gates plasticity at cortico-striatal synapses, and thereby changes the future likelihood of selecting the action(s) coded by striatal neurons. But this hypothesis faces serious challenges. First, cortico-striatal plasticity is inexplicably complex, depending on spike timing, dopamine level, and dopamine receptor type. Second, there is a credit assignment problem-action selection signals occur long before the consequent dopamine reinforcement signal. Third, the two types of striatal output neuron have apparently opposite effects on action selection. Whether these factors rule out the interface hypothesis and how they interact to produce reinforcement learning is unknown. We present a computational framework that addresses these challenges. We first predict the expected activity changes over an operant task for both types of action-coding striatal neuron, and show they co-operate to promote action selection in learning and compete to promote action suppression in extinction. Separately, we derive a complete model of dopamine and spike-timing dependent cortico-striatal plasticity from in vitro data. We then show this model produces the predicted activity changes necessary for learning and extinction in an operant task, a remarkable convergence of a bottom-up data-driven plasticity model with the top-down behavioural requirements of learning theory. Moreover, we show the complex dependencies of cortico-striatal plasticity are not only sufficient but necessary for learning and extinction. Validating the model, we show it can account for behavioural data describing extinction, renewal, and reacquisition, and replicate in vitro experimental data on cortico-striatal plasticity. By bridging the levels between the single synapse and behaviour, our model shows how striatum acts as the action-reinforcement interface.",
journal = "PLoS Biol.",
volume =  13,
number =  1,
pages = "e1002034",
month =  jan,
year =  2015,
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Tepper2007-ot,
title = "{GABAergic} control of substantia nigra dopaminergic neurons",
booktitle = "Progress in Brain Research",
author = "Tepper, James M and Lee, Christian R",
publisher = "Elsevier",
volume =  160,
pages = "189--208",
year =  2007,
annote = "<p>- SNc DA neurons receive GABA from Striatum, GPe AND (the projection neurons of) SNr...</p>
<p>- They say that Pallidal ++ = SNc-DA ++, because the disinhibition through SNr overtakes the weak direct inhibition...</p>
<p>- [NOTE: if pallidal ++ = SNc-DA ++, then D2/ indirect-pathway ++ = SNC-DA -- AND direct / D1-pathway ++ (which also inhibits SNr) should = SNc-DA ++ !  As it should be, conceptually! ]</p>
<p> </p>
<p> </p>
<p>- SNcDA neurons all send one massive dendrite into the SNr !... which actually mingle with the SNr dendrites \& somata themselves!</p>
<p> </p>
<p>- SNc DA has three firing modes: Poisson, pace-maker, or isolated bursts. Only in vivo, so afferent-dependent.</p>
<p> </p>
<p>- Striatum -> SNr is the ``direct'' pathway (``Go''?).</p>
<p>- However, the SNr receives from Striatum matrix, while the SNc receives from Striatum patches!</p>
<p> </p>
<p>- Pallidum (GPe) -> SN is fast, spontaneously highly active. Targets both SNc and SNr.</p>
<p>- SNr GABA neurons are also spontaneously active and project to SNc-DA.</p>
<p> </p>
<p>- The SNr GABA that project to SNc-DA may or may not be the same that project to Thalamus (``output'' neurons) (on the balance, they seem to be).</p>
<p> </p>
<p>- SNc-DA also receive GABA from sources outside the BG (Superior colliculus - both exc and inh, lateral habenula - inhibitory, peripheral pain sensors - inhibitory, Central amygdala - unknown, presumed GABAergic)</p>
<p> </p>
<p>- Stimulating GABAergic afferents from Stri, GPe or SNr has complex effects that depend on type and intensity of stimulation!</p>
<p> </p>
<p>- Striatal stimulation: monosynaptic IPSPs in DA neurons [contradicted by Xia et al. 2011 J Neurosci, Chuhna et al. J Neurosci... But Watabe-Uchida says these are bollocks?] and stronger IPSPs in SNr GABA neurons, which in turn produces a late depolarization of DA neurons...</p>
<p> </p>
<p>- Electrical stimulation of  ``projection neurons'' in Striatum, Pallidum or SNr all produce GABA-A inhibition in SNc-DA !</p>
<p> </p>
<p>- GABA-A antagonists in SNc-DA switches them to reliable bursting.</p>
<p> </p>
<p>- Pallidal activation (with gaba-antagonist) leads to massive inhibition of SNr, but modest *increase* in SNc-DA, with increase in burst firing, and large increase (~45\%) in the DA received by Striatum!  (and conversely for inhibition of Pall with muscimol)</p>
<p> </p>
<p>- This is despite the existence of a direct Pallidal-SNc-DA inhibitory pathway, revealed by direct electrical stimulation. The idea is that the disinhibitory effect of SNr inactivation overwhelms the small, direct inhibitory effect from Pallidum - SNc-DA neurons are less sensitive to GABA than SNr neurons! (also seen by, if you just inject muscimol, DA neurons fire more!)  Also, electric stimulation produces massive simultaneous release of GABA, which exaggerates the effect in comparison to in vivo.</p>
<p> </p>
<p>- ``Since low-intensity stimulation of the striatal or pallidal afferents to the substantia nigra causes disinhibition of nigral dopaminergic neurons, the GABAergic afferents that most consistently act to inhibit dopaminergic neurons in vivo are those originating from the axon collaterals of nigral GABAergic projection neurons''</p>
<p> </p>
<p> </p>
<p>- Suggests that the addiction effect of gaba-like substances (alcohol, benzodiazepines) arises from this ability to disinhibit SNc-DA</p>
<p> </p>
<p> </p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Watabe-Uchida2012-ny,
title = "Whole-brain mapping of direct inputs to midbrain dopamine neurons",
author = "Watabe-Uchida, Mitsuko and Zhu, Lisa and Ogawa, Sachie K and Vamanrao, Archana and Uchida, Naoshige",
affiliation = "Department of Molecular and Cellular Biology, Harvard University, Cambridge, MA 02138, USA. uchida@mcb.harvard.edu",
abstract = "Recent studies indicate that dopamine neurons in the ventral tegmental area (VTA) and substantia nigra pars compacta (SNc) convey distinct signals. To explore this difference, we comprehensively identified each area's monosynaptic inputs using the rabies virus. We show that dopamine neurons in both areas integrate inputs from a more diverse collection of areas than previously thought, including autonomic, motor, and somatosensory areas. SNc and VTA dopamine neurons receive contrasting excitatory inputs: the former from the somatosensory/motor cortex and subthalamic nucleus, which may explain their short-latency responses to salient events; and the latter from the lateral hypothalamus, which may explain their involvement in value coding. We demonstrate that neurons in the striatum that project directly to dopamine neurons form patches in both the dorsal and ventral striatum, whereas those projecting to GABAergic neurons are distributed in the matrix compartment. Neuron-type-specific connectivity lays a foundation for studying how dopamine neurons compute outputs.",
journal = "Neuron",
volume =  74,
number =  5,
pages = "858--873",
month =  "7~" # jun,
year =  2012,
annote = "<p>p- SNc and VTA may be somewhat different.</p>
<p>- DA neurons phasically respond by unpredicted reward / sensory cues that predict reward, inhibited by lack of expected reward / delivery or expactation of ``negative outcome''</p>
<p>- Some neurons react to reward - value coding; but some (especially in SNc) also react to noxious stimuli - saliency coding. Also SNc has faster responses</p>
<p> </p>
<p>- [DIFFICULTY of this whole paper: some of these inputs are GABergi, other are excitatory !! Not obvious which is which!! Though we can make assumptions, e.g. Striatal input largely inhibitory, anything from cortex / Hypothalamus excitatory]</p>
<p> </p>
<p>- Monosynaptic inputs to the VTA and SNc originate from large bands of neurons that cover the BG and specific Hypothalamus areas (plus parts of amygdala: CA and Extended Amygdala).</p>
<p> </p>
<p>- With BG inputs: SNc receives from Dorsal Striatum and GP, VTA receives from NAcc and VP</p>
<p>- VTA and SNc receive from distinct portions of STN (para-STN and STN proper, respectively)</p>
<p>- VTA receives from Lateral Hypothalamic, SNc doesn't.</p>
<p> </p>
<p>- Cortical inputs: mostly frontal+motor/SS. Almost none from caudal (occipital, parietal, or EC (!)) Cortical inputs are generally small in comparison to BG</p>
<p> </p>
<p>- SNc receives from M1/M2 and S1 (also a little bit to VTA). VTA receives from Lateral Orbitofrontal. Little input from other cortical areas (maybe a bit from insular). Very little mPFC input.</p>
<p> </p>
<p>- Midbrain/Hindbrain: SC projects to both [Note: would suffice to create a saliency signal?? But it would be in both, whereas it's observed mostly in SNc...], Dorsal Raphe also. Several random nuclei.</p>
<p> </p>
<p>- Not much labelling in septum or mHabenula, contrarily to previous studies (well, VTA does get some from mHB/lHB, though quite small in number). This may be because thse actually project to non-DA neurons in the VTA !</p>
<p> </p>
<p>- DS has Matrix (project to SNr [uh, and pallidum??]) and Patch (project to SNc).</p>
<p>- DS MSNs from Matrix have radial dendrites with even spines (typical MSNs) and project to Gaba neurons (presumably SNr)</p>
<p>- MSNs from patch project to DA neurons (SnC?), have curving dendrites with uneven spines !</p>
<p>- Xia et al, Chuhma et al. 2011 are bollocks</p>
<p> </p>
<p>- NAcc neurons that project to DA neurons (in VTA rather than SNc) also form ``patches'!</p>
<p> </p>
<p>- Note that VTA also receives from DS - just much less than SNc, but it's still the largest number of inputs to VTA (quite larger, in raw numbers, than from NAcc)! Also, NAcc sends to SNc too - a little.</p>
<p> </p>
<p>- STh inputs to SNc may explain the fast responses of SNc; LH to VTA vs STh/M1/M2/SS to SNc may explain value-coded vs. saliency-detecting neurons...</p>
<p> </p>
<p>- STh is the densest concentration of inputs to SNc, maybe explaining its effectiveness in deep brain stimulation / DBS for Parkinson as a near-perfect replacement for L-dopa.</p>",
language = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tsotsos1995-eg,
title = "Modeling visual attention via selective tuning",
author = "Tsotsos, John K and Culhane, Scan M and Kei Wai, Winky Yan and Lai, Yuzhong and Davis, Neal and Nuflo, Fernando",
abstract = "A model for aspects of visual attention based on the concept of selective tuning is presented. It provides for a solution to the problems of selection in an image, information routing through the visual processing hierarchy and task-specific attentional bias. The central thesis is that attention acts to optimize the search procedure inherent in a solution to vision. It does so by selectively tuning the visual processing network which is accomplished by a top-down hierarchy of winner-take-all processes embedded within the visual processing pyramid. Comparisons to other major computational models of attention and to the relevant neurobiology are included in detail throughout the paper. The model has been implemented; several examples of its performance are shown. This model is a hypothesis for primate visual attention, but it also outperforms existing computational solutions for attention in machine vision and is highly appropriate to solving the problem in a robot vision system.",
journal = "Artif. Intell.",
volume =  78,
number = "1--2",
pages = "507--545",
series = "Special Volume on Computer Vision",
month =  oct,
year =  1995,
annote = "<p>- Tough to understand</p>
<p> </p>
<p>- It seems that he models both saliency AND the ``cleaning'' effects of attention within the same network. The two effects are not clearly distinguished.</p>
<p> </p>
<p>- Keep in mind that even in the top layer there may be more than one unit per location. So you might interpret that as IT cells, such that the most excited one gest selected, then everything that oes not contribute to it is turned off, which gets a clearer definition of its real value/inputs, then you change to the next most excited IT cell, etc.</p>
<p> </p>
<p>- But attention does not target IT directly, and if the top layer is supposed to be V4 it's pretty limited?... How does it explain object-level attention?</p>
<p> </p>
<p>- At any rate, pruning connections? Not realistic.</p>"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cutzu2003-oe,
title = "The selective tuning model of attention: psychophysical evidence for a suppressive annulus around an attended item",
author = "Cutzu, Florin and Tsotsos, John K",
abstract = "The selective tuning model [Artif. Intell. 78 (1995) 507] is a neurobiologically plausible neural network model of visual attention. One of its key predictions is that to simultaneously solve the problems of convergence of neural input and selection of attended items, the portions of the visual neural network that process an attended stimulus must be surrounded by inhibition. To test this hypothesis, we mapped the attentional field around an attended location in a matching task where the subject's attention was directed to a cued target while the distance of a probe item to the target was varied systematically. The main result was that accuracy increased with inter-target separation. The observed pattern of variation of accuracy with distance provided strong evidence in favor of the critical prediction of the model that attention is actively inhibited in the immediate vicinity of an attended location.",
journal = "Vision Res.",
volume =  43,
number =  2,
pages = "205--219",
month =  jan,
year =  2003,
annote = "<p>- The Tsotsos model of ``selective tuning'' of attention predicts a large surround of inhibition around the attended stimulus, so they look for evidence of it.</p>
<p> </p>
<p>- Provides a somewhat clearer description of the Tsotsos model.</p>",
language = "eng"
}

@ARTICLE{Hamker2005-hg,
title = "The Reentry Hypothesis: The Putative Interaction of the Frontal Eye Field, Ventrolateral Prefrontal Cortex, and Areas V4, {IT} for Attention and Eye Movement",
author = "Hamker, Fred H",
abstract = "Attention is known to play a key role in perception, including action selection, object recognition and memory. Despite findings revealing competitive interactions among cell populations, attention remains difficult to explain. The central purpose of this paper is to link up a large number of findings in a single computational approach. Our simulation results suggest that attention can be well explained on a network level involving many areas of the brain. We argue that attention is an emergent phenomenon that arises from reentry and competitive interactions. We hypothesize that guided visual search requires the usage of an object-specific template in prefrontal cortex to sensitize V4 and IT cells whose preferred stimuli match the target template. This induces a feature-specific bias and provides guidance for eye movements. Prior to an eye movement, a spatially organized reentry from occulomotor centers, specifically the movement cells of the frontal eye field, occurs and modulates the gain of V4 and IT cells. The processes involved are elucidated by quantitatively comparing the time course of simulated neural activity with experimental data. Using visual search tasks as an example, we provide clear and empirically testable predictions for the participation of IT, V4 and the frontal eye field in attention. Finally, we explain a possible physiological mechanism that can lead to non-flat search slopes as the result of a slow, parallel discrimination process.",
journal = "Cereb. Cortex",
volume =  15,
number =  4,
pages = "431--447",
month =  "1~" # apr,
year =  2005,
annote = "<p>- Money shot: ``the model V4 reproduces the data of Reynolds et al. (1999): a bias towards one stimulus reduces the influence of the other stimulus within the receptive field. We explain these attention effects by an INPUT GAIN increase and additionally by an indirect inhibition among active populations.''</p>",
language = "en"
}

@ARTICLE{Hamker2006-wp,
title = "{V4} receptive field dynamics as predicted by a systems-level model of visual attention using feedback from the frontal eye field",
author = "Hamker, Fred H and Zirnsak, Marc",
abstract = "Visual attention is generally considered to facilitate the processing of the attended stimulus. Its mechanisms, however, are still under debate. We have developed a systems-level model of visual attention which predicts that attentive effects emerge by the interactions between different brain areas. Recent physiological studies have provided evidence that attention also alters the receptive field structure. For example, V4 receptive fields typically shrink and shift towards the saccade target around saccade onset. We show that receptive field dynamics are inherently predicted by the mechanism of feedback in our model. According to the model an oculomotor feedback signal from an area involved in the competition for the saccade target location, e.g. the frontal eye field, enhances the gain of V4 cells. V4 receptive field dynamics can be observed after pooling the gain modulated responses to obtain a certain degree of spatial invariance. The time course of the receptive field dynamics in the model resemble those obtained from macaque V4.",
journal = "Neural Netw.",
volume =  19,
number =  9,
pages = "1371--1382",
series = "Brain and Attention Brain and Attention",
month =  nov,
year =  2006
}

@INPROCEEDINGS{Coates2011-if,
title = "An analysis of single-layer networks in unsupervised feature learning",
booktitle = "International Conference on Artificial Intelligence and Statistics",
author = "Coates, Adam and Ng, Andrew Y and Lee, Honglak",
abstract = "Abstract A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR by employing increasingly complex unsupervised learning algorithms and ...",
publisher = "machinelearning.wustl.edu",
pages = "215--223",
year =  2011
}

@ARTICLE{Reynolds1999-mo,
title = "Competitive mechanisms subserve attention in macaque areas {V2} and {V4}",
author = "Reynolds, J H and Chelazzi, L and Desimone, R",
affiliation = "Laboratory of Neuropsychology, National Institute of Mental Health, National Institutes of Health, Bethesda, Maryland 20892-4415, USA.",
abstract = "It is well established that attention modulates visual processing in extrastriate cortex. However, the underlying neural mechanisms are unknown. A consistent observation is that attention has its greatest impact on neuronal responses when multiple stimuli appear together within a cell's receptive field. One way to explain this is to assume that multiple stimuli activate competing populations of neurons and that attention biases this competition in favor of the attended stimulus. In the absence of competing stimuli, there is no competition to be resolved. Accordingly, attention has a more limited effect on the neuronal response to a single stimulus. To test this interpretation, we measured the responses of neurons in macaque areas V2 and V4 using a behavioral paradigm that allowed us to isolate automatic sensory processing mechanisms from attentional effects. First, we measured each cell's response to a single stimulus presented alone inside the receptive field or paired with a second receptive field stimulus, while the monkey attended to a location outside the receptive field. Adding the second stimulus typically caused the neuron's response to move toward the response that was elicited by the second stimulus alone. Then, we directed the monkey's attention to one element of the pair. This drove the neuron's response toward the response elicited when the attended stimulus appeared alone. These findings are consistent with the idea that attention biases competitive interactions among neurons, causing them to respond primarily to the attended stimulus. A quantitative neural model of attention is proposed to account for these results.",
journal = "J. Neurosci.",
volume =  19,
number =  5,
pages = "1736--1753",
month =  "1~" # mar,
year =  1999
}

@ARTICLE{Kastner2001-yi,
title = "Modulation of sensory suppression: implications for receptive field sizes in the human visual cortex",
author = "Kastner, S and De Weerd, P and Pinsk, M A and Elizondo, M I and Desimone, R and Ungerleider, L G",
affiliation = "Department of Psychology, Center for the Study of Brain, Mind and Behavior, Princeton University, Princeton, NJ 08544, USA. skastner@princeton.edu",
abstract = "Neurophysiological studies in monkeys show that when multiple visual stimuli appear simultaneously in the visual field, they are not processed independently, but rather interact in a mutually suppressive way. This suggests that multiple stimuli compete for neural representation. Consistent with this notion, we have previously found in humans that functional magnetic resonance imaging (fMRI) signals in V1 and ventral extrastriate areas V2, V4, and TEO are smaller for simultaneously presented (i.e., competing) stimuli than for the same stimuli presented sequentially (i.e., not competing). Here we report that suppressive interactions between stimuli are also present in dorsal extrastriate areas V3A and MT, and we compare these interactions to those in areas V1 through TEO. To exclude the possibility that the differences in responses to simultaneously and sequentially presented stimuli were due to differences in the number of transient onsets, we tested for suppressive interactions in area V4, in an experiment that held constant the number of transient onsets. We found that the fMRI response to a stimulus in the upper visual field was suppressed by the presence of nearby stimuli in the lower visual field. Further, we excluded the possibility that the greater fMRI responses to sequential compared with simultaneous presentations were due to exogeneous attentional cueing by having our subjects count T's or L's at fixation, an attentionally demanding task. Behavioral testing demonstrated that neither condition interfered with performance of the T/L task. Our previous findings suggested that suppressive interactions among nearby stimuli in areas V1 through TEO were scaled to the receptive field (RF) sizes of neurons in those areas. Here we tested this idea by parametrically varying the spatial separation among stimuli in the display. Display sizes ranged from 2 x 2 degrees to 7 x 7 degrees and were centered at 5.5 degrees eccentricity. Based on the effects of display size on the magnitude of suppressive interactions, we estimated that RF sizes at an eccentricity of 5.5 degrees were <2 degrees in V1, 2-4 degrees in V2, 4-6 degrees in V4, larger than 7 degrees (but still confined to a quadrant) in TEO, and larger than 6 degrees (confined to a quadrant) in V3A. These estimates of RF sizes in human visual cortex are strikingly similar to those measured in physiological mapping studies in the homologous visual areas in monkeys.",
journal = "J. Neurophysiol.",
volume =  86,
number =  3,
pages = "1398--1411",
month =  sep,
year =  2001
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Williford2006-ke,
title = "Effects of spatial attention on contrast response functions in macaque area {V4}",
author = "Williford, Tori and Maunsell, John H R",
affiliation = "Department of Neuroscience, Howard Hughes Medical Institute and Baylor College, Houston, Texas, USA.",
abstract = "Previous single-unit studies of visual cortex have reported that spatial attention modulates responses to different orientations and directions proportionally, such that it does not change the width of tuning functions for these properties. Other studies have suggested that spatial attention causes a leftward shift in contrast response functions, such that its effects on responses to stimuli of different contrasts are not proportional. We have further explored the effects of attention on stimulus-response functions by measuring the responses of 131 individual V4 neurons in two monkeys while they did a task that controlled their spatial attention. Each neuron was tested with a set of stimuli that spanned complete ranges of orientation and contrast during different states of attention. Consistent with earlier reports, attention scaled responses to preferred and nonpreferred orientations proportionally. However, we did not find compelling evidence that the effects were best described by a leftward shift of the contrast response function. The modulation of neuronal responses by attention was well described by either a leftward shift or proportional scaling of the contrast response function. Consideration of differences in experimental design and analysis that may have contributed to this discrepancy suggests that it was premature to exclude a proportional scaling of responses to different contrasts by attention in favor of a leftward shift of contrast response functions. The current results reopen the possibility that the effects of attention on stimulus-response functions are well described by a single proportional increase in a neuron's response to all stimuli.",
journal = "J. Neurophysiol.",
volume =  96,
number =  1,
pages = "40--54",
month =  jul,
year =  2006,
annote = "- Is attention contrast gain or response gain? <div><br></div><div>- Answer: Not clear !</div>"
}

@INCOLLECTION{Edelman1978-aa,
title = "Group selection and phasic reentrant signaling: A theory of higher brain function",
booktitle = "The Mindful Brain: Cortical Organization and the {Group-Selective} Theory of Higher Brain Function",
author = "Edelman, Gerald M",
editor = "{Gerald M Edelman and Vernon B Mountcastle}",
publisher = "MIT Press",
pages = "51--100",
year =  1978,
address = "Cambridge"
}

@BOOK{Hebb1949-zr,
title = "The organization of behavior: a neuropsychological theory",
author = "Hebb, D O",
publisher = "Wiley",
series = "A Wiley book in clinical psychology",
year =  1949
}

@ARTICLE{Barlow1972-ob,
title = "Single units and sensation: A neuron doctrine for perceptual psychology?",
author = "Barlow, H B",
journal = "Perception",
volume =  1,
pages = "371--394",
year =  1972
}

@BOOK{Edelman1978-lj,
title = "The mindful brain: Cortical organization and the group-selective theory of higher brain function",
author = "Edelman, Gerald M and Mountcastle, Vernon B",
abstract = "Examines in 2 papers the relationships that connect the higher brain functions---memory, learning, perception, and thinking---with basic levels of neural activity, emphasizing the role of local neuronal circuits. The 1st paper reviews the structure of the neocortex, and the 2nd discusses the hypothesis that consciousness results from phasic reentrant signaling occurring in parallel processes involving associations between stored patterns and current sensory input. (14 p ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)",
publisher = "Massachusetts Inst of Technology Pr",
year =  1978,
keywords = "cortical organization \& group-selective theory of higher brain function, book"
}


